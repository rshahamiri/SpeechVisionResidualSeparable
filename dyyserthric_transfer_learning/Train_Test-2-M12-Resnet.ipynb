{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which speaker do you want to train/test? M12\n",
      "Vocabulary Size: 155\n",
      "Setting training date...\n",
      "Found 930 images belonging to 155 classes.\n",
      "Setting testing date...\n",
      "Found 465 images belonging to 155 classes.\n"
     ]
    }
   ],
   "source": [
    "import utilities\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout , SpatialDropout2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Activation\n",
    "from tensorflow.keras.callbacks import History\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from  tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.regularizers import l1_l2, l1,l2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.utils import class_weight\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import pyprog\n",
    "import os\n",
    "\n",
    "def set_gpus(gpus_number=\"1,2\"):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus_number\n",
    "    \n",
    "SETTINGS_DIR = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "speaker_name=input(\"Which speaker do you want to train/test? \")\n",
    "train_set_path = SETTINGS_DIR+'/images/Dysarthric/Train/'+speaker_name\n",
    "test_set_path = SETTINGS_DIR+\"/images/Dysarthric/Test/\"+speaker_name\n",
    "dnn_file_name_structure = SETTINGS_DIR +\"/Models/cnn_\"+speaker_name+\".json\"\n",
    "training_dynamics_path = SETTINGS_DIR+'/Training Performance/TrainingDynamics'+speaker_name+'.csv'\n",
    "dnn_file_name_weights = SETTINGS_DIR +  \"/Models/cnn_weight_\"+speaker_name+\".h5\"\n",
    "\n",
    "batch_size=256\n",
    "image_input_size=(150,150)\n",
    "vocab_size = utilities.get_no_folders_in_path(test_set_path)\n",
    "print (\"Vocabulary Size:\",vocab_size)\n",
    "\n",
    "def model_compile(model,lr=0.001):\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                          optimizer=optimizers.Adam(lr),\n",
    "                          metrics=['accuracy'])\n",
    "    \n",
    "def get_model(hp):\n",
    "    droprates=hp.Float('droprate', 0.2, 0.75, sampling='linear')\n",
    "    learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
    "    first_train=hp.Choice('first_train', values=['2','3','4','5','6'])\n",
    "    model = FreezeLayers(droprates, load_model(learning_rate=learning_rate), top_unfrozen_layer_name=\"separable_conv2d_\"+ first_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_an_image(image_path, model):\n",
    "    \n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    test_image = image.load_img(image_path, target_size = image_input_size)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0) \n",
    "\n",
    "    y_pred = model.predict_classes(test_image,batch_size)[0]\n",
    "    classes =training_set.class_indices\n",
    "    for key, value in classes.items():\n",
    "        if value==y_pred:\n",
    "            break       \n",
    "\n",
    "    pred_key=utilities.dictionary .index [ utilities.dictionary  ['FILE NAME'] == key ] \n",
    "    predicted_word=utilities.dictionary .iloc[pred_key[0],0]\n",
    "    # Get true label\n",
    "    true_key=true_key=utilities.file_to_index(image_path)\n",
    "    true_word = utilities.dictionary .iloc[true_key,0]\n",
    "    #print(\"Predicted:\",predicted_word,\", True:\",true_word)\n",
    "    return predicted_word, true_word\n",
    "\n",
    "def read_epoch():\n",
    "    if os.path.exists(training_dynamics_path):\n",
    "        \n",
    "        # First check the csv file has headres and add then if missing\n",
    "        try:\n",
    "            training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "            training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        except:\n",
    "            df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "            df.columns = columns=[\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "            df.to_csv(training_dynamics_path, index=False)\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)               \n",
    "        return training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_model(learning_rate=0.001):\n",
    "    # Loading the CNN\n",
    "    json_file = open(dnn_file_name_structure, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(dnn_file_name_weights)\n",
    "    print(learning_rate)\n",
    "    model_compile(model,learning_rate)\n",
    "    return model\n",
    "\n",
    "def save_model(model,is_max_val_inclluded=False,max_val=None, ep=None):\n",
    "    # Save/overwrite the model\n",
    "    if (is_max_val_inclluded):\n",
    "        json_file_name = SETTINGS_DIR+\"/Models/cnn_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".json\"\n",
    "        wights_file_name = SETTINGS_DIR+\"/Models/cnn_weight_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".h5\"\n",
    "        # Delete previously stored models for this speaker\n",
    "        for directory, s, files in os.walk(SETTINGS_DIR+\"/Models/\"):\n",
    "            for f in files:\n",
    "                if speaker_name in f:\n",
    "                    file_path=directory+\"/\"+f\n",
    "                    os.remove(file_path)\n",
    "    else:\n",
    "        json_file_name = dnn_file_name_structure\n",
    "        wights_file_name = dnn_file_name_weights\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(json_file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(wights_file_name)\n",
    "    \n",
    "def save_training_dynamics(epoch,history,with_header=False):\n",
    "    training_dynamics=pd.DataFrame(\n",
    "        data = [ [epoch, history.history['loss'][0] ,  history.history['accuracy'][0],  \n",
    "                history.history['val_loss'][0],  history.history['val_accuracy'][0] ]],\n",
    "        columns=[\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "    )\n",
    "    if (with_header):\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=True)\n",
    "    else:\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=False)\n",
    "            \n",
    "def visualize_training():\n",
    "    import matplotlib.pyplot as plt\n",
    "    if (os.path.isfile(training_dynamics_path) == False ):\n",
    "        print (\"Training dynamics file is not found.\")\n",
    "        return\n",
    "    try:\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "        loss_values = training_dynamics[\"TrainingLoss\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationLoss\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Ploting Accuracy\n",
    "        loss_values = training_dynamics[\"TrainingAccuracy\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationAccuracy\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "     \n",
    "    except:\n",
    "        df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "        df.columns = [\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "        df.to_csv(training_dynamics_path, index=False)\n",
    "        visualize_training()\n",
    "    \n",
    "def get_train_test_sets():\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "        \n",
    "        # https://fairyonice.github.io/Learn-about-ImageDataGenerator.html\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "            width_shift_range=0.30,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=False)\n",
    "        \n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # If shuffle=False then the validation results will be different from classifier.predict_generator()\n",
    "        print (\"Setting training date...\")\n",
    "        training_set = train_datagen.flow_from_directory(\n",
    "            train_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True)\n",
    "        \n",
    "        print (\"Setting testing date...\")\n",
    "        test_set = test_datagen.flow_from_directory(\n",
    "           test_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "        return training_set, test_set\n",
    "    \n",
    "def test_generator(test_set_generator):\n",
    "    steps=test_set_generator.samples/batch_size\n",
    "    model = load_model()\n",
    "\n",
    "    y_pred = model.evaluate_generator(test_set_generator, steps = steps, verbose = 1)\n",
    "    y_test = test_set_generator.classes\n",
    "    correct_classifications=0\n",
    "    for pred,label in zip(y_pred, y_test):\n",
    "        if pred.argmax()==label:\n",
    "            correct_classifications+=1\n",
    "    print (\"Loss:\", y_pred[0])\n",
    "    print (\"Acuracy:\", y_pred[1] *100,\"%\")\n",
    "    return \n",
    "\n",
    "def manual_testing():\n",
    "    model = load_model() \n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/F05\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M06\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M10\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    test_path=test_set_path\n",
    "    \n",
    "    correct_classifications=0\n",
    "    i=0\n",
    "    prog = pyprog.ProgressBar(\"Predicting \", \" Done\", utilities.get_no_files_in_path(test_path))\n",
    "    # Show the initial status\n",
    "    prog.update()\n",
    "    no_processed=i\n",
    "    for directory, s, files in os.walk(test_path):\n",
    "            for f in files:\n",
    "                file_path=directory+\"/\"+f\n",
    "                if (\"jpg\" in f):                \n",
    "                    predicted_word, true_word = predict_an_image(file_path,model)\n",
    "                    #print (predicted_word,true_word)\n",
    "                    if (predicted_word==true_word):\n",
    "                        correct_classifications+=1\n",
    "                    i+=1\n",
    "                    prog.set_stat(i)\n",
    "                    prog.update()\n",
    "\n",
    "    prog.end()\n",
    "    print (\"Testing acuracy:\", correct_classifications/i *100,\"%\")\n",
    "    \n",
    "def train(ideal_loss=0.01, is_dnn_structure_changned=False, learning_rate=0.001, max_epoch=50, enabled_trasfer_learning=False):\n",
    "        \n",
    "        # Check if speaker_name is set\n",
    "        if (speaker_name==\"\"):\n",
    "            print (\"Please set speaker_name and try again.\")\n",
    "            return\n",
    "            \n",
    "        is_new_dnn=False\n",
    "        \n",
    "        history = History()\n",
    "        \n",
    "        print(\"=================================================\")\n",
    "        \n",
    "        if (os.path.isfile(dnn_file_name_structure) and\n",
    "                (os.path.isfile(dnn_file_name_weights)) and \n",
    "                (is_dnn_structure_changned == False)):\n",
    "            # load the previosly trained DNN\n",
    "            if (enabled_trasfer_learning):\n",
    "                # Enable Transfer Learning\n",
    "                print (\"Transfer learning is enabled.\")\n",
    "                model = FreezeLayers(load_model(learning_rate=learning_rate),\n",
    "                                     top_unfrozen_layer_name=\"separable_conv2d_3\" ) \n",
    "            else:\n",
    "                print (\"Transer learning is disabled.\")\n",
    "                model = load_model(learning_rate=learning_rate)\n",
    "            print(\"CNN is loaded.\")\n",
    "        else:\n",
    "            # Create a new model\n",
    "            model =  get_model()                    \n",
    "            print(\"CNN is created\")\n",
    "            # Erase the training_dynamic_csv file\n",
    "            if os.path.exists(training_dynamics_path):\n",
    "                os.remove(training_dynamics_path)\n",
    "            is_new_dnn=True\n",
    "            model_compile(model)\n",
    "        \n",
    "        ep= read_epoch()+1\n",
    "        PringFrozenLayers(model)\n",
    "        history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size, epochs=1,                            \n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10, \n",
    "                             max_queue_size=10)\n",
    "        \n",
    "        save_training_dynamics(ep,history,with_header=is_new_dnn)\n",
    "       \n",
    "        max_val = history.history['val_accuracy'][0]\n",
    "        \n",
    "        while (history.history['loss'][0] >= ideal_loss):\n",
    "            print(\"Epoch\", ep)\n",
    "            history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size,epochs=1,\n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10,\n",
    "                             max_queue_size=10)\n",
    "\n",
    "            # Save the max model, if any            \n",
    "            if (history.history['val_accuracy'][0]>max_val):\n",
    "                max_val= history.history['val_accuracy'][0]\n",
    "                save_model(model=model,is_max_val_inclluded=True,max_val=max_val,ep=ep)\n",
    "             \n",
    "            # Save/overwrite the model\n",
    "            save_model(model)\n",
    "               \n",
    "            ep += 1\n",
    "            save_training_dynamics(ep,history,with_header=False)        \n",
    "\n",
    "            # stop the traning if certain accuracy is reached\n",
    "            #if (ep%10==0):\n",
    "                #manual_testing()   \n",
    "            #if   (history.history['val_accuracy'][0]>0.92):\n",
    "              #  break\n",
    "            if (history.history['loss'][0]<ideal_loss):\n",
    "                   break\n",
    "            \n",
    "            if (ep > max_epoch):\n",
    "                break\n",
    "\n",
    "        return history\n",
    "    \n",
    "    # Transfer learning: freeze top layers but unfreeze all layers below the given layer   \n",
    "def FreezeLayers(droprate, model, top_unfrozen_layer_name):\n",
    "    \n",
    "    model.trainable=True\n",
    "    set_trainable = False\n",
    "    for layer in model.layers:\n",
    "        # Increase dropout rate\n",
    "        if \"dropout\" in layer.name:\n",
    "            layer.rate=droprate\n",
    "            print (layer.name,\"dropout rate updated to\",layer.rate)\n",
    "        if (layer.name==top_unfrozen_layer_name):\n",
    "            set_trainable=True\n",
    "\n",
    "        if (set_trainable):\n",
    "            print (layer.name,\" NOT FREEZED\")\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            print (layer.name,\" FREEZED\")\n",
    "            layer.trainable=False\n",
    "        #if (layer.name==\"dense_1\"):\n",
    "            #layer.trainable = False\n",
    "    #model = add_new_dense(model)\n",
    "    model_compile(model)\n",
    "    return model\n",
    "\n",
    "# add a new dense layer\n",
    "def add_new_dense(model):\n",
    "    new_model=Sequential()\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.name=layer.name+\"_old\"\n",
    "        new_model.add(layer)\n",
    "    new_model.add(Dense(units = 1024, activation='relu' ))\n",
    "    new_model.add(Dropout(0.5))\n",
    "    new_model.add(Dense (units=vocab_size, activation='softmax' ))\n",
    "    return new_model\n",
    "\n",
    "def PringFrozenLayers(model):\n",
    "     for layer in model.layers:\n",
    "            print (\"Layer:\",layer.name, \"Frozen:\",not layer.trainable)\n",
    "            \n",
    "def training_restart_initalize():\n",
    "    import shutil\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_control.json\", dnn_file_name_structure)\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_weight_control.h5\", dnn_file_name_weights)\n",
    "    if (os.path.isfile(training_dynamics_path)):\n",
    "        os.remove(training_dynamics_path)\n",
    "    print (\"Ready for training...\")\n",
    "\n",
    "# Load X and y\n",
    "training_set, test_set =get_train_test_sets()\n",
    "\n",
    "\n",
    "!find '.' -name '*.ipynb_checkpoints' -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training...\n"
     ]
    }
   ],
   "source": [
    "# Enable this if you want to train the model for this speaker from scracth. \n",
    "# Otherwise, the previously trained model is continued training.\n",
    "# This loads the base, control model.\n",
    "training_restart_initalize()\n",
    "set_gpus(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Transfer learning is enabled.\n",
      "0.0001\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.5\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.5\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "separable_conv2d_2  FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.5\n",
      "spatial_dropout2d_2  FREEZED\n",
      "batch_normalization_2  FREEZED\n",
      "max_pooling2d_1  FREEZED\n",
      "separable_conv2d_3  FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.5\n",
      "spatial_dropout2d_3  FREEZED\n",
      "batch_normalization_3  FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.5\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "dropout dropout rate updated to 0.5\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "CNN is loaded.\n",
      "Layer: separable_conv2d Frozen: True\n",
      "Layer: spatial_dropout2d Frozen: True\n",
      "Layer: batch_normalization Frozen: True\n",
      "Layer: max_pooling2d Frozen: True\n",
      "Layer: separable_conv2d_1 Frozen: True\n",
      "Layer: spatial_dropout2d_1 Frozen: True\n",
      "Layer: batch_normalization_1 Frozen: True\n",
      "Layer: separable_conv2d_2 Frozen: True\n",
      "Layer: spatial_dropout2d_2 Frozen: True\n",
      "Layer: batch_normalization_2 Frozen: True\n",
      "Layer: max_pooling2d_1 Frozen: True\n",
      "Layer: separable_conv2d_3 Frozen: True\n",
      "Layer: spatial_dropout2d_3 Frozen: True\n",
      "Layer: batch_normalization_3 Frozen: True\n",
      "Layer: separable_conv2d_4 Frozen: False\n",
      "Layer: spatial_dropout2d_4 Frozen: False\n",
      "Layer: max_pooling2d_2 Frozen: False\n",
      "Layer: dropout Frozen: False\n",
      "Layer: flatten Frozen: False\n",
      "Layer: dense Frozen: False\n",
      "3/3 [==============================] - 3s 673ms/step - loss: 2.7660 - accuracy: 0.7471 - val_loss: 3.5738 - val_accuracy: 0.5462\n",
      "Epoch 449\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 2.2899 - accuracy: 0.7591 - val_loss: 3.3216 - val_accuracy: 0.5462\n",
      "Epoch 450\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.2801 - accuracy: 0.7183 - val_loss: 3.2029 - val_accuracy: 0.5527\n",
      "Epoch 451\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.1721 - accuracy: 0.7118 - val_loss: 3.1773 - val_accuracy: 0.5290\n",
      "Epoch 452\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.1272 - accuracy: 0.7151 - val_loss: 3.1911 - val_accuracy: 0.5269\n",
      "Epoch 453\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.0891 - accuracy: 0.7269 - val_loss: 3.1949 - val_accuracy: 0.5312\n",
      "Epoch 454\n",
      "3/3 [==============================] - 3s 571ms/step - loss: 2.1246 - accuracy: 0.7161 - val_loss: 3.2124 - val_accuracy: 0.5333\n",
      "Epoch 455\n",
      "3/3 [==============================] - 3s 680ms/step - loss: 2.1127 - accuracy: 0.7215 - val_loss: 3.2373 - val_accuracy: 0.5226\n",
      "Epoch 456\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.2582 - accuracy: 0.6914 - val_loss: 3.2863 - val_accuracy: 0.5247\n",
      "Epoch 457\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.3642 - accuracy: 0.6839 - val_loss: 3.2926 - val_accuracy: 0.5226\n",
      "Epoch 458\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.2079 - accuracy: 0.7215 - val_loss: 3.2926 - val_accuracy: 0.5312\n",
      "Epoch 459\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3902 - accuracy: 0.6817 - val_loss: 3.2982 - val_accuracy: 0.5312\n",
      "Epoch 460\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.3555 - accuracy: 0.6871 - val_loss: 3.3035 - val_accuracy: 0.5312\n",
      "Epoch 461\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.3715 - accuracy: 0.6935 - val_loss: 3.2973 - val_accuracy: 0.5419\n",
      "Epoch 462\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.3480 - accuracy: 0.6968 - val_loss: 3.2820 - val_accuracy: 0.5419\n",
      "Epoch 463\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.3693 - accuracy: 0.7226 - val_loss: 3.2755 - val_accuracy: 0.5419\n",
      "Epoch 464\n",
      "3/3 [==============================] - 3s 677ms/step - loss: 2.5134 - accuracy: 0.6742 - val_loss: 3.2932 - val_accuracy: 0.5484\n",
      "Epoch 465\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.3586 - accuracy: 0.6946 - val_loss: 3.3284 - val_accuracy: 0.5505\n",
      "Epoch 466\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.3791 - accuracy: 0.7215 - val_loss: 3.3493 - val_accuracy: 0.5441\n",
      "Epoch 467\n",
      "3/3 [==============================] - 3s 697ms/step - loss: 2.4815 - accuracy: 0.7000 - val_loss: 3.3745 - val_accuracy: 0.5419\n",
      "Epoch 468\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.4687 - accuracy: 0.7129 - val_loss: 3.4283 - val_accuracy: 0.5419\n",
      "Epoch 469\n",
      "3/3 [==============================] - 3s 688ms/step - loss: 2.5971 - accuracy: 0.6828 - val_loss: 3.4723 - val_accuracy: 0.5484\n",
      "Epoch 470\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.4748 - accuracy: 0.6989 - val_loss: 3.4972 - val_accuracy: 0.5419\n",
      "Epoch 471\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.5804 - accuracy: 0.6968 - val_loss: 3.5235 - val_accuracy: 0.5312\n",
      "Epoch 472\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.4794 - accuracy: 0.7366 - val_loss: 3.5339 - val_accuracy: 0.5419\n",
      "Epoch 473\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.6176 - accuracy: 0.6860 - val_loss: 3.5346 - val_accuracy: 0.5419\n",
      "Epoch 474\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.5299 - accuracy: 0.7258 - val_loss: 3.5263 - val_accuracy: 0.5419\n",
      "Epoch 475\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.6990 - accuracy: 0.6806 - val_loss: 3.5067 - val_accuracy: 0.5527\n",
      "Epoch 476\n",
      "3/3 [==============================] - 3s 572ms/step - loss: 2.7148 - accuracy: 0.6892 - val_loss: 3.4851 - val_accuracy: 0.5462\n",
      "Epoch 477\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.5557 - accuracy: 0.7108 - val_loss: 3.4808 - val_accuracy: 0.5376\n",
      "Epoch 478\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5900 - accuracy: 0.7108 - val_loss: 3.5062 - val_accuracy: 0.5441\n",
      "Epoch 479\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.6076 - accuracy: 0.6935 - val_loss: 3.5012 - val_accuracy: 0.5527\n",
      "Epoch 480\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.6665 - accuracy: 0.6914 - val_loss: 3.5026 - val_accuracy: 0.5570\n",
      "Epoch 481\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.5763 - accuracy: 0.6968 - val_loss: 3.5344 - val_accuracy: 0.5484\n",
      "Epoch 482\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.6960 - accuracy: 0.7075 - val_loss: 3.5553 - val_accuracy: 0.5484\n",
      "Epoch 483\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.7200 - accuracy: 0.6957 - val_loss: 3.5728 - val_accuracy: 0.5441\n",
      "Epoch 484\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.6825 - accuracy: 0.7129 - val_loss: 3.5881 - val_accuracy: 0.5419\n",
      "Epoch 485\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.7093 - accuracy: 0.7043 - val_loss: 3.5974 - val_accuracy: 0.5376\n",
      "Epoch 486\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.6665 - accuracy: 0.7086 - val_loss: 3.6159 - val_accuracy: 0.5462\n",
      "Epoch 487\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.6753 - accuracy: 0.7000 - val_loss: 3.6453 - val_accuracy: 0.5441\n",
      "Epoch 488\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.8033 - accuracy: 0.6667 - val_loss: 3.6806 - val_accuracy: 0.5247\n",
      "Epoch 489\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.7125 - accuracy: 0.7011 - val_loss: 3.7170 - val_accuracy: 0.5269\n",
      "Epoch 490\n",
      "3/3 [==============================] - 3s 571ms/step - loss: 2.7117 - accuracy: 0.6978 - val_loss: 3.7637 - val_accuracy: 0.5269\n",
      "Epoch 491\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.7463 - accuracy: 0.6978 - val_loss: 3.7817 - val_accuracy: 0.5183\n",
      "Epoch 492\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 2.7606 - accuracy: 0.7097 - val_loss: 3.7826 - val_accuracy: 0.5075\n",
      "Epoch 493\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.6443 - accuracy: 0.7204 - val_loss: 3.7534 - val_accuracy: 0.5118\n",
      "Epoch 494\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.7457 - accuracy: 0.7215 - val_loss: 3.7281 - val_accuracy: 0.5118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.7882 - accuracy: 0.7097 - val_loss: 3.7300 - val_accuracy: 0.5054\n",
      "Epoch 496\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.7216 - accuracy: 0.7161 - val_loss: 3.7459 - val_accuracy: 0.5247\n",
      "Epoch 497\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.7576 - accuracy: 0.7194 - val_loss: 3.7531 - val_accuracy: 0.5226\n",
      "Epoch 498\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.7254 - accuracy: 0.7108 - val_loss: 3.7662 - val_accuracy: 0.5312\n",
      "Epoch 499\n",
      "3/3 [==============================] - 3s 775ms/step - loss: 2.7486 - accuracy: 0.7086 - val_loss: 3.7458 - val_accuracy: 0.5419\n",
      "Epoch 500\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.7570 - accuracy: 0.7226 - val_loss: 3.7160 - val_accuracy: 0.5462\n",
      "Epoch 501\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.6732 - accuracy: 0.7387 - val_loss: 3.7037 - val_accuracy: 0.5570\n",
      "Epoch 502\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.7108 - accuracy: 0.7161 - val_loss: 3.7044 - val_accuracy: 0.5419\n",
      "Epoch 503\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 2.9043 - accuracy: 0.6839 - val_loss: 3.7045 - val_accuracy: 0.5591\n",
      "Epoch 504\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.6815 - accuracy: 0.7204 - val_loss: 3.7020 - val_accuracy: 0.5591\n",
      "Epoch 505\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.8014 - accuracy: 0.6989 - val_loss: 3.7292 - val_accuracy: 0.5505\n",
      "Epoch 506\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.7081 - accuracy: 0.7215 - val_loss: 3.7471 - val_accuracy: 0.5462\n",
      "Epoch 507\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.8497 - accuracy: 0.7151 - val_loss: 3.7767 - val_accuracy: 0.5548\n",
      "Epoch 508\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.8160 - accuracy: 0.7032 - val_loss: 3.8004 - val_accuracy: 0.5462\n",
      "Epoch 509\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.6992 - accuracy: 0.7462 - val_loss: 3.8042 - val_accuracy: 0.5419\n",
      "Epoch 510\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.7146 - accuracy: 0.7398 - val_loss: 3.7941 - val_accuracy: 0.5419\n",
      "Epoch 511\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.8547 - accuracy: 0.6946 - val_loss: 3.7986 - val_accuracy: 0.5484\n",
      "Epoch 512\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 2.7610 - accuracy: 0.7247 - val_loss: 3.7995 - val_accuracy: 0.5591\n",
      "Epoch 513\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.8720 - accuracy: 0.7204 - val_loss: 3.8046 - val_accuracy: 0.5484\n",
      "Epoch 514\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.7766 - accuracy: 0.7333 - val_loss: 3.8234 - val_accuracy: 0.5312\n",
      "Epoch 515\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.7922 - accuracy: 0.7269 - val_loss: 3.8274 - val_accuracy: 0.5183\n",
      "Epoch 516\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.7613 - accuracy: 0.7366 - val_loss: 3.8225 - val_accuracy: 0.5226\n",
      "Epoch 517\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.8046 - accuracy: 0.7151 - val_loss: 3.8088 - val_accuracy: 0.5269\n",
      "Epoch 518\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.8183 - accuracy: 0.7333 - val_loss: 3.8127 - val_accuracy: 0.5183\n",
      "Epoch 519\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.8212 - accuracy: 0.7237 - val_loss: 3.8262 - val_accuracy: 0.5204\n",
      "Epoch 520\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.8078 - accuracy: 0.7183 - val_loss: 3.8409 - val_accuracy: 0.5312\n",
      "Epoch 521\n",
      "3/3 [==============================] - 3s 776ms/step - loss: 2.8519 - accuracy: 0.7183 - val_loss: 3.8420 - val_accuracy: 0.5333\n",
      "Epoch 522\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.6863 - accuracy: 0.7473 - val_loss: 3.8588 - val_accuracy: 0.5355\n",
      "Epoch 523\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.7732 - accuracy: 0.7183 - val_loss: 3.8729 - val_accuracy: 0.5398\n",
      "Epoch 524\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.8983 - accuracy: 0.7054 - val_loss: 3.8831 - val_accuracy: 0.5355\n",
      "Epoch 525\n",
      "3/3 [==============================] - 3s 695ms/step - loss: 2.7635 - accuracy: 0.7269 - val_loss: 3.8764 - val_accuracy: 0.5484\n",
      "Epoch 526\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.7744 - accuracy: 0.7505 - val_loss: 3.8687 - val_accuracy: 0.5441\n",
      "Epoch 527\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.8709 - accuracy: 0.7280 - val_loss: 3.8441 - val_accuracy: 0.5441\n",
      "Epoch 528\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 2.8213 - accuracy: 0.7011 - val_loss: 3.8402 - val_accuracy: 0.5484\n",
      "Epoch 529\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.7913 - accuracy: 0.7484 - val_loss: 3.8444 - val_accuracy: 0.5419\n",
      "Epoch 530\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.6907 - accuracy: 0.7527 - val_loss: 3.8518 - val_accuracy: 0.5419\n",
      "Epoch 531\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.7705 - accuracy: 0.7419 - val_loss: 3.8669 - val_accuracy: 0.5355\n",
      "Epoch 532\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.8103 - accuracy: 0.7215 - val_loss: 3.8663 - val_accuracy: 0.5355\n",
      "Epoch 533\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.7252 - accuracy: 0.7441 - val_loss: 3.8753 - val_accuracy: 0.5226\n",
      "Epoch 534\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.7546 - accuracy: 0.7301 - val_loss: 3.8713 - val_accuracy: 0.5161\n",
      "Epoch 535\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.7302 - accuracy: 0.7505 - val_loss: 3.8470 - val_accuracy: 0.5269\n",
      "Epoch 536\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.7272 - accuracy: 0.7495 - val_loss: 3.8226 - val_accuracy: 0.5355\n",
      "Epoch 537\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.7679 - accuracy: 0.7398 - val_loss: 3.8280 - val_accuracy: 0.5312\n",
      "Epoch 538\n",
      "3/3 [==============================] - 3s 550ms/step - loss: 2.7573 - accuracy: 0.7258 - val_loss: 3.8642 - val_accuracy: 0.5290\n",
      "Epoch 539\n",
      "3/3 [==============================] - 3s 557ms/step - loss: 2.8628 - accuracy: 0.7183 - val_loss: 3.9014 - val_accuracy: 0.5097\n",
      "Epoch 540\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.8097 - accuracy: 0.7194 - val_loss: 3.9243 - val_accuracy: 0.5140\n",
      "Epoch 541\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.9073 - accuracy: 0.7247 - val_loss: 3.9116 - val_accuracy: 0.5204\n",
      "Epoch 542\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.6468 - accuracy: 0.7849 - val_loss: 3.8803 - val_accuracy: 0.5226\n",
      "Epoch 543\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.8047 - accuracy: 0.7312 - val_loss: 3.8354 - val_accuracy: 0.5355\n",
      "Epoch 544\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.7724 - accuracy: 0.7409 - val_loss: 3.8184 - val_accuracy: 0.5355\n",
      "Epoch 545\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.8119 - accuracy: 0.7183 - val_loss: 3.8167 - val_accuracy: 0.5613\n",
      "Epoch 546\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.8487 - accuracy: 0.7312 - val_loss: 3.8268 - val_accuracy: 0.5634\n",
      "Epoch 547\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.8124 - accuracy: 0.7269 - val_loss: 3.8258 - val_accuracy: 0.5527\n",
      "Epoch 548\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 2.7971 - accuracy: 0.7301 - val_loss: 3.8397 - val_accuracy: 0.5462\n",
      "Epoch 549\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.7991 - accuracy: 0.7548 - val_loss: 3.8433 - val_accuracy: 0.5570\n",
      "Epoch 550\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.7611 - accuracy: 0.7527 - val_loss: 3.8475 - val_accuracy: 0.5419\n",
      "Epoch 551\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.8493 - accuracy: 0.7376 - val_loss: 3.8595 - val_accuracy: 0.5376\n",
      "Epoch 552\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.8063 - accuracy: 0.7462 - val_loss: 3.8625 - val_accuracy: 0.5484\n",
      "Epoch 553\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.8169 - accuracy: 0.7495 - val_loss: 3.8424 - val_accuracy: 0.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554\n",
      "3/3 [==============================] - 3s 706ms/step - loss: 2.8216 - accuracy: 0.7312 - val_loss: 3.8347 - val_accuracy: 0.5398\n",
      "Epoch 555\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.9498 - accuracy: 0.7129 - val_loss: 3.8355 - val_accuracy: 0.5419\n",
      "Epoch 556\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.8174 - accuracy: 0.7376 - val_loss: 3.8296 - val_accuracy: 0.5419\n",
      "Epoch 557\n",
      "3/3 [==============================] - 3s 572ms/step - loss: 2.8313 - accuracy: 0.7387 - val_loss: 3.8347 - val_accuracy: 0.5527\n",
      "Epoch 558\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.7765 - accuracy: 0.7591 - val_loss: 3.8441 - val_accuracy: 0.5419\n",
      "Epoch 559\n",
      "3/3 [==============================] - 3s 555ms/step - loss: 2.6827 - accuracy: 0.7656 - val_loss: 3.8699 - val_accuracy: 0.5376\n",
      "Epoch 560\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 2.8089 - accuracy: 0.7376 - val_loss: 3.8910 - val_accuracy: 0.5376\n",
      "Epoch 561\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.8151 - accuracy: 0.7323 - val_loss: 3.8971 - val_accuracy: 0.5290\n",
      "Epoch 562\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.8497 - accuracy: 0.7323 - val_loss: 3.9003 - val_accuracy: 0.5312\n",
      "Epoch 563\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.9461 - accuracy: 0.7366 - val_loss: 3.8803 - val_accuracy: 0.5548\n",
      "Epoch 564\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.8129 - accuracy: 0.7634 - val_loss: 3.8676 - val_accuracy: 0.5548\n",
      "Epoch 565\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.7508 - accuracy: 0.7548 - val_loss: 3.8657 - val_accuracy: 0.5634\n",
      "Epoch 566\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.7818 - accuracy: 0.7527 - val_loss: 3.8688 - val_accuracy: 0.5505\n",
      "Epoch 567\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.7898 - accuracy: 0.7409 - val_loss: 3.8617 - val_accuracy: 0.5570\n",
      "Epoch 568\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.8098 - accuracy: 0.7452 - val_loss: 3.8614 - val_accuracy: 0.5634\n",
      "Epoch 569\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.8245 - accuracy: 0.7538 - val_loss: 3.8692 - val_accuracy: 0.5613\n",
      "Epoch 570\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.8233 - accuracy: 0.7366 - val_loss: 3.8857 - val_accuracy: 0.5484\n",
      "Epoch 571\n",
      "3/3 [==============================] - 3s 712ms/step - loss: 2.8865 - accuracy: 0.7333 - val_loss: 3.9185 - val_accuracy: 0.5548\n",
      "Epoch 572\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.7109 - accuracy: 0.7538 - val_loss: 3.9463 - val_accuracy: 0.5462\n",
      "Epoch 573\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.8171 - accuracy: 0.7559 - val_loss: 3.9575 - val_accuracy: 0.5548\n",
      "Epoch 574\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.8110 - accuracy: 0.7527 - val_loss: 3.9733 - val_accuracy: 0.5398\n",
      "Epoch 575\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.8494 - accuracy: 0.7516 - val_loss: 3.9709 - val_accuracy: 0.5419\n",
      "Epoch 576\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.8053 - accuracy: 0.7527 - val_loss: 3.9524 - val_accuracy: 0.5376\n",
      "Epoch 577\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.8167 - accuracy: 0.7409 - val_loss: 3.9263 - val_accuracy: 0.5591\n",
      "Epoch 578\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.8548 - accuracy: 0.7333 - val_loss: 3.9042 - val_accuracy: 0.5484\n",
      "Epoch 579\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 2.7016 - accuracy: 0.7656 - val_loss: 3.9104 - val_accuracy: 0.5398\n",
      "Epoch 580\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.7405 - accuracy: 0.7602 - val_loss: 3.9266 - val_accuracy: 0.5333\n",
      "Epoch 581\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.9557 - accuracy: 0.7161 - val_loss: 3.9272 - val_accuracy: 0.5290\n",
      "Epoch 582\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 2.8502 - accuracy: 0.7312 - val_loss: 3.9224 - val_accuracy: 0.5247\n",
      "Epoch 583\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.8572 - accuracy: 0.7129 - val_loss: 3.9051 - val_accuracy: 0.5333\n",
      "Epoch 584\n",
      "3/3 [==============================] - 3s 695ms/step - loss: 2.7802 - accuracy: 0.7581 - val_loss: 3.9018 - val_accuracy: 0.5419\n",
      "Epoch 585\n",
      "3/3 [==============================] - 3s 677ms/step - loss: 2.9613 - accuracy: 0.7151 - val_loss: 3.9044 - val_accuracy: 0.5527\n",
      "Epoch 586\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.9667 - accuracy: 0.7054 - val_loss: 3.9029 - val_accuracy: 0.5527\n",
      "Epoch 587\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.6613 - accuracy: 0.7828 - val_loss: 3.9150 - val_accuracy: 0.5527\n",
      "Epoch 588\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.8517 - accuracy: 0.7462 - val_loss: 3.9122 - val_accuracy: 0.5505\n",
      "Epoch 589\n",
      "3/3 [==============================] - 3s 704ms/step - loss: 2.8063 - accuracy: 0.7462 - val_loss: 3.8925 - val_accuracy: 0.5462\n",
      "Epoch 590\n",
      "3/3 [==============================] - 3s 557ms/step - loss: 2.8121 - accuracy: 0.7516 - val_loss: 3.8851 - val_accuracy: 0.5570\n",
      "Epoch 591\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.7584 - accuracy: 0.7602 - val_loss: 3.8608 - val_accuracy: 0.5548\n",
      "Epoch 592\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.7329 - accuracy: 0.7591 - val_loss: 3.8315 - val_accuracy: 0.5677\n",
      "Epoch 593\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.8152 - accuracy: 0.7398 - val_loss: 3.8174 - val_accuracy: 0.5763\n",
      "Epoch 594\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 2.8678 - accuracy: 0.7387 - val_loss: 3.8013 - val_accuracy: 0.5957\n",
      "Epoch 595\n",
      "3/3 [==============================] - 3s 689ms/step - loss: 2.7477 - accuracy: 0.7591 - val_loss: 3.8385 - val_accuracy: 0.5785\n",
      "Epoch 596\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.8261 - accuracy: 0.7484 - val_loss: 3.8939 - val_accuracy: 0.5613\n",
      "Epoch 597\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.8174 - accuracy: 0.7387 - val_loss: 3.9480 - val_accuracy: 0.5376\n",
      "Epoch 598\n",
      "3/3 [==============================] - 3s 691ms/step - loss: 2.7532 - accuracy: 0.7774 - val_loss: 3.9693 - val_accuracy: 0.5312\n",
      "Epoch 599\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.9384 - accuracy: 0.7366 - val_loss: 3.9641 - val_accuracy: 0.5355\n",
      "Epoch 600\n",
      "3/3 [==============================] - 3s 565ms/step - loss: 2.7530 - accuracy: 0.7538 - val_loss: 3.9558 - val_accuracy: 0.5398\n",
      "Epoch 601\n",
      "3/3 [==============================] - 3s 685ms/step - loss: 2.8376 - accuracy: 0.7462 - val_loss: 3.9492 - val_accuracy: 0.5376\n",
      "Epoch 602\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.8004 - accuracy: 0.7527 - val_loss: 3.9501 - val_accuracy: 0.5333\n",
      "Epoch 603\n",
      "3/3 [==============================] - 3s 701ms/step - loss: 2.7780 - accuracy: 0.7581 - val_loss: 3.9476 - val_accuracy: 0.5355\n",
      "Epoch 604\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 2.8438 - accuracy: 0.7290 - val_loss: 3.9677 - val_accuracy: 0.5376\n",
      "Epoch 605\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.7642 - accuracy: 0.7570 - val_loss: 3.9887 - val_accuracy: 0.5333\n",
      "Epoch 606\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.7197 - accuracy: 0.7677 - val_loss: 4.0135 - val_accuracy: 0.5269\n",
      "Epoch 607\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.8040 - accuracy: 0.7441 - val_loss: 4.0096 - val_accuracy: 0.5398\n",
      "Epoch 608\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.7262 - accuracy: 0.7774 - val_loss: 4.0243 - val_accuracy: 0.5419\n",
      "Epoch 609\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.8101 - accuracy: 0.7559 - val_loss: 4.0143 - val_accuracy: 0.5419\n",
      "Epoch 610\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 2.8341 - accuracy: 0.7516 - val_loss: 4.0014 - val_accuracy: 0.5505\n",
      "Epoch 611\n",
      "3/3 [==============================] - 3s 553ms/step - loss: 2.8551 - accuracy: 0.7430 - val_loss: 3.9932 - val_accuracy: 0.5462\n",
      "Epoch 612\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.7930 - accuracy: 0.7409 - val_loss: 3.9916 - val_accuracy: 0.5419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.8146 - accuracy: 0.7430 - val_loss: 4.0030 - val_accuracy: 0.5355\n",
      "Epoch 614\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.6805 - accuracy: 0.7720 - val_loss: 4.0146 - val_accuracy: 0.5247\n",
      "Epoch 615\n",
      "3/3 [==============================] - 3s 564ms/step - loss: 2.8083 - accuracy: 0.7527 - val_loss: 4.0273 - val_accuracy: 0.5161\n",
      "Epoch 616\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.7401 - accuracy: 0.7516 - val_loss: 4.0418 - val_accuracy: 0.5011\n",
      "Epoch 617\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.7887 - accuracy: 0.7505 - val_loss: 4.0600 - val_accuracy: 0.5075\n",
      "Epoch 618\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.7542 - accuracy: 0.7473 - val_loss: 4.0449 - val_accuracy: 0.5140\n",
      "Epoch 619\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.8585 - accuracy: 0.7387 - val_loss: 4.0102 - val_accuracy: 0.5226\n",
      "Epoch 620\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 2.8402 - accuracy: 0.7484 - val_loss: 3.9912 - val_accuracy: 0.5140\n",
      "Epoch 621\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.6634 - accuracy: 0.7763 - val_loss: 3.9800 - val_accuracy: 0.5312\n",
      "Epoch 622\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.7615 - accuracy: 0.7516 - val_loss: 3.9646 - val_accuracy: 0.5355\n",
      "Epoch 623\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.6886 - accuracy: 0.7871 - val_loss: 3.9701 - val_accuracy: 0.5441\n",
      "Epoch 624\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.7392 - accuracy: 0.7806 - val_loss: 3.9667 - val_accuracy: 0.5441\n",
      "Epoch 625\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.7516 - accuracy: 0.7591 - val_loss: 3.9539 - val_accuracy: 0.5462\n",
      "Epoch 626\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.8082 - accuracy: 0.7570 - val_loss: 3.9749 - val_accuracy: 0.5312\n",
      "Epoch 627\n",
      "3/3 [==============================] - 3s 772ms/step - loss: 2.8458 - accuracy: 0.7452 - val_loss: 4.0044 - val_accuracy: 0.5376\n",
      "Epoch 628\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 2.8807 - accuracy: 0.7419 - val_loss: 4.0052 - val_accuracy: 0.5376\n",
      "Epoch 629\n",
      "3/3 [==============================] - 3s 555ms/step - loss: 2.7990 - accuracy: 0.7656 - val_loss: 4.0237 - val_accuracy: 0.5462\n",
      "Epoch 630\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.7258 - accuracy: 0.7656 - val_loss: 4.0403 - val_accuracy: 0.5419\n",
      "Epoch 631\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.6427 - accuracy: 0.7882 - val_loss: 4.0395 - val_accuracy: 0.5355\n",
      "Epoch 632\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.8006 - accuracy: 0.7559 - val_loss: 4.0394 - val_accuracy: 0.5333\n",
      "Epoch 633\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.8023 - accuracy: 0.7667 - val_loss: 4.0293 - val_accuracy: 0.5290\n",
      "Epoch 634\n",
      "3/3 [==============================] - 3s 571ms/step - loss: 2.7353 - accuracy: 0.7796 - val_loss: 4.0333 - val_accuracy: 0.5204\n",
      "Epoch 635\n",
      "3/3 [==============================] - 3s 709ms/step - loss: 2.8000 - accuracy: 0.7613 - val_loss: 4.0386 - val_accuracy: 0.5097\n",
      "Epoch 636\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.8164 - accuracy: 0.7484 - val_loss: 4.0489 - val_accuracy: 0.5054\n",
      "Epoch 637\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.7886 - accuracy: 0.7785 - val_loss: 4.0433 - val_accuracy: 0.5054\n",
      "Epoch 638\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.7305 - accuracy: 0.7527 - val_loss: 4.0243 - val_accuracy: 0.5097\n",
      "Epoch 639\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.8238 - accuracy: 0.7452 - val_loss: 4.0178 - val_accuracy: 0.5140\n",
      "Epoch 640\n",
      "3/3 [==============================] - 3s 706ms/step - loss: 2.7777 - accuracy: 0.7624 - val_loss: 4.0167 - val_accuracy: 0.5183\n",
      "Epoch 641\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.7968 - accuracy: 0.7473 - val_loss: 4.0265 - val_accuracy: 0.5161\n",
      "Epoch 642\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.7757 - accuracy: 0.7624 - val_loss: 4.0122 - val_accuracy: 0.5204\n",
      "Epoch 643\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.7089 - accuracy: 0.7753 - val_loss: 4.0023 - val_accuracy: 0.5290\n",
      "Epoch 644\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.7492 - accuracy: 0.7634 - val_loss: 4.0089 - val_accuracy: 0.5312\n",
      "Epoch 645\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.8154 - accuracy: 0.7634 - val_loss: 4.0240 - val_accuracy: 0.5290\n",
      "Epoch 646\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.7172 - accuracy: 0.7720 - val_loss: 4.0052 - val_accuracy: 0.5226\n",
      "Epoch 647\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.7918 - accuracy: 0.7473 - val_loss: 3.9984 - val_accuracy: 0.5333\n",
      "Epoch 648\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.7840 - accuracy: 0.7677 - val_loss: 3.9861 - val_accuracy: 0.5548\n",
      "Epoch 649\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.7825 - accuracy: 0.7710 - val_loss: 3.9897 - val_accuracy: 0.5419\n",
      "Epoch 650\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.8282 - accuracy: 0.7430 - val_loss: 3.9700 - val_accuracy: 0.5398\n",
      "Epoch 651\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.7470 - accuracy: 0.7538 - val_loss: 3.9388 - val_accuracy: 0.5290\n",
      "Epoch 652\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 2.7463 - accuracy: 0.7656 - val_loss: 3.9452 - val_accuracy: 0.5226\n",
      "Epoch 653\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.7665 - accuracy: 0.7548 - val_loss: 3.9783 - val_accuracy: 0.5161\n",
      "Epoch 654\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.8195 - accuracy: 0.7452 - val_loss: 4.0053 - val_accuracy: 0.5118\n",
      "Epoch 655\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.6499 - accuracy: 0.7828 - val_loss: 4.0474 - val_accuracy: 0.5204\n",
      "Epoch 656\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.7371 - accuracy: 0.7624 - val_loss: 4.0709 - val_accuracy: 0.5183\n",
      "Epoch 657\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.8745 - accuracy: 0.7387 - val_loss: 4.0388 - val_accuracy: 0.5247\n",
      "Epoch 658\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.7638 - accuracy: 0.7527 - val_loss: 4.0224 - val_accuracy: 0.5204\n",
      "Epoch 659\n",
      "3/3 [==============================] - 3s 769ms/step - loss: 2.6208 - accuracy: 0.7892 - val_loss: 4.0174 - val_accuracy: 0.5290\n",
      "Epoch 660\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.7308 - accuracy: 0.7688 - val_loss: 3.9916 - val_accuracy: 0.5290\n",
      "Epoch 661\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.7219 - accuracy: 0.7516 - val_loss: 3.9825 - val_accuracy: 0.5183\n",
      "Epoch 662\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.8122 - accuracy: 0.7570 - val_loss: 3.9951 - val_accuracy: 0.5226\n",
      "Epoch 663\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.6769 - accuracy: 0.7796 - val_loss: 4.0111 - val_accuracy: 0.5118\n",
      "Epoch 664\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.7216 - accuracy: 0.7634 - val_loss: 4.0156 - val_accuracy: 0.5183\n",
      "Epoch 665\n",
      "3/3 [==============================] - 3s 712ms/step - loss: 2.7788 - accuracy: 0.7548 - val_loss: 4.0380 - val_accuracy: 0.5183\n",
      "Epoch 666\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 2.7690 - accuracy: 0.7645 - val_loss: 4.0708 - val_accuracy: 0.5054\n",
      "Epoch 667\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.7709 - accuracy: 0.7581 - val_loss: 4.0895 - val_accuracy: 0.4968\n",
      "Epoch 668\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.7860 - accuracy: 0.7462 - val_loss: 4.0975 - val_accuracy: 0.5032\n",
      "Epoch 669\n",
      "3/3 [==============================] - 3s 553ms/step - loss: 2.7885 - accuracy: 0.7699 - val_loss: 4.0877 - val_accuracy: 0.5054\n",
      "Epoch 670\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.7808 - accuracy: 0.7559 - val_loss: 4.0658 - val_accuracy: 0.5011\n",
      "Epoch 671\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.6755 - accuracy: 0.7796 - val_loss: 4.0576 - val_accuracy: 0.4946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.7399 - accuracy: 0.7591 - val_loss: 4.0791 - val_accuracy: 0.4989\n",
      "Epoch 673\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.6467 - accuracy: 0.7839 - val_loss: 4.0941 - val_accuracy: 0.5097\n",
      "Epoch 674\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.7010 - accuracy: 0.7828 - val_loss: 4.1011 - val_accuracy: 0.5075\n",
      "Epoch 675\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.7138 - accuracy: 0.7559 - val_loss: 4.0934 - val_accuracy: 0.5075\n",
      "Epoch 676\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.6863 - accuracy: 0.7882 - val_loss: 4.0800 - val_accuracy: 0.5054\n",
      "Epoch 677\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.7230 - accuracy: 0.7688 - val_loss: 4.0622 - val_accuracy: 0.5054\n",
      "Epoch 678\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 2.6912 - accuracy: 0.7828 - val_loss: 4.0476 - val_accuracy: 0.5226\n",
      "Epoch 679\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.6771 - accuracy: 0.7903 - val_loss: 4.0454 - val_accuracy: 0.5161\n",
      "Epoch 680\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.7220 - accuracy: 0.7720 - val_loss: 4.0565 - val_accuracy: 0.5204\n",
      "Epoch 681\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.7091 - accuracy: 0.7882 - val_loss: 4.0625 - val_accuracy: 0.5032\n",
      "Epoch 682\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.7040 - accuracy: 0.7806 - val_loss: 4.0621 - val_accuracy: 0.5054\n",
      "Epoch 683\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.6865 - accuracy: 0.7796 - val_loss: 4.0902 - val_accuracy: 0.5054\n",
      "Epoch 684\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.8095 - accuracy: 0.7441 - val_loss: 4.1202 - val_accuracy: 0.5140\n",
      "Epoch 685\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.7020 - accuracy: 0.7753 - val_loss: 4.1104 - val_accuracy: 0.5161\n",
      "Epoch 686\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.6539 - accuracy: 0.7903 - val_loss: 4.1066 - val_accuracy: 0.5183\n",
      "Epoch 687\n",
      "3/3 [==============================] - 3s 565ms/step - loss: 2.7058 - accuracy: 0.7763 - val_loss: 4.1152 - val_accuracy: 0.5226\n",
      "Epoch 688\n",
      "3/3 [==============================] - 3s 695ms/step - loss: 2.7418 - accuracy: 0.7570 - val_loss: 4.1051 - val_accuracy: 0.5118\n",
      "Epoch 689\n",
      "3/3 [==============================] - 3s 565ms/step - loss: 2.7134 - accuracy: 0.7602 - val_loss: 4.1116 - val_accuracy: 0.5097\n",
      "Epoch 690\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.7403 - accuracy: 0.7559 - val_loss: 4.1231 - val_accuracy: 0.5118\n",
      "Epoch 691\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 2.7124 - accuracy: 0.7720 - val_loss: 4.1445 - val_accuracy: 0.5054\n",
      "Epoch 692\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.6701 - accuracy: 0.7925 - val_loss: 4.1648 - val_accuracy: 0.5075\n",
      "Epoch 693\n",
      "3/3 [==============================] - 3s 569ms/step - loss: 2.6500 - accuracy: 0.8054 - val_loss: 4.1652 - val_accuracy: 0.5011\n",
      "Epoch 694\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.6799 - accuracy: 0.7763 - val_loss: 4.1620 - val_accuracy: 0.5118\n",
      "Epoch 695\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.6438 - accuracy: 0.7742 - val_loss: 4.1527 - val_accuracy: 0.5097\n",
      "Epoch 696\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.7235 - accuracy: 0.7720 - val_loss: 4.1369 - val_accuracy: 0.5140\n",
      "Epoch 697\n",
      "3/3 [==============================] - 3s 557ms/step - loss: 2.6656 - accuracy: 0.7882 - val_loss: 4.1366 - val_accuracy: 0.5226\n",
      "Epoch 698\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.6603 - accuracy: 0.7849 - val_loss: 4.1659 - val_accuracy: 0.5226\n",
      "Epoch 699\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.7203 - accuracy: 0.7688 - val_loss: 4.1667 - val_accuracy: 0.5140\n",
      "Epoch 700\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.7248 - accuracy: 0.7817 - val_loss: 4.1550 - val_accuracy: 0.4968\n",
      "Epoch 701\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.6723 - accuracy: 0.7731 - val_loss: 4.1690 - val_accuracy: 0.4946\n",
      "Epoch 702\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.7592 - accuracy: 0.7624 - val_loss: 4.1701 - val_accuracy: 0.4946\n",
      "Epoch 703\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.7181 - accuracy: 0.7688 - val_loss: 4.1503 - val_accuracy: 0.4946\n",
      "Epoch 704\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.5912 - accuracy: 0.7957 - val_loss: 4.1573 - val_accuracy: 0.4989\n",
      "Epoch 705\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 2.7077 - accuracy: 0.7849 - val_loss: 4.1486 - val_accuracy: 0.5011\n",
      "Epoch 706\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.6470 - accuracy: 0.7817 - val_loss: 4.1356 - val_accuracy: 0.5032\n",
      "Epoch 707\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.6482 - accuracy: 0.7731 - val_loss: 4.1315 - val_accuracy: 0.5032\n",
      "Epoch 708\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.6848 - accuracy: 0.7946 - val_loss: 4.1319 - val_accuracy: 0.5247\n",
      "Epoch 709\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.6994 - accuracy: 0.7860 - val_loss: 4.1670 - val_accuracy: 0.5269\n",
      "Epoch 710\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.6569 - accuracy: 0.7720 - val_loss: 4.1874 - val_accuracy: 0.5247\n",
      "Epoch 711\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.6259 - accuracy: 0.7839 - val_loss: 4.1949 - val_accuracy: 0.5226\n",
      "Epoch 712\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.6977 - accuracy: 0.7677 - val_loss: 4.1903 - val_accuracy: 0.5097\n",
      "Epoch 713\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.7022 - accuracy: 0.7753 - val_loss: 4.1719 - val_accuracy: 0.5204\n",
      "Epoch 714\n",
      "3/3 [==============================] - 3s 690ms/step - loss: 2.7051 - accuracy: 0.7796 - val_loss: 4.1444 - val_accuracy: 0.5054\n",
      "Epoch 715\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.6371 - accuracy: 0.7763 - val_loss: 4.1375 - val_accuracy: 0.5097\n",
      "Epoch 716\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.6022 - accuracy: 0.7806 - val_loss: 4.1502 - val_accuracy: 0.5140\n",
      "Epoch 717\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.7182 - accuracy: 0.7753 - val_loss: 4.1676 - val_accuracy: 0.5075\n",
      "Epoch 718\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.6920 - accuracy: 0.7882 - val_loss: 4.1890 - val_accuracy: 0.5075\n",
      "Epoch 719\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.7377 - accuracy: 0.7495 - val_loss: 4.2131 - val_accuracy: 0.5054\n",
      "Epoch 720\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 2.7197 - accuracy: 0.7634 - val_loss: 4.2267 - val_accuracy: 0.5032\n",
      "Epoch 721\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.5822 - accuracy: 0.8054 - val_loss: 4.2415 - val_accuracy: 0.4946\n",
      "Epoch 722\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.6768 - accuracy: 0.7796 - val_loss: 4.2492 - val_accuracy: 0.4882\n",
      "Epoch 723\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.6621 - accuracy: 0.7763 - val_loss: 4.2366 - val_accuracy: 0.4925\n",
      "Epoch 724\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.6397 - accuracy: 0.7946 - val_loss: 4.2351 - val_accuracy: 0.4925\n",
      "Epoch 725\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.6529 - accuracy: 0.7817 - val_loss: 4.2083 - val_accuracy: 0.5011\n",
      "Epoch 726\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.6573 - accuracy: 0.7871 - val_loss: 4.1674 - val_accuracy: 0.5054\n",
      "Epoch 727\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.6216 - accuracy: 0.7957 - val_loss: 4.1517 - val_accuracy: 0.5118\n",
      "Epoch 728\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.5250 - accuracy: 0.8065 - val_loss: 4.1592 - val_accuracy: 0.5140\n",
      "Epoch 729\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.6808 - accuracy: 0.7763 - val_loss: 4.1563 - val_accuracy: 0.5075\n",
      "Epoch 730\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.6449 - accuracy: 0.7817 - val_loss: 4.1420 - val_accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 2.6199 - accuracy: 0.7957 - val_loss: 4.1285 - val_accuracy: 0.5140\n",
      "Epoch 732\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 2.7316 - accuracy: 0.7656 - val_loss: 4.1104 - val_accuracy: 0.5290\n",
      "Epoch 733\n",
      "3/3 [==============================] - 3s 712ms/step - loss: 2.7083 - accuracy: 0.7624 - val_loss: 4.1065 - val_accuracy: 0.5204\n",
      "Epoch 734\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.6687 - accuracy: 0.7796 - val_loss: 4.1168 - val_accuracy: 0.5097\n",
      "Epoch 735\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5717 - accuracy: 0.7871 - val_loss: 4.1243 - val_accuracy: 0.5140\n",
      "Epoch 736\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.8015 - accuracy: 0.7452 - val_loss: 4.1228 - val_accuracy: 0.5204\n",
      "Epoch 737\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.5826 - accuracy: 0.7978 - val_loss: 4.1365 - val_accuracy: 0.5290\n",
      "Epoch 738\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.5718 - accuracy: 0.8000 - val_loss: 4.1515 - val_accuracy: 0.5290\n",
      "Epoch 739\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.5146 - accuracy: 0.7989 - val_loss: 4.1603 - val_accuracy: 0.5269\n",
      "Epoch 740\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.6167 - accuracy: 0.7871 - val_loss: 4.1590 - val_accuracy: 0.5204\n",
      "Epoch 741\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.5922 - accuracy: 0.7849 - val_loss: 4.1489 - val_accuracy: 0.5118\n",
      "Epoch 742\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.6828 - accuracy: 0.7731 - val_loss: 4.1490 - val_accuracy: 0.5183\n",
      "Epoch 743\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.6026 - accuracy: 0.7989 - val_loss: 4.1590 - val_accuracy: 0.5140\n",
      "Epoch 744\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.6928 - accuracy: 0.7667 - val_loss: 4.1801 - val_accuracy: 0.5118\n",
      "Epoch 745\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.5947 - accuracy: 0.7903 - val_loss: 4.1826 - val_accuracy: 0.5054\n",
      "Epoch 746\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.7116 - accuracy: 0.7624 - val_loss: 4.1812 - val_accuracy: 0.5204\n",
      "Epoch 747\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.5762 - accuracy: 0.8075 - val_loss: 4.1932 - val_accuracy: 0.5226\n",
      "Epoch 748\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.5963 - accuracy: 0.7882 - val_loss: 4.2317 - val_accuracy: 0.5183\n",
      "Epoch 749\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 2.5575 - accuracy: 0.7989 - val_loss: 4.2533 - val_accuracy: 0.5097\n",
      "Epoch 750\n",
      "3/3 [==============================] - 3s 698ms/step - loss: 2.6372 - accuracy: 0.7774 - val_loss: 4.2613 - val_accuracy: 0.5075\n",
      "Epoch 751\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.5944 - accuracy: 0.7882 - val_loss: 4.2683 - val_accuracy: 0.5075\n",
      "Epoch 752\n",
      "3/3 [==============================] - 3s 709ms/step - loss: 2.6348 - accuracy: 0.8011 - val_loss: 4.2534 - val_accuracy: 0.5140\n",
      "Epoch 753\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6163 - accuracy: 0.7849 - val_loss: 4.2347 - val_accuracy: 0.5183\n",
      "Epoch 754\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.7482 - accuracy: 0.7505 - val_loss: 4.2318 - val_accuracy: 0.5118\n",
      "Epoch 755\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 2.6021 - accuracy: 0.7978 - val_loss: 4.2440 - val_accuracy: 0.5011\n",
      "Epoch 756\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.5927 - accuracy: 0.7839 - val_loss: 4.2386 - val_accuracy: 0.5140\n",
      "Epoch 757\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.5512 - accuracy: 0.7989 - val_loss: 4.2098 - val_accuracy: 0.5226\n",
      "Epoch 758\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.6231 - accuracy: 0.7785 - val_loss: 4.1795 - val_accuracy: 0.5376\n",
      "Epoch 759\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.5900 - accuracy: 0.7742 - val_loss: 4.1671 - val_accuracy: 0.5333\n",
      "Epoch 760\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.6511 - accuracy: 0.7892 - val_loss: 4.1822 - val_accuracy: 0.5419\n",
      "Epoch 761\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.6476 - accuracy: 0.7796 - val_loss: 4.1851 - val_accuracy: 0.5333\n",
      "Epoch 762\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.5758 - accuracy: 0.7978 - val_loss: 4.1892 - val_accuracy: 0.5312\n",
      "Epoch 763\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.6599 - accuracy: 0.7688 - val_loss: 4.1600 - val_accuracy: 0.5355\n",
      "Epoch 764\n",
      "3/3 [==============================] - 3s 710ms/step - loss: 2.5856 - accuracy: 0.7860 - val_loss: 4.1428 - val_accuracy: 0.5333\n",
      "Epoch 765\n",
      "3/3 [==============================] - 3s 571ms/step - loss: 2.5933 - accuracy: 0.7946 - val_loss: 4.1583 - val_accuracy: 0.5355\n",
      "Epoch 766\n",
      "3/3 [==============================] - 3s 696ms/step - loss: 2.6149 - accuracy: 0.7849 - val_loss: 4.1757 - val_accuracy: 0.5376\n",
      "Epoch 767\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.5281 - accuracy: 0.8172 - val_loss: 4.1964 - val_accuracy: 0.5290\n",
      "Epoch 768\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.7505 - accuracy: 0.7688 - val_loss: 4.1928 - val_accuracy: 0.5333\n",
      "Epoch 769\n",
      "3/3 [==============================] - 3s 552ms/step - loss: 2.6944 - accuracy: 0.7645 - val_loss: 4.1720 - val_accuracy: 0.5183\n",
      "Epoch 770\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.6468 - accuracy: 0.7785 - val_loss: 4.1374 - val_accuracy: 0.5204\n",
      "Epoch 771\n",
      "3/3 [==============================] - 3s 553ms/step - loss: 2.6357 - accuracy: 0.7634 - val_loss: 4.1235 - val_accuracy: 0.5247\n",
      "Epoch 772\n",
      "3/3 [==============================] - 3s 551ms/step - loss: 2.5902 - accuracy: 0.7817 - val_loss: 4.1405 - val_accuracy: 0.5183\n",
      "Epoch 773\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.5903 - accuracy: 0.7935 - val_loss: 4.1577 - val_accuracy: 0.5333\n",
      "Epoch 774\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.5328 - accuracy: 0.7968 - val_loss: 4.1579 - val_accuracy: 0.5355\n",
      "Epoch 775\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.5374 - accuracy: 0.8032 - val_loss: 4.1589 - val_accuracy: 0.5484\n",
      "Epoch 776\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.5870 - accuracy: 0.7828 - val_loss: 4.1576 - val_accuracy: 0.5355\n",
      "Epoch 777\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.5718 - accuracy: 0.7935 - val_loss: 4.1593 - val_accuracy: 0.5290\n",
      "Epoch 778\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5715 - accuracy: 0.7828 - val_loss: 4.1622 - val_accuracy: 0.5269\n",
      "Epoch 779\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.5053 - accuracy: 0.8054 - val_loss: 4.1635 - val_accuracy: 0.5355\n",
      "Epoch 780\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.6005 - accuracy: 0.7817 - val_loss: 4.1627 - val_accuracy: 0.5355\n",
      "Epoch 781\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.5489 - accuracy: 0.8108 - val_loss: 4.1648 - val_accuracy: 0.5290\n",
      "Epoch 782\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6422 - accuracy: 0.7796 - val_loss: 4.1889 - val_accuracy: 0.5183\n",
      "Epoch 783\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4971 - accuracy: 0.8151 - val_loss: 4.2023 - val_accuracy: 0.5247\n",
      "Epoch 784\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4711 - accuracy: 0.8226 - val_loss: 4.2164 - val_accuracy: 0.5247\n",
      "Epoch 785\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.5260 - accuracy: 0.8065 - val_loss: 4.2354 - val_accuracy: 0.5355\n",
      "Epoch 786\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.5659 - accuracy: 0.8075 - val_loss: 4.2474 - val_accuracy: 0.5247\n",
      "Epoch 787\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.6194 - accuracy: 0.7860 - val_loss: 4.2421 - val_accuracy: 0.5247\n",
      "Epoch 788\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.5519 - accuracy: 0.8032 - val_loss: 4.2263 - val_accuracy: 0.5290\n",
      "Epoch 789\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.5545 - accuracy: 0.8032 - val_loss: 4.1935 - val_accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.5466 - accuracy: 0.8032 - val_loss: 4.1897 - val_accuracy: 0.5204\n",
      "Epoch 791\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.6069 - accuracy: 0.7710 - val_loss: 4.1934 - val_accuracy: 0.5247\n",
      "Epoch 792\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.5318 - accuracy: 0.7978 - val_loss: 4.1888 - val_accuracy: 0.5204\n",
      "Epoch 793\n",
      "3/3 [==============================] - 3s 553ms/step - loss: 2.5165 - accuracy: 0.8118 - val_loss: 4.1845 - val_accuracy: 0.5376\n",
      "Epoch 794\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.5399 - accuracy: 0.7903 - val_loss: 4.1801 - val_accuracy: 0.5247\n",
      "Epoch 795\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5449 - accuracy: 0.7892 - val_loss: 4.1894 - val_accuracy: 0.5333\n",
      "Epoch 796\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.5133 - accuracy: 0.8032 - val_loss: 4.1883 - val_accuracy: 0.5312\n",
      "Epoch 797\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 2.5763 - accuracy: 0.7871 - val_loss: 4.1957 - val_accuracy: 0.5333\n",
      "Epoch 798\n",
      "3/3 [==============================] - 3s 557ms/step - loss: 2.5622 - accuracy: 0.7903 - val_loss: 4.1895 - val_accuracy: 0.5419\n",
      "Epoch 799\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.5764 - accuracy: 0.7989 - val_loss: 4.1881 - val_accuracy: 0.5505\n",
      "Epoch 800\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.5310 - accuracy: 0.7935 - val_loss: 4.1743 - val_accuracy: 0.5419\n",
      "Epoch 801\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 2.4167 - accuracy: 0.8258 - val_loss: 4.2119 - val_accuracy: 0.5269\n",
      "Epoch 802\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.4507 - accuracy: 0.8269 - val_loss: 4.2431 - val_accuracy: 0.5161\n",
      "Epoch 803\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.5493 - accuracy: 0.8151 - val_loss: 4.2734 - val_accuracy: 0.5226\n",
      "Epoch 804\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.5572 - accuracy: 0.7925 - val_loss: 4.2737 - val_accuracy: 0.5118\n",
      "Epoch 805\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.5662 - accuracy: 0.8000 - val_loss: 4.2477 - val_accuracy: 0.5204\n",
      "Epoch 806\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.5255 - accuracy: 0.7903 - val_loss: 4.2341 - val_accuracy: 0.5269\n",
      "Epoch 807\n",
      "3/3 [==============================] - 3s 697ms/step - loss: 2.5414 - accuracy: 0.7892 - val_loss: 4.2230 - val_accuracy: 0.5269\n",
      "Epoch 808\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.6051 - accuracy: 0.8043 - val_loss: 4.2017 - val_accuracy: 0.5312\n",
      "Epoch 809\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.5440 - accuracy: 0.8108 - val_loss: 4.2049 - val_accuracy: 0.5247\n",
      "Epoch 810\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.5641 - accuracy: 0.7957 - val_loss: 4.2170 - val_accuracy: 0.5247\n",
      "Epoch 811\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5012 - accuracy: 0.8022 - val_loss: 4.2087 - val_accuracy: 0.5204\n",
      "Epoch 812\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.4487 - accuracy: 0.8258 - val_loss: 4.2100 - val_accuracy: 0.5269\n",
      "Epoch 813\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.6002 - accuracy: 0.7828 - val_loss: 4.2131 - val_accuracy: 0.5226\n",
      "Epoch 814\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.5088 - accuracy: 0.8000 - val_loss: 4.2250 - val_accuracy: 0.5140\n",
      "Epoch 815\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.5182 - accuracy: 0.8000 - val_loss: 4.2244 - val_accuracy: 0.5226\n",
      "Epoch 816\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.5075 - accuracy: 0.8075 - val_loss: 4.2397 - val_accuracy: 0.5247\n",
      "Epoch 817\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.5994 - accuracy: 0.7871 - val_loss: 4.2228 - val_accuracy: 0.5355\n",
      "Epoch 818\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.5259 - accuracy: 0.8097 - val_loss: 4.2034 - val_accuracy: 0.5312\n",
      "Epoch 819\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 2.5724 - accuracy: 0.7946 - val_loss: 4.1670 - val_accuracy: 0.5290\n",
      "Epoch 820\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 2.5438 - accuracy: 0.7957 - val_loss: 4.1424 - val_accuracy: 0.5183\n",
      "Epoch 821\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.4421 - accuracy: 0.8140 - val_loss: 4.1481 - val_accuracy: 0.5312\n",
      "Epoch 822\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.5896 - accuracy: 0.7731 - val_loss: 4.1631 - val_accuracy: 0.5269\n",
      "Epoch 823\n",
      "3/3 [==============================] - 3s 552ms/step - loss: 2.5619 - accuracy: 0.7860 - val_loss: 4.1691 - val_accuracy: 0.5333\n",
      "Epoch 824\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.5275 - accuracy: 0.8043 - val_loss: 4.1634 - val_accuracy: 0.5290\n",
      "Epoch 825\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 2.4669 - accuracy: 0.8161 - val_loss: 4.1546 - val_accuracy: 0.5269\n",
      "Epoch 826\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.5542 - accuracy: 0.7860 - val_loss: 4.1341 - val_accuracy: 0.5204\n",
      "Epoch 827\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.4639 - accuracy: 0.8108 - val_loss: 4.1306 - val_accuracy: 0.5161\n",
      "Epoch 828\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.4932 - accuracy: 0.8043 - val_loss: 4.1365 - val_accuracy: 0.5161\n",
      "Epoch 829\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.5380 - accuracy: 0.8000 - val_loss: 4.1585 - val_accuracy: 0.5183\n",
      "Epoch 830\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.5434 - accuracy: 0.8000 - val_loss: 4.1835 - val_accuracy: 0.5204\n",
      "Epoch 831\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 2.4909 - accuracy: 0.8129 - val_loss: 4.1962 - val_accuracy: 0.5075\n",
      "Epoch 832\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4417 - accuracy: 0.8323 - val_loss: 4.1776 - val_accuracy: 0.5140\n",
      "Epoch 833\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.5032 - accuracy: 0.7817 - val_loss: 4.1505 - val_accuracy: 0.5075\n",
      "Epoch 834\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.4849 - accuracy: 0.8215 - val_loss: 4.1270 - val_accuracy: 0.5226\n",
      "Epoch 835\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.4973 - accuracy: 0.8022 - val_loss: 4.0934 - val_accuracy: 0.5312\n",
      "Epoch 836\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.4624 - accuracy: 0.8172 - val_loss: 4.0425 - val_accuracy: 0.5398\n",
      "Epoch 837\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.5342 - accuracy: 0.7871 - val_loss: 4.0106 - val_accuracy: 0.5398\n",
      "Epoch 838\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.4437 - accuracy: 0.8000 - val_loss: 4.0075 - val_accuracy: 0.5376\n",
      "Epoch 839\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.6565 - accuracy: 0.7591 - val_loss: 3.9901 - val_accuracy: 0.5419\n",
      "Epoch 840\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.5786 - accuracy: 0.7914 - val_loss: 4.0002 - val_accuracy: 0.5462\n",
      "Epoch 841\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.5616 - accuracy: 0.7774 - val_loss: 4.0487 - val_accuracy: 0.5419\n",
      "Epoch 842\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.4458 - accuracy: 0.8097 - val_loss: 4.0788 - val_accuracy: 0.5462\n",
      "Epoch 843\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5356 - accuracy: 0.7935 - val_loss: 4.0940 - val_accuracy: 0.5376\n",
      "Epoch 844\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.5486 - accuracy: 0.7849 - val_loss: 4.1159 - val_accuracy: 0.5355\n",
      "Epoch 845\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.5431 - accuracy: 0.7828 - val_loss: 4.1054 - val_accuracy: 0.5419\n",
      "Epoch 846\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.5707 - accuracy: 0.7774 - val_loss: 4.0641 - val_accuracy: 0.5398\n",
      "Epoch 847\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.5045 - accuracy: 0.8043 - val_loss: 4.0413 - val_accuracy: 0.5398\n",
      "Epoch 848\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 2.5228 - accuracy: 0.8011 - val_loss: 4.0337 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.4158 - accuracy: 0.8161 - val_loss: 4.0231 - val_accuracy: 0.5290\n",
      "Epoch 850\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.4745 - accuracy: 0.7946 - val_loss: 4.0421 - val_accuracy: 0.5247\n",
      "Epoch 851\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5041 - accuracy: 0.8054 - val_loss: 4.0755 - val_accuracy: 0.5312\n",
      "Epoch 852\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.4912 - accuracy: 0.8108 - val_loss: 4.1241 - val_accuracy: 0.5333\n",
      "Epoch 853\n",
      "3/3 [==============================] - 3s 715ms/step - loss: 2.5516 - accuracy: 0.7828 - val_loss: 4.1297 - val_accuracy: 0.5355\n",
      "Epoch 854\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.5230 - accuracy: 0.7946 - val_loss: 4.1301 - val_accuracy: 0.5398\n",
      "Epoch 855\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.4807 - accuracy: 0.8011 - val_loss: 4.1095 - val_accuracy: 0.5333\n",
      "Epoch 856\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.4867 - accuracy: 0.7968 - val_loss: 4.1105 - val_accuracy: 0.5355\n",
      "Epoch 857\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.5243 - accuracy: 0.7860 - val_loss: 4.1341 - val_accuracy: 0.5376\n",
      "Epoch 858\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.4345 - accuracy: 0.8151 - val_loss: 4.1577 - val_accuracy: 0.5290\n",
      "Epoch 859\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.5900 - accuracy: 0.7677 - val_loss: 4.1785 - val_accuracy: 0.5183\n",
      "Epoch 860\n",
      "3/3 [==============================] - 3s 762ms/step - loss: 2.4550 - accuracy: 0.8097 - val_loss: 4.1945 - val_accuracy: 0.5118\n",
      "Epoch 861\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.5743 - accuracy: 0.7914 - val_loss: 4.1913 - val_accuracy: 0.5054\n",
      "Epoch 862\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5305 - accuracy: 0.7989 - val_loss: 4.1928 - val_accuracy: 0.5161\n",
      "Epoch 863\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.5356 - accuracy: 0.8022 - val_loss: 4.1860 - val_accuracy: 0.5247\n",
      "Epoch 864\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.5326 - accuracy: 0.8118 - val_loss: 4.1634 - val_accuracy: 0.5226\n",
      "Epoch 865\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.4534 - accuracy: 0.8226 - val_loss: 4.1748 - val_accuracy: 0.5054\n",
      "Epoch 866\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.5496 - accuracy: 0.7903 - val_loss: 4.2000 - val_accuracy: 0.5097\n",
      "Epoch 867\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.5681 - accuracy: 0.7871 - val_loss: 4.2051 - val_accuracy: 0.4946\n",
      "Epoch 868\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.5183 - accuracy: 0.7925 - val_loss: 4.2301 - val_accuracy: 0.4989\n",
      "Epoch 869\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.5009 - accuracy: 0.7871 - val_loss: 4.2685 - val_accuracy: 0.5011\n",
      "Epoch 870\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.5043 - accuracy: 0.7978 - val_loss: 4.2711 - val_accuracy: 0.5011\n",
      "Epoch 871\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.4418 - accuracy: 0.8204 - val_loss: 4.2494 - val_accuracy: 0.5011\n",
      "Epoch 872\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.4687 - accuracy: 0.8118 - val_loss: 4.2351 - val_accuracy: 0.5118\n",
      "Epoch 873\n",
      "3/3 [==============================] - 3s 703ms/step - loss: 2.4142 - accuracy: 0.8226 - val_loss: 4.2547 - val_accuracy: 0.5140\n",
      "Epoch 874\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.6011 - accuracy: 0.7796 - val_loss: 4.2545 - val_accuracy: 0.5204\n",
      "Epoch 875\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 2.4403 - accuracy: 0.8226 - val_loss: 4.2603 - val_accuracy: 0.5290\n",
      "Epoch 876\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5079 - accuracy: 0.7914 - val_loss: 4.2421 - val_accuracy: 0.5333\n",
      "Epoch 877\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.5290 - accuracy: 0.7957 - val_loss: 4.2283 - val_accuracy: 0.5247\n",
      "Epoch 878\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.5410 - accuracy: 0.7978 - val_loss: 4.2257 - val_accuracy: 0.5161\n",
      "Epoch 879\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 2.5536 - accuracy: 0.7742 - val_loss: 4.2091 - val_accuracy: 0.5140\n",
      "Epoch 880\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 2.3934 - accuracy: 0.8204 - val_loss: 4.1941 - val_accuracy: 0.5269\n",
      "Epoch 881\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.5378 - accuracy: 0.7903 - val_loss: 4.2098 - val_accuracy: 0.5226\n",
      "Epoch 882\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4631 - accuracy: 0.8108 - val_loss: 4.2094 - val_accuracy: 0.5269\n",
      "Epoch 883\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.5127 - accuracy: 0.7989 - val_loss: 4.2175 - val_accuracy: 0.5140\n",
      "Epoch 884\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.4716 - accuracy: 0.7914 - val_loss: 4.2301 - val_accuracy: 0.5032\n",
      "Epoch 885\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.4892 - accuracy: 0.8054 - val_loss: 4.2185 - val_accuracy: 0.5097\n",
      "Epoch 886\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4876 - accuracy: 0.8000 - val_loss: 4.2112 - val_accuracy: 0.5204\n",
      "Epoch 887\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.5814 - accuracy: 0.7957 - val_loss: 4.1844 - val_accuracy: 0.5290\n",
      "Epoch 888\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 2.5491 - accuracy: 0.7946 - val_loss: 4.1800 - val_accuracy: 0.5376\n",
      "Epoch 889\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.5151 - accuracy: 0.7882 - val_loss: 4.1779 - val_accuracy: 0.5312\n",
      "Epoch 890\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.4190 - accuracy: 0.8280 - val_loss: 4.1684 - val_accuracy: 0.5419\n",
      "Epoch 891\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.4541 - accuracy: 0.7968 - val_loss: 4.1824 - val_accuracy: 0.5376\n",
      "Epoch 892\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.4610 - accuracy: 0.7935 - val_loss: 4.1941 - val_accuracy: 0.5226\n",
      "Epoch 893\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.5906 - accuracy: 0.7710 - val_loss: 4.1879 - val_accuracy: 0.5140\n",
      "Epoch 894\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.4971 - accuracy: 0.8054 - val_loss: 4.1764 - val_accuracy: 0.5075\n",
      "Epoch 895\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4570 - accuracy: 0.8172 - val_loss: 4.1603 - val_accuracy: 0.5032\n",
      "Epoch 896\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4791 - accuracy: 0.8097 - val_loss: 4.1561 - val_accuracy: 0.5226\n",
      "Epoch 897\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.5871 - accuracy: 0.7849 - val_loss: 4.1757 - val_accuracy: 0.5312\n",
      "Epoch 898\n",
      "3/3 [==============================] - 3s 569ms/step - loss: 2.4854 - accuracy: 0.8022 - val_loss: 4.1812 - val_accuracy: 0.5312\n",
      "Epoch 899\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.5203 - accuracy: 0.8011 - val_loss: 4.1809 - val_accuracy: 0.5398\n",
      "Epoch 900\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.4816 - accuracy: 0.8075 - val_loss: 4.2103 - val_accuracy: 0.5247\n",
      "Epoch 901\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.5648 - accuracy: 0.7871 - val_loss: 4.2179 - val_accuracy: 0.5204\n",
      "Epoch 902\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 2.5263 - accuracy: 0.7882 - val_loss: 4.2089 - val_accuracy: 0.5183\n",
      "Epoch 903\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.5084 - accuracy: 0.8043 - val_loss: 4.1918 - val_accuracy: 0.5140\n",
      "Epoch 904\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 2.5044 - accuracy: 0.7946 - val_loss: 4.1892 - val_accuracy: 0.5183\n",
      "Epoch 905\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.4029 - accuracy: 0.8118 - val_loss: 4.2112 - val_accuracy: 0.5204\n",
      "Epoch 906\n",
      "3/3 [==============================] - 3s 696ms/step - loss: 2.3911 - accuracy: 0.8215 - val_loss: 4.2627 - val_accuracy: 0.5204\n",
      "Epoch 907\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.4433 - accuracy: 0.7978 - val_loss: 4.3111 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 908\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.4192 - accuracy: 0.8247 - val_loss: 4.3292 - val_accuracy: 0.5183\n",
      "Epoch 909\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4601 - accuracy: 0.8054 - val_loss: 4.3217 - val_accuracy: 0.5269\n",
      "Epoch 910\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 2.4614 - accuracy: 0.8075 - val_loss: 4.2865 - val_accuracy: 0.5226\n",
      "Epoch 911\n",
      "3/3 [==============================] - 3s 790ms/step - loss: 2.4770 - accuracy: 0.8226 - val_loss: 4.2547 - val_accuracy: 0.5333\n",
      "Epoch 912\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.4944 - accuracy: 0.7903 - val_loss: 4.2262 - val_accuracy: 0.5419\n",
      "Epoch 913\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.5147 - accuracy: 0.7989 - val_loss: 4.1971 - val_accuracy: 0.5376\n",
      "Epoch 914\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.5137 - accuracy: 0.7914 - val_loss: 4.1561 - val_accuracy: 0.5118\n",
      "Epoch 915\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.5587 - accuracy: 0.7903 - val_loss: 4.1265 - val_accuracy: 0.5183\n",
      "Epoch 916\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.4740 - accuracy: 0.8000 - val_loss: 4.1258 - val_accuracy: 0.5161\n",
      "Epoch 917\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.4589 - accuracy: 0.7935 - val_loss: 4.1276 - val_accuracy: 0.5247\n",
      "Epoch 918\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 2.3944 - accuracy: 0.8161 - val_loss: 4.1163 - val_accuracy: 0.5226\n",
      "Epoch 919\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.4637 - accuracy: 0.8043 - val_loss: 4.1040 - val_accuracy: 0.5290\n",
      "Epoch 920\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.5835 - accuracy: 0.7892 - val_loss: 4.1067 - val_accuracy: 0.5333\n",
      "Epoch 921\n",
      "3/3 [==============================] - 3s 698ms/step - loss: 2.5369 - accuracy: 0.7946 - val_loss: 4.1060 - val_accuracy: 0.5312\n",
      "Epoch 922\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 2.5751 - accuracy: 0.7871 - val_loss: 4.0997 - val_accuracy: 0.5269\n",
      "Epoch 923\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 2.4508 - accuracy: 0.8097 - val_loss: 4.0833 - val_accuracy: 0.5355\n",
      "Epoch 924\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.4614 - accuracy: 0.8161 - val_loss: 4.0694 - val_accuracy: 0.5376\n",
      "Epoch 925\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 2.4739 - accuracy: 0.8151 - val_loss: 4.0398 - val_accuracy: 0.5376\n",
      "Epoch 926\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.4683 - accuracy: 0.8097 - val_loss: 4.0383 - val_accuracy: 0.5269\n",
      "Epoch 927\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.4884 - accuracy: 0.7839 - val_loss: 4.0689 - val_accuracy: 0.5183\n",
      "Epoch 928\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.4124 - accuracy: 0.8140 - val_loss: 4.0948 - val_accuracy: 0.5183\n",
      "Epoch 929\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.5039 - accuracy: 0.7968 - val_loss: 4.1165 - val_accuracy: 0.5204\n",
      "Epoch 930\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.3880 - accuracy: 0.8258 - val_loss: 4.1375 - val_accuracy: 0.5161\n",
      "Epoch 931\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.4985 - accuracy: 0.7925 - val_loss: 4.1465 - val_accuracy: 0.5054\n",
      "Epoch 932\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.4467 - accuracy: 0.7989 - val_loss: 4.1410 - val_accuracy: 0.5075\n",
      "Epoch 933\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.3737 - accuracy: 0.8129 - val_loss: 4.1540 - val_accuracy: 0.5183\n",
      "Epoch 934\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.4656 - accuracy: 0.8075 - val_loss: 4.1346 - val_accuracy: 0.5204\n",
      "Epoch 935\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.5229 - accuracy: 0.7817 - val_loss: 4.1218 - val_accuracy: 0.5204\n",
      "Epoch 936\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4016 - accuracy: 0.8161 - val_loss: 4.1049 - val_accuracy: 0.5247\n",
      "Epoch 937\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.3908 - accuracy: 0.8226 - val_loss: 4.1158 - val_accuracy: 0.5161\n",
      "Epoch 938\n",
      "3/3 [==============================] - 3s 697ms/step - loss: 2.5652 - accuracy: 0.7785 - val_loss: 4.1224 - val_accuracy: 0.5140\n",
      "Epoch 939\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.4043 - accuracy: 0.8247 - val_loss: 4.1225 - val_accuracy: 0.5226\n",
      "Epoch 940\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.4097 - accuracy: 0.8215 - val_loss: 4.1324 - val_accuracy: 0.5269\n",
      "Epoch 941\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.4681 - accuracy: 0.8054 - val_loss: 4.1365 - val_accuracy: 0.5226\n",
      "Epoch 942\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.4051 - accuracy: 0.8161 - val_loss: 4.1299 - val_accuracy: 0.5204\n",
      "Epoch 943\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.3794 - accuracy: 0.8161 - val_loss: 4.1550 - val_accuracy: 0.5161\n",
      "Epoch 944\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 2.5098 - accuracy: 0.7925 - val_loss: 4.1773 - val_accuracy: 0.5097\n",
      "Epoch 945\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.3915 - accuracy: 0.8129 - val_loss: 4.1954 - val_accuracy: 0.5011\n",
      "Epoch 946\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.4885 - accuracy: 0.7882 - val_loss: 4.2116 - val_accuracy: 0.5011\n",
      "Epoch 947\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.4034 - accuracy: 0.8097 - val_loss: 4.2185 - val_accuracy: 0.5140\n",
      "Epoch 948\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.4044 - accuracy: 0.8118 - val_loss: 4.1972 - val_accuracy: 0.5226\n",
      "Epoch 949\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.5186 - accuracy: 0.7957 - val_loss: 4.1641 - val_accuracy: 0.5140\n",
      "Epoch 950\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.3941 - accuracy: 0.8215 - val_loss: 4.1233 - val_accuracy: 0.5226\n",
      "Epoch 951\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 2.4239 - accuracy: 0.8161 - val_loss: 4.0862 - val_accuracy: 0.5376\n",
      "Epoch 952\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.4505 - accuracy: 0.8032 - val_loss: 4.0610 - val_accuracy: 0.5226\n",
      "Epoch 953\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 2.4840 - accuracy: 0.7935 - val_loss: 4.0620 - val_accuracy: 0.5247\n",
      "Epoch 954\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.4944 - accuracy: 0.7860 - val_loss: 4.0686 - val_accuracy: 0.5204\n",
      "Epoch 955\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.4097 - accuracy: 0.8000 - val_loss: 4.0829 - val_accuracy: 0.5204\n",
      "Epoch 956\n",
      "3/3 [==============================] - 3s 767ms/step - loss: 2.3941 - accuracy: 0.8118 - val_loss: 4.0991 - val_accuracy: 0.5204\n",
      "Epoch 957\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.5104 - accuracy: 0.8022 - val_loss: 4.1032 - val_accuracy: 0.5140\n",
      "Epoch 958\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.4145 - accuracy: 0.8129 - val_loss: 4.1057 - val_accuracy: 0.5183\n",
      "Epoch 959\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.5403 - accuracy: 0.7903 - val_loss: 4.1054 - val_accuracy: 0.5290\n",
      "Epoch 960\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.3531 - accuracy: 0.8172 - val_loss: 4.1159 - val_accuracy: 0.5247\n",
      "Epoch 961\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.3936 - accuracy: 0.8247 - val_loss: 4.1284 - val_accuracy: 0.5247\n",
      "Epoch 962\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.4444 - accuracy: 0.8000 - val_loss: 4.1022 - val_accuracy: 0.5226\n",
      "Epoch 963\n",
      "3/3 [==============================] - 3s 703ms/step - loss: 2.3760 - accuracy: 0.8237 - val_loss: 4.0668 - val_accuracy: 0.5290\n",
      "Epoch 964\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.4430 - accuracy: 0.8043 - val_loss: 4.0501 - val_accuracy: 0.5161\n",
      "Epoch 965\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.4811 - accuracy: 0.8032 - val_loss: 4.0535 - val_accuracy: 0.5097\n",
      "Epoch 966\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.3550 - accuracy: 0.8183 - val_loss: 4.0803 - val_accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967\n",
      "3/3 [==============================] - 3s 711ms/step - loss: 2.4154 - accuracy: 0.8043 - val_loss: 4.1469 - val_accuracy: 0.5161\n",
      "Epoch 968\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 2.4889 - accuracy: 0.7796 - val_loss: 4.1625 - val_accuracy: 0.5140\n",
      "Epoch 969\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3705 - accuracy: 0.8086 - val_loss: 4.1808 - val_accuracy: 0.5140\n",
      "Epoch 970\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 2.3856 - accuracy: 0.8419 - val_loss: 4.1850 - val_accuracy: 0.5161\n",
      "Epoch 971\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.4723 - accuracy: 0.7968 - val_loss: 4.1926 - val_accuracy: 0.5075\n",
      "Epoch 972\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.4727 - accuracy: 0.8086 - val_loss: 4.1844 - val_accuracy: 0.5118\n",
      "Epoch 973\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.4467 - accuracy: 0.7957 - val_loss: 4.1757 - val_accuracy: 0.5269\n",
      "Epoch 974\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.4492 - accuracy: 0.8000 - val_loss: 4.1650 - val_accuracy: 0.5247\n",
      "Epoch 975\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.4147 - accuracy: 0.8054 - val_loss: 4.1803 - val_accuracy: 0.5204\n",
      "Epoch 976\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.4191 - accuracy: 0.8172 - val_loss: 4.2010 - val_accuracy: 0.5161\n",
      "Epoch 977\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.4029 - accuracy: 0.8355 - val_loss: 4.2104 - val_accuracy: 0.5161\n",
      "Epoch 978\n",
      "3/3 [==============================] - 3s 772ms/step - loss: 2.3379 - accuracy: 0.8312 - val_loss: 4.2001 - val_accuracy: 0.5140\n",
      "Epoch 979\n",
      "3/3 [==============================] - 3s 572ms/step - loss: 2.4333 - accuracy: 0.8011 - val_loss: 4.1698 - val_accuracy: 0.5140\n",
      "Epoch 980\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.4585 - accuracy: 0.8032 - val_loss: 4.1410 - val_accuracy: 0.5183\n",
      "Epoch 981\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.4075 - accuracy: 0.8204 - val_loss: 4.1197 - val_accuracy: 0.5312\n",
      "Epoch 982\n",
      "3/3 [==============================] - 3s 710ms/step - loss: 2.4195 - accuracy: 0.7989 - val_loss: 4.1152 - val_accuracy: 0.5376\n",
      "Epoch 983\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.4498 - accuracy: 0.8118 - val_loss: 4.1143 - val_accuracy: 0.5333\n",
      "Epoch 984\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.3972 - accuracy: 0.8118 - val_loss: 4.1190 - val_accuracy: 0.5269\n",
      "Epoch 985\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4308 - accuracy: 0.8022 - val_loss: 4.1211 - val_accuracy: 0.5355\n",
      "Epoch 986\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.4612 - accuracy: 0.8194 - val_loss: 4.1244 - val_accuracy: 0.5333\n",
      "Epoch 987\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.4135 - accuracy: 0.8129 - val_loss: 4.1624 - val_accuracy: 0.5312\n",
      "Epoch 988\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.5318 - accuracy: 0.7796 - val_loss: 4.2112 - val_accuracy: 0.5355\n",
      "Epoch 989\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3711 - accuracy: 0.8280 - val_loss: 4.2275 - val_accuracy: 0.5183\n",
      "Epoch 990\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.4454 - accuracy: 0.8075 - val_loss: 4.2378 - val_accuracy: 0.5140\n",
      "Epoch 991\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3550 - accuracy: 0.8194 - val_loss: 4.2264 - val_accuracy: 0.5140\n",
      "Epoch 992\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.4096 - accuracy: 0.8140 - val_loss: 4.1771 - val_accuracy: 0.5161\n",
      "Epoch 993\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.3864 - accuracy: 0.8129 - val_loss: 4.1209 - val_accuracy: 0.5355\n",
      "Epoch 994\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.4528 - accuracy: 0.8172 - val_loss: 4.1018 - val_accuracy: 0.5290\n",
      "Epoch 995\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 2.3848 - accuracy: 0.8075 - val_loss: 4.1030 - val_accuracy: 0.5204\n",
      "Epoch 996\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.3629 - accuracy: 0.8258 - val_loss: 4.1232 - val_accuracy: 0.5312\n",
      "Epoch 997\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.3867 - accuracy: 0.8054 - val_loss: 4.1539 - val_accuracy: 0.5247\n",
      "Epoch 998\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.4986 - accuracy: 0.7935 - val_loss: 4.1520 - val_accuracy: 0.5204\n",
      "Epoch 999\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.4034 - accuracy: 0.8065 - val_loss: 4.1351 - val_accuracy: 0.5140\n",
      "Epoch 1000\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.3711 - accuracy: 0.8161 - val_loss: 4.1327 - val_accuracy: 0.5118\n",
      "Epoch 1001\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.3436 - accuracy: 0.8258 - val_loss: 4.1016 - val_accuracy: 0.5183\n",
      "Epoch 1002\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.3631 - accuracy: 0.8301 - val_loss: 4.0840 - val_accuracy: 0.5161\n",
      "Epoch 1003\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.4476 - accuracy: 0.8065 - val_loss: 4.0839 - val_accuracy: 0.5247\n",
      "Epoch 1004\n",
      "3/3 [==============================] - 3s 564ms/step - loss: 2.3448 - accuracy: 0.8140 - val_loss: 4.0872 - val_accuracy: 0.5183\n",
      "Epoch 1005\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.3608 - accuracy: 0.8086 - val_loss: 4.0925 - val_accuracy: 0.5204\n",
      "Epoch 1006\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.4423 - accuracy: 0.8108 - val_loss: 4.0785 - val_accuracy: 0.5247\n",
      "Epoch 1007\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4058 - accuracy: 0.8204 - val_loss: 4.0334 - val_accuracy: 0.5398\n",
      "Epoch 1008\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.4687 - accuracy: 0.8011 - val_loss: 4.0228 - val_accuracy: 0.5355\n",
      "Epoch 1009\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 2.3709 - accuracy: 0.8097 - val_loss: 4.0042 - val_accuracy: 0.5398\n",
      "Epoch 1010\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3656 - accuracy: 0.8108 - val_loss: 4.0069 - val_accuracy: 0.5355\n",
      "Epoch 1011\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.3087 - accuracy: 0.8183 - val_loss: 4.0218 - val_accuracy: 0.5333\n",
      "Epoch 1012\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3989 - accuracy: 0.8247 - val_loss: 4.0294 - val_accuracy: 0.5204\n",
      "Epoch 1013\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.4140 - accuracy: 0.8086 - val_loss: 4.0580 - val_accuracy: 0.5183\n",
      "Epoch 1014\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3763 - accuracy: 0.8226 - val_loss: 4.0880 - val_accuracy: 0.5204\n",
      "Epoch 1015\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4258 - accuracy: 0.8043 - val_loss: 4.1144 - val_accuracy: 0.5269\n",
      "Epoch 1016\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3388 - accuracy: 0.8204 - val_loss: 4.1372 - val_accuracy: 0.5290\n",
      "Epoch 1017\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 2.4291 - accuracy: 0.8022 - val_loss: 4.1867 - val_accuracy: 0.5312\n",
      "Epoch 1018\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.4513 - accuracy: 0.8054 - val_loss: 4.2259 - val_accuracy: 0.5118\n",
      "Epoch 1019\n",
      "3/3 [==============================] - 3s 554ms/step - loss: 2.3989 - accuracy: 0.8086 - val_loss: 4.2445 - val_accuracy: 0.5118\n",
      "Epoch 1020\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.4795 - accuracy: 0.7935 - val_loss: 4.2110 - val_accuracy: 0.5075\n",
      "Epoch 1021\n",
      "3/3 [==============================] - 3s 769ms/step - loss: 2.3931 - accuracy: 0.8043 - val_loss: 4.1420 - val_accuracy: 0.4903\n",
      "Epoch 1022\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.3434 - accuracy: 0.8258 - val_loss: 4.0985 - val_accuracy: 0.4839\n",
      "Epoch 1023\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.4489 - accuracy: 0.8065 - val_loss: 4.0841 - val_accuracy: 0.4968\n",
      "Epoch 1024\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.3984 - accuracy: 0.8043 - val_loss: 4.0895 - val_accuracy: 0.5011\n",
      "Epoch 1025\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.4103 - accuracy: 0.8204 - val_loss: 4.0832 - val_accuracy: 0.5032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.4697 - accuracy: 0.7946 - val_loss: 4.0791 - val_accuracy: 0.5140\n",
      "Epoch 1027\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.4908 - accuracy: 0.7957 - val_loss: 4.0903 - val_accuracy: 0.5204\n",
      "Epoch 1028\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.3975 - accuracy: 0.8075 - val_loss: 4.1107 - val_accuracy: 0.5204\n",
      "Epoch 1029\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4312 - accuracy: 0.8065 - val_loss: 4.1268 - val_accuracy: 0.5183\n",
      "Epoch 1030\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.4217 - accuracy: 0.8129 - val_loss: 4.1229 - val_accuracy: 0.5075\n",
      "Epoch 1031\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.4093 - accuracy: 0.8151 - val_loss: 4.1264 - val_accuracy: 0.4989\n",
      "Epoch 1032\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3426 - accuracy: 0.8118 - val_loss: 4.1074 - val_accuracy: 0.5075\n",
      "Epoch 1033\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.4327 - accuracy: 0.8151 - val_loss: 4.0867 - val_accuracy: 0.5290\n",
      "Epoch 1034\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.4077 - accuracy: 0.8194 - val_loss: 4.0933 - val_accuracy: 0.5355\n",
      "Epoch 1035\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.3654 - accuracy: 0.8290 - val_loss: 4.1260 - val_accuracy: 0.5355\n",
      "Epoch 1036\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.3785 - accuracy: 0.8204 - val_loss: 4.1616 - val_accuracy: 0.5312\n",
      "Epoch 1037\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.4306 - accuracy: 0.8097 - val_loss: 4.1851 - val_accuracy: 0.5312\n",
      "Epoch 1038\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.4218 - accuracy: 0.8011 - val_loss: 4.2018 - val_accuracy: 0.5333\n",
      "Epoch 1039\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.3884 - accuracy: 0.8172 - val_loss: 4.2075 - val_accuracy: 0.5333\n",
      "Epoch 1040\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.3544 - accuracy: 0.8151 - val_loss: 4.1847 - val_accuracy: 0.5290\n",
      "Epoch 1041\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 2.3291 - accuracy: 0.8237 - val_loss: 4.1730 - val_accuracy: 0.5355\n",
      "Epoch 1042\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4372 - accuracy: 0.8215 - val_loss: 4.1212 - val_accuracy: 0.5376\n",
      "Epoch 1043\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.4846 - accuracy: 0.7989 - val_loss: 4.0514 - val_accuracy: 0.5398\n",
      "Epoch 1044\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 2.4593 - accuracy: 0.8011 - val_loss: 4.0005 - val_accuracy: 0.5333\n",
      "Epoch 1045\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.4269 - accuracy: 0.8108 - val_loss: 3.9848 - val_accuracy: 0.5441\n",
      "Epoch 1046\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.4644 - accuracy: 0.8108 - val_loss: 3.9920 - val_accuracy: 0.5376\n",
      "Epoch 1047\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.4099 - accuracy: 0.7989 - val_loss: 4.0140 - val_accuracy: 0.5484\n",
      "Epoch 1048\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4144 - accuracy: 0.7968 - val_loss: 4.0359 - val_accuracy: 0.5419\n",
      "Epoch 1049\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.3415 - accuracy: 0.8151 - val_loss: 4.0677 - val_accuracy: 0.5333\n",
      "Epoch 1050\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.3792 - accuracy: 0.8032 - val_loss: 4.0940 - val_accuracy: 0.5290\n",
      "Epoch 1051\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3753 - accuracy: 0.8161 - val_loss: 4.0874 - val_accuracy: 0.5312\n",
      "Epoch 1052\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.3889 - accuracy: 0.8161 - val_loss: 4.0940 - val_accuracy: 0.5269\n",
      "Epoch 1053\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 2.4462 - accuracy: 0.8054 - val_loss: 4.1063 - val_accuracy: 0.5247\n",
      "Epoch 1054\n",
      "3/3 [==============================] - 3s 709ms/step - loss: 2.3640 - accuracy: 0.8194 - val_loss: 4.0985 - val_accuracy: 0.5312\n",
      "Epoch 1055\n",
      "3/3 [==============================] - 3s 692ms/step - loss: 2.2700 - accuracy: 0.8355 - val_loss: 4.0871 - val_accuracy: 0.5290\n",
      "Epoch 1056\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.3684 - accuracy: 0.8172 - val_loss: 4.0754 - val_accuracy: 0.5204\n",
      "Epoch 1057\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.4115 - accuracy: 0.8086 - val_loss: 4.0573 - val_accuracy: 0.5247\n",
      "Epoch 1058\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.4228 - accuracy: 0.8161 - val_loss: 4.0958 - val_accuracy: 0.5204\n",
      "Epoch 1059\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.4069 - accuracy: 0.8161 - val_loss: 4.1587 - val_accuracy: 0.5161\n",
      "Epoch 1060\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3142 - accuracy: 0.8366 - val_loss: 4.2270 - val_accuracy: 0.5269\n",
      "Epoch 1061\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 2.4002 - accuracy: 0.8032 - val_loss: 4.2684 - val_accuracy: 0.5290\n",
      "Epoch 1062\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.3980 - accuracy: 0.8183 - val_loss: 4.2813 - val_accuracy: 0.5290\n",
      "Epoch 1063\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 2.3944 - accuracy: 0.8441 - val_loss: 4.2591 - val_accuracy: 0.5204\n",
      "Epoch 1064\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.3866 - accuracy: 0.8226 - val_loss: 4.2308 - val_accuracy: 0.5183\n",
      "Epoch 1065\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.3317 - accuracy: 0.8398 - val_loss: 4.1951 - val_accuracy: 0.5204\n",
      "Epoch 1066\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.3727 - accuracy: 0.8108 - val_loss: 4.1271 - val_accuracy: 0.5290\n",
      "Epoch 1067\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.4344 - accuracy: 0.8161 - val_loss: 4.1043 - val_accuracy: 0.5441\n",
      "Epoch 1068\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 2.4457 - accuracy: 0.7882 - val_loss: 4.1267 - val_accuracy: 0.5462\n",
      "Epoch 1069\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.4092 - accuracy: 0.8151 - val_loss: 4.1500 - val_accuracy: 0.5312\n",
      "Epoch 1070\n",
      "3/3 [==============================] - 3s 772ms/step - loss: 2.3765 - accuracy: 0.8194 - val_loss: 4.1559 - val_accuracy: 0.5376\n",
      "Epoch 1071\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.3693 - accuracy: 0.8151 - val_loss: 4.1383 - val_accuracy: 0.5333\n",
      "Epoch 1072\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.4321 - accuracy: 0.8075 - val_loss: 4.1448 - val_accuracy: 0.5355\n",
      "Epoch 1073\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.3859 - accuracy: 0.8161 - val_loss: 4.1630 - val_accuracy: 0.5226\n",
      "Epoch 1074\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 2.3552 - accuracy: 0.8108 - val_loss: 4.1686 - val_accuracy: 0.5204\n",
      "Epoch 1075\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.3540 - accuracy: 0.8194 - val_loss: 4.1888 - val_accuracy: 0.5269\n",
      "Epoch 1076\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.3863 - accuracy: 0.8280 - val_loss: 4.2313 - val_accuracy: 0.5140\n",
      "Epoch 1077\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.3578 - accuracy: 0.8258 - val_loss: 4.2313 - val_accuracy: 0.5269\n",
      "Epoch 1078\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.4299 - accuracy: 0.8129 - val_loss: 4.2208 - val_accuracy: 0.5355\n",
      "Epoch 1079\n",
      "3/3 [==============================] - 3s 916ms/step - loss: 2.4017 - accuracy: 0.8183 - val_loss: 4.2131 - val_accuracy: 0.5355\n",
      "Epoch 1080\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.2858 - accuracy: 0.8333 - val_loss: 4.1839 - val_accuracy: 0.5398\n",
      "Epoch 1081\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3976 - accuracy: 0.8301 - val_loss: 4.1429 - val_accuracy: 0.5441\n",
      "Epoch 1082\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 2.3808 - accuracy: 0.8172 - val_loss: 4.1454 - val_accuracy: 0.5376\n",
      "Epoch 1083\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3293 - accuracy: 0.8151 - val_loss: 4.1714 - val_accuracy: 0.5226\n",
      "Epoch 1084\n",
      "3/3 [==============================] - 3s 698ms/step - loss: 2.3361 - accuracy: 0.8194 - val_loss: 4.1894 - val_accuracy: 0.5247\n",
      "Epoch 1085\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.4537 - accuracy: 0.7903 - val_loss: 4.1927 - val_accuracy: 0.5290\n",
      "Epoch 1086\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.3451 - accuracy: 0.8258 - val_loss: 4.2137 - val_accuracy: 0.5376\n",
      "Epoch 1087\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.4065 - accuracy: 0.8054 - val_loss: 4.2336 - val_accuracy: 0.5312\n",
      "Epoch 1088\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3633 - accuracy: 0.8151 - val_loss: 4.2417 - val_accuracy: 0.5312\n",
      "Epoch 1089\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.3327 - accuracy: 0.8194 - val_loss: 4.2614 - val_accuracy: 0.5312\n",
      "Epoch 1090\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.3701 - accuracy: 0.8075 - val_loss: 4.2941 - val_accuracy: 0.5226\n",
      "Epoch 1091\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.4861 - accuracy: 0.8054 - val_loss: 4.3411 - val_accuracy: 0.5204\n",
      "Epoch 1092\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3688 - accuracy: 0.8183 - val_loss: 4.3322 - val_accuracy: 0.5204\n",
      "Epoch 1093\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.3857 - accuracy: 0.8043 - val_loss: 4.3044 - val_accuracy: 0.5247\n",
      "Epoch 1094\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.4059 - accuracy: 0.8204 - val_loss: 4.2880 - val_accuracy: 0.5269\n",
      "Epoch 1095\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.3709 - accuracy: 0.8118 - val_loss: 4.3063 - val_accuracy: 0.5247\n",
      "Epoch 1096\n",
      "3/3 [==============================] - 3s 807ms/step - loss: 2.3823 - accuracy: 0.8247 - val_loss: 4.3021 - val_accuracy: 0.5183\n",
      "Epoch 1097\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.3771 - accuracy: 0.8086 - val_loss: 4.2916 - val_accuracy: 0.5140\n",
      "Epoch 1098\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.3105 - accuracy: 0.8312 - val_loss: 4.2594 - val_accuracy: 0.5161\n",
      "Epoch 1099\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.3634 - accuracy: 0.8226 - val_loss: 4.2491 - val_accuracy: 0.5054\n",
      "Epoch 1100\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4913 - accuracy: 0.7946 - val_loss: 4.2623 - val_accuracy: 0.5011\n",
      "Epoch 1101\n",
      "3/3 [==============================] - 3s 571ms/step - loss: 2.2911 - accuracy: 0.8204 - val_loss: 4.2747 - val_accuracy: 0.5097\n",
      "Epoch 1102\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3534 - accuracy: 0.8183 - val_loss: 4.2754 - val_accuracy: 0.5097\n",
      "Epoch 1103\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3738 - accuracy: 0.8129 - val_loss: 4.2601 - val_accuracy: 0.5011\n",
      "Epoch 1104\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.4470 - accuracy: 0.7946 - val_loss: 4.2778 - val_accuracy: 0.4946\n",
      "Epoch 1105\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.2621 - accuracy: 0.8344 - val_loss: 4.2846 - val_accuracy: 0.5032\n",
      "Epoch 1106\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.3490 - accuracy: 0.8075 - val_loss: 4.2794 - val_accuracy: 0.4968\n",
      "Epoch 1107\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.3391 - accuracy: 0.8194 - val_loss: 4.2627 - val_accuracy: 0.4968\n",
      "Epoch 1108\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.3904 - accuracy: 0.8161 - val_loss: 4.2416 - val_accuracy: 0.4925\n",
      "Epoch 1109\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.2669 - accuracy: 0.8290 - val_loss: 4.2382 - val_accuracy: 0.4946\n",
      "Epoch 1110\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.3936 - accuracy: 0.8086 - val_loss: 4.2007 - val_accuracy: 0.5097\n",
      "Epoch 1111\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3191 - accuracy: 0.8290 - val_loss: 4.1926 - val_accuracy: 0.5183\n",
      "Epoch 1112\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3947 - accuracy: 0.8075 - val_loss: 4.2031 - val_accuracy: 0.5204\n",
      "Epoch 1113\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.3136 - accuracy: 0.8237 - val_loss: 4.2203 - val_accuracy: 0.5161\n",
      "Epoch 1114\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.3548 - accuracy: 0.8215 - val_loss: 4.2162 - val_accuracy: 0.5161\n",
      "Epoch 1115\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 2.3979 - accuracy: 0.8194 - val_loss: 4.1913 - val_accuracy: 0.4989\n",
      "Epoch 1116\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.3541 - accuracy: 0.8118 - val_loss: 4.1781 - val_accuracy: 0.4860\n",
      "Epoch 1117\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.2860 - accuracy: 0.8301 - val_loss: 4.1795 - val_accuracy: 0.4925\n",
      "Epoch 1118\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.3853 - accuracy: 0.8183 - val_loss: 4.1897 - val_accuracy: 0.5054\n",
      "Epoch 1119\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.3027 - accuracy: 0.8247 - val_loss: 4.1959 - val_accuracy: 0.4946\n",
      "Epoch 1120\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.3427 - accuracy: 0.8301 - val_loss: 4.1929 - val_accuracy: 0.5075\n",
      "Epoch 1121\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.2753 - accuracy: 0.8355 - val_loss: 4.1934 - val_accuracy: 0.5118\n",
      "Epoch 1122\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3558 - accuracy: 0.8054 - val_loss: 4.2350 - val_accuracy: 0.5226\n",
      "Epoch 1123\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.3406 - accuracy: 0.8280 - val_loss: 4.2793 - val_accuracy: 0.5140\n",
      "Epoch 1124\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.4418 - accuracy: 0.8108 - val_loss: 4.3035 - val_accuracy: 0.5118\n",
      "Epoch 1125\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.4383 - accuracy: 0.8247 - val_loss: 4.2972 - val_accuracy: 0.5011\n",
      "Epoch 1126\n",
      "3/3 [==============================] - 3s 781ms/step - loss: 2.3578 - accuracy: 0.8129 - val_loss: 4.2784 - val_accuracy: 0.4968\n",
      "Epoch 1127\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.4660 - accuracy: 0.7914 - val_loss: 4.2256 - val_accuracy: 0.4989\n",
      "Epoch 1128\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.3298 - accuracy: 0.8376 - val_loss: 4.2106 - val_accuracy: 0.5054\n",
      "Epoch 1129\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.3232 - accuracy: 0.8258 - val_loss: 4.1950 - val_accuracy: 0.5183\n",
      "Epoch 1130\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.3713 - accuracy: 0.8204 - val_loss: 4.1800 - val_accuracy: 0.5226\n",
      "Epoch 1131\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.3382 - accuracy: 0.8108 - val_loss: 4.1526 - val_accuracy: 0.5226\n",
      "Epoch 1132\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.3801 - accuracy: 0.8118 - val_loss: 4.1125 - val_accuracy: 0.5161\n",
      "Epoch 1133\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.4037 - accuracy: 0.8097 - val_loss: 4.0917 - val_accuracy: 0.5204\n",
      "Epoch 1134\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.3424 - accuracy: 0.8269 - val_loss: 4.0944 - val_accuracy: 0.5032\n",
      "Epoch 1135\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.2855 - accuracy: 0.8269 - val_loss: 4.0968 - val_accuracy: 0.5054\n",
      "Epoch 1136\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.3463 - accuracy: 0.8172 - val_loss: 4.1120 - val_accuracy: 0.4989\n",
      "Epoch 1137\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.3124 - accuracy: 0.8323 - val_loss: 4.1227 - val_accuracy: 0.5097\n",
      "Epoch 1138\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4058 - accuracy: 0.8065 - val_loss: 4.1325 - val_accuracy: 0.5118\n",
      "Epoch 1139\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.3245 - accuracy: 0.8258 - val_loss: 4.1311 - val_accuracy: 0.5183\n",
      "Epoch 1140\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3970 - accuracy: 0.8194 - val_loss: 4.1479 - val_accuracy: 0.5183\n",
      "Epoch 1141\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3553 - accuracy: 0.8301 - val_loss: 4.1548 - val_accuracy: 0.5204\n",
      "Epoch 1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3291 - accuracy: 0.8323 - val_loss: 4.1476 - val_accuracy: 0.5118\n",
      "Epoch 1143\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.2967 - accuracy: 0.8194 - val_loss: 4.1506 - val_accuracy: 0.5097\n",
      "Epoch 1144\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.3688 - accuracy: 0.8129 - val_loss: 4.1631 - val_accuracy: 0.5032\n",
      "Epoch 1145\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.3390 - accuracy: 0.8301 - val_loss: 4.1746 - val_accuracy: 0.5075\n",
      "Epoch 1146\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.4125 - accuracy: 0.8108 - val_loss: 4.1766 - val_accuracy: 0.5011\n",
      "Epoch 1147\n",
      "3/3 [==============================] - 3s 570ms/step - loss: 2.3406 - accuracy: 0.8237 - val_loss: 4.1421 - val_accuracy: 0.5097\n",
      "Epoch 1148\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.3874 - accuracy: 0.8108 - val_loss: 4.1049 - val_accuracy: 0.5204\n",
      "Epoch 1149\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.2378 - accuracy: 0.8419 - val_loss: 4.0721 - val_accuracy: 0.5333\n",
      "Epoch 1150\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.2540 - accuracy: 0.8312 - val_loss: 4.0535 - val_accuracy: 0.5269\n",
      "Epoch 1151\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3106 - accuracy: 0.8366 - val_loss: 4.0530 - val_accuracy: 0.5355\n",
      "Epoch 1152\n",
      "3/3 [==============================] - 3s 557ms/step - loss: 2.4011 - accuracy: 0.8108 - val_loss: 4.0453 - val_accuracy: 0.5269\n",
      "Epoch 1153\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3671 - accuracy: 0.7914 - val_loss: 4.0327 - val_accuracy: 0.5269\n",
      "Epoch 1154\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.2796 - accuracy: 0.8387 - val_loss: 4.0467 - val_accuracy: 0.5183\n",
      "Epoch 1155\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.3286 - accuracy: 0.8226 - val_loss: 4.0726 - val_accuracy: 0.5011\n",
      "Epoch 1156\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.3842 - accuracy: 0.7957 - val_loss: 4.0764 - val_accuracy: 0.4989\n",
      "Epoch 1157\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.3652 - accuracy: 0.8129 - val_loss: 4.0687 - val_accuracy: 0.5075\n",
      "Epoch 1158\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.2543 - accuracy: 0.8290 - val_loss: 4.1038 - val_accuracy: 0.5183\n",
      "Epoch 1159\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.3590 - accuracy: 0.8140 - val_loss: 4.1565 - val_accuracy: 0.5269\n",
      "Epoch 1160\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.3680 - accuracy: 0.8129 - val_loss: 4.1874 - val_accuracy: 0.5161\n",
      "Epoch 1161\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.3604 - accuracy: 0.8237 - val_loss: 4.2022 - val_accuracy: 0.5204\n",
      "Epoch 1162\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3289 - accuracy: 0.8355 - val_loss: 4.1972 - val_accuracy: 0.5333\n",
      "Epoch 1163\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 2.3150 - accuracy: 0.8237 - val_loss: 4.1676 - val_accuracy: 0.5183\n",
      "Epoch 1164\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.4053 - accuracy: 0.8183 - val_loss: 4.1553 - val_accuracy: 0.5075\n",
      "Epoch 1165\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.2708 - accuracy: 0.8355 - val_loss: 4.1200 - val_accuracy: 0.5183\n",
      "Epoch 1166\n",
      "3/3 [==============================] - 3s 712ms/step - loss: 2.2969 - accuracy: 0.8398 - val_loss: 4.1293 - val_accuracy: 0.5290\n",
      "Epoch 1167\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 2.3402 - accuracy: 0.8075 - val_loss: 4.1483 - val_accuracy: 0.5183\n",
      "Epoch 1168\n",
      "3/3 [==============================] - 3s 564ms/step - loss: 2.3520 - accuracy: 0.8129 - val_loss: 4.1419 - val_accuracy: 0.5247\n",
      "Epoch 1169\n",
      "3/3 [==============================] - 3s 701ms/step - loss: 2.3073 - accuracy: 0.8226 - val_loss: 4.1303 - val_accuracy: 0.5269\n",
      "Epoch 1170\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.3357 - accuracy: 0.8011 - val_loss: 4.1301 - val_accuracy: 0.5247\n",
      "Epoch 1171\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.2388 - accuracy: 0.8269 - val_loss: 4.1424 - val_accuracy: 0.5226\n",
      "Epoch 1172\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3747 - accuracy: 0.8247 - val_loss: 4.1630 - val_accuracy: 0.5419\n",
      "Epoch 1173\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.2266 - accuracy: 0.8473 - val_loss: 4.1950 - val_accuracy: 0.5312\n",
      "Epoch 1174\n",
      "3/3 [==============================] - 3s 766ms/step - loss: 2.3503 - accuracy: 0.8151 - val_loss: 4.2096 - val_accuracy: 0.5269\n",
      "Epoch 1175\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.3608 - accuracy: 0.8140 - val_loss: 4.1965 - val_accuracy: 0.5161\n",
      "Epoch 1176\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.3928 - accuracy: 0.8097 - val_loss: 4.1807 - val_accuracy: 0.5226\n",
      "Epoch 1177\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3653 - accuracy: 0.8290 - val_loss: 4.1896 - val_accuracy: 0.5054\n",
      "Epoch 1178\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3801 - accuracy: 0.8086 - val_loss: 4.1928 - val_accuracy: 0.5118\n",
      "Epoch 1179\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.3475 - accuracy: 0.8194 - val_loss: 4.2106 - val_accuracy: 0.5290\n",
      "Epoch 1180\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3619 - accuracy: 0.8140 - val_loss: 4.2085 - val_accuracy: 0.5312\n",
      "Epoch 1181\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.2779 - accuracy: 0.8280 - val_loss: 4.2087 - val_accuracy: 0.5355\n",
      "Epoch 1182\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.4048 - accuracy: 0.8000 - val_loss: 4.1940 - val_accuracy: 0.5441\n",
      "Epoch 1183\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.2863 - accuracy: 0.8376 - val_loss: 4.1782 - val_accuracy: 0.5419\n",
      "Epoch 1184\n",
      "3/3 [==============================] - 3s 572ms/step - loss: 2.2936 - accuracy: 0.8172 - val_loss: 4.1844 - val_accuracy: 0.5355\n",
      "Epoch 1185\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.3309 - accuracy: 0.8140 - val_loss: 4.1907 - val_accuracy: 0.5398\n",
      "Epoch 1186\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3303 - accuracy: 0.8226 - val_loss: 4.2130 - val_accuracy: 0.5398\n",
      "Epoch 1187\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3012 - accuracy: 0.8344 - val_loss: 4.2151 - val_accuracy: 0.5419\n",
      "Epoch 1188\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 2.2707 - accuracy: 0.8473 - val_loss: 4.1991 - val_accuracy: 0.5441\n",
      "Epoch 1189\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3095 - accuracy: 0.8215 - val_loss: 4.1769 - val_accuracy: 0.5355\n",
      "Epoch 1190\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.4297 - accuracy: 0.7968 - val_loss: 4.1755 - val_accuracy: 0.5247\n",
      "Epoch 1191\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3261 - accuracy: 0.8226 - val_loss: 4.1534 - val_accuracy: 0.5462\n",
      "Epoch 1192\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3195 - accuracy: 0.8312 - val_loss: 4.1388 - val_accuracy: 0.5462\n",
      "Epoch 1193\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.3234 - accuracy: 0.8269 - val_loss: 4.1473 - val_accuracy: 0.5355\n",
      "Epoch 1194\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.3181 - accuracy: 0.8290 - val_loss: 4.1652 - val_accuracy: 0.5333\n",
      "Epoch 1195\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 2.3603 - accuracy: 0.8258 - val_loss: 4.1935 - val_accuracy: 0.5333\n",
      "Epoch 1196\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3868 - accuracy: 0.8086 - val_loss: 4.2292 - val_accuracy: 0.5290\n",
      "Epoch 1197\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.3843 - accuracy: 0.8118 - val_loss: 4.2354 - val_accuracy: 0.5269\n",
      "Epoch 1198\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3587 - accuracy: 0.8118 - val_loss: 4.2263 - val_accuracy: 0.5161\n",
      "Epoch 1199\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.3720 - accuracy: 0.8344 - val_loss: 4.1839 - val_accuracy: 0.5376\n",
      "Epoch 1200\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.3084 - accuracy: 0.8290 - val_loss: 4.1743 - val_accuracy: 0.5441\n",
      "Epoch 1201\n",
      "3/3 [==============================] - 3s 710ms/step - loss: 2.2729 - accuracy: 0.8323 - val_loss: 4.1917 - val_accuracy: 0.5333\n",
      "Epoch 1202\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3348 - accuracy: 0.8172 - val_loss: 4.2188 - val_accuracy: 0.5140\n",
      "Epoch 1203\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3460 - accuracy: 0.8161 - val_loss: 4.2052 - val_accuracy: 0.5161\n",
      "Epoch 1204\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3997 - accuracy: 0.8108 - val_loss: 4.1944 - val_accuracy: 0.5247\n",
      "Epoch 1205\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 2.4235 - accuracy: 0.7957 - val_loss: 4.1814 - val_accuracy: 0.5312\n",
      "Epoch 1206\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3677 - accuracy: 0.8140 - val_loss: 4.1684 - val_accuracy: 0.5376\n",
      "Epoch 1207\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.3422 - accuracy: 0.8355 - val_loss: 4.1550 - val_accuracy: 0.5355\n",
      "Epoch 1208\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.3154 - accuracy: 0.8204 - val_loss: 4.1637 - val_accuracy: 0.5441\n",
      "Epoch 1209\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.3124 - accuracy: 0.8355 - val_loss: 4.1678 - val_accuracy: 0.5398\n",
      "Epoch 1210\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.3512 - accuracy: 0.8151 - val_loss: 4.1692 - val_accuracy: 0.5376\n",
      "Epoch 1211\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.4099 - accuracy: 0.8086 - val_loss: 4.1490 - val_accuracy: 0.5290\n",
      "Epoch 1212\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 2.4347 - accuracy: 0.8097 - val_loss: 4.1373 - val_accuracy: 0.5333\n",
      "Epoch 1213\n",
      "3/3 [==============================] - 3s 701ms/step - loss: 2.3805 - accuracy: 0.8172 - val_loss: 4.1157 - val_accuracy: 0.5484\n",
      "Epoch 1214\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3382 - accuracy: 0.8312 - val_loss: 4.1185 - val_accuracy: 0.5505\n",
      "Epoch 1215\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.3818 - accuracy: 0.8237 - val_loss: 4.1152 - val_accuracy: 0.5333\n",
      "Epoch 1216\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3348 - accuracy: 0.8409 - val_loss: 4.0937 - val_accuracy: 0.5419\n",
      "Epoch 1217\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.3476 - accuracy: 0.8204 - val_loss: 4.0748 - val_accuracy: 0.5462\n",
      "Epoch 1218\n",
      "3/3 [==============================] - 3s 702ms/step - loss: 2.3501 - accuracy: 0.8129 - val_loss: 4.1010 - val_accuracy: 0.5527\n",
      "Epoch 1219\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 2.3440 - accuracy: 0.8247 - val_loss: 4.1478 - val_accuracy: 0.5505\n",
      "Epoch 1220\n",
      "3/3 [==============================] - 3s 718ms/step - loss: 2.3134 - accuracy: 0.8301 - val_loss: 4.1852 - val_accuracy: 0.5398\n",
      "Epoch 1221\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.3339 - accuracy: 0.8290 - val_loss: 4.2023 - val_accuracy: 0.5441\n",
      "Epoch 1222\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.3215 - accuracy: 0.8280 - val_loss: 4.2121 - val_accuracy: 0.5355\n",
      "Epoch 1223\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.3661 - accuracy: 0.8312 - val_loss: 4.2361 - val_accuracy: 0.5505\n",
      "Epoch 1224\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3854 - accuracy: 0.8140 - val_loss: 4.2365 - val_accuracy: 0.5505\n",
      "Epoch 1225\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3943 - accuracy: 0.8043 - val_loss: 4.2219 - val_accuracy: 0.5505\n",
      "Epoch 1226\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.3092 - accuracy: 0.8430 - val_loss: 4.2440 - val_accuracy: 0.5441\n",
      "Epoch 1227\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.3857 - accuracy: 0.8172 - val_loss: 4.2280 - val_accuracy: 0.5376\n",
      "Epoch 1228\n",
      "3/3 [==============================] - 3s 555ms/step - loss: 2.3270 - accuracy: 0.8097 - val_loss: 4.2382 - val_accuracy: 0.5269\n",
      "Epoch 1229\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3618 - accuracy: 0.8183 - val_loss: 4.2469 - val_accuracy: 0.5290\n",
      "Epoch 1230\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3511 - accuracy: 0.8129 - val_loss: 4.2473 - val_accuracy: 0.5290\n",
      "Epoch 1231\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.2772 - accuracy: 0.8280 - val_loss: 4.2643 - val_accuracy: 0.5419\n",
      "Epoch 1232\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.3303 - accuracy: 0.8430 - val_loss: 4.3047 - val_accuracy: 0.5398\n",
      "Epoch 1233\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.2592 - accuracy: 0.8387 - val_loss: 4.3208 - val_accuracy: 0.5333\n",
      "Epoch 1234\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.3328 - accuracy: 0.8430 - val_loss: 4.2755 - val_accuracy: 0.5247\n",
      "Epoch 1235\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.3287 - accuracy: 0.8280 - val_loss: 4.2281 - val_accuracy: 0.5419\n",
      "Epoch 1236\n",
      "3/3 [==============================] - 3s 698ms/step - loss: 2.2643 - accuracy: 0.8409 - val_loss: 4.1943 - val_accuracy: 0.5462\n",
      "Epoch 1237\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.3513 - accuracy: 0.8237 - val_loss: 4.1702 - val_accuracy: 0.5355\n",
      "Epoch 1238\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.2790 - accuracy: 0.8441 - val_loss: 4.1628 - val_accuracy: 0.5226\n",
      "Epoch 1239\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.3763 - accuracy: 0.8129 - val_loss: 4.1558 - val_accuracy: 0.5398\n",
      "Epoch 1240\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.3106 - accuracy: 0.8323 - val_loss: 4.1549 - val_accuracy: 0.5548\n",
      "Epoch 1241\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.3525 - accuracy: 0.8097 - val_loss: 4.1442 - val_accuracy: 0.5570\n",
      "Epoch 1242\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 2.3139 - accuracy: 0.8183 - val_loss: 4.1382 - val_accuracy: 0.5484\n",
      "Epoch 1243\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3457 - accuracy: 0.8215 - val_loss: 4.1274 - val_accuracy: 0.5419\n",
      "Epoch 1244\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.4146 - accuracy: 0.8118 - val_loss: 4.1404 - val_accuracy: 0.5484\n",
      "Epoch 1245\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 2.3763 - accuracy: 0.8204 - val_loss: 4.1710 - val_accuracy: 0.5484\n",
      "Epoch 1246\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.3716 - accuracy: 0.8312 - val_loss: 4.2148 - val_accuracy: 0.5269\n",
      "Epoch 1247\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.3599 - accuracy: 0.8108 - val_loss: 4.2422 - val_accuracy: 0.5290\n",
      "Epoch 1248\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3029 - accuracy: 0.8301 - val_loss: 4.2548 - val_accuracy: 0.5183\n",
      "Epoch 1249\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3588 - accuracy: 0.8118 - val_loss: 4.2737 - val_accuracy: 0.5140\n",
      "Epoch 1250\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.3022 - accuracy: 0.8269 - val_loss: 4.2541 - val_accuracy: 0.5161\n",
      "Epoch 1251\n",
      "3/3 [==============================] - 3s 759ms/step - loss: 2.3080 - accuracy: 0.8312 - val_loss: 4.1843 - val_accuracy: 0.5462\n",
      "Epoch 1252\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3839 - accuracy: 0.8172 - val_loss: 4.1511 - val_accuracy: 0.5462\n",
      "Epoch 1253\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.3421 - accuracy: 0.8075 - val_loss: 4.1455 - val_accuracy: 0.5548\n",
      "Epoch 1254\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 2.4472 - accuracy: 0.8065 - val_loss: 4.1807 - val_accuracy: 0.5398\n",
      "Epoch 1255\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.3641 - accuracy: 0.8301 - val_loss: 4.1981 - val_accuracy: 0.5290\n",
      "Epoch 1256\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.2745 - accuracy: 0.8333 - val_loss: 4.2062 - val_accuracy: 0.5247\n",
      "Epoch 1257\n",
      "3/3 [==============================] - 3s 555ms/step - loss: 2.3754 - accuracy: 0.8344 - val_loss: 4.2214 - val_accuracy: 0.5183\n",
      "Epoch 1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 575ms/step - loss: 2.3265 - accuracy: 0.8183 - val_loss: 4.2422 - val_accuracy: 0.5247\n",
      "Epoch 1259\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3918 - accuracy: 0.8194 - val_loss: 4.2405 - val_accuracy: 0.5226\n",
      "Epoch 1260\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3989 - accuracy: 0.8204 - val_loss: 4.2207 - val_accuracy: 0.5183\n",
      "Epoch 1261\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.2903 - accuracy: 0.8226 - val_loss: 4.2024 - val_accuracy: 0.5183\n",
      "Epoch 1262\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3326 - accuracy: 0.8215 - val_loss: 4.2013 - val_accuracy: 0.5226\n",
      "Epoch 1263\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 2.3169 - accuracy: 0.8280 - val_loss: 4.2404 - val_accuracy: 0.5269\n",
      "Epoch 1264\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3882 - accuracy: 0.8258 - val_loss: 4.2692 - val_accuracy: 0.5075\n",
      "Epoch 1265\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3950 - accuracy: 0.8118 - val_loss: 4.2547 - val_accuracy: 0.5054\n",
      "Epoch 1266\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 2.3005 - accuracy: 0.8301 - val_loss: 4.2315 - val_accuracy: 0.5097\n",
      "Epoch 1267\n",
      "3/3 [==============================] - 3s 563ms/step - loss: 2.3805 - accuracy: 0.8075 - val_loss: 4.2307 - val_accuracy: 0.5118\n",
      "Epoch 1268\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3666 - accuracy: 0.8129 - val_loss: 4.2460 - val_accuracy: 0.4968\n",
      "Epoch 1269\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3613 - accuracy: 0.8151 - val_loss: 4.2365 - val_accuracy: 0.5161\n",
      "Epoch 1270\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.3602 - accuracy: 0.8140 - val_loss: 4.2160 - val_accuracy: 0.5161\n",
      "Epoch 1271\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3696 - accuracy: 0.8075 - val_loss: 4.1989 - val_accuracy: 0.5183\n",
      "Epoch 1272\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.4418 - accuracy: 0.8011 - val_loss: 4.1939 - val_accuracy: 0.5075\n",
      "Epoch 1273\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.3755 - accuracy: 0.8118 - val_loss: 4.1760 - val_accuracy: 0.5118\n",
      "Epoch 1274\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3087 - accuracy: 0.8333 - val_loss: 4.1618 - val_accuracy: 0.5161\n",
      "Epoch 1275\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.2769 - accuracy: 0.8323 - val_loss: 4.1912 - val_accuracy: 0.5140\n",
      "Epoch 1276\n",
      "3/3 [==============================] - 3s 703ms/step - loss: 2.3156 - accuracy: 0.8333 - val_loss: 4.2175 - val_accuracy: 0.5183\n",
      "Epoch 1277\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3178 - accuracy: 0.8204 - val_loss: 4.2422 - val_accuracy: 0.5097\n",
      "Epoch 1278\n",
      "3/3 [==============================] - 3s 556ms/step - loss: 2.4055 - accuracy: 0.8183 - val_loss: 4.2525 - val_accuracy: 0.5140\n",
      "Epoch 1279\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 2.3110 - accuracy: 0.8312 - val_loss: 4.2420 - val_accuracy: 0.5204\n",
      "Epoch 1280\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.2317 - accuracy: 0.8505 - val_loss: 4.2364 - val_accuracy: 0.5118\n",
      "Epoch 1281\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.3671 - accuracy: 0.8151 - val_loss: 4.2299 - val_accuracy: 0.5183\n",
      "Epoch 1282\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3357 - accuracy: 0.8301 - val_loss: 4.1984 - val_accuracy: 0.5312\n",
      "Epoch 1283\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.2982 - accuracy: 0.8269 - val_loss: 4.1845 - val_accuracy: 0.5419\n",
      "Epoch 1284\n",
      "3/3 [==============================] - 3s 701ms/step - loss: 2.3349 - accuracy: 0.8247 - val_loss: 4.1701 - val_accuracy: 0.5398\n",
      "Epoch 1285\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.3496 - accuracy: 0.8226 - val_loss: 4.1791 - val_accuracy: 0.5333\n",
      "Epoch 1286\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.3478 - accuracy: 0.8366 - val_loss: 4.2213 - val_accuracy: 0.5355\n",
      "Epoch 1287\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 2.3963 - accuracy: 0.8097 - val_loss: 4.2581 - val_accuracy: 0.5333\n",
      "Epoch 1288\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3514 - accuracy: 0.8333 - val_loss: 4.2973 - val_accuracy: 0.5183\n",
      "Epoch 1289\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.3172 - accuracy: 0.8355 - val_loss: 4.3218 - val_accuracy: 0.5075\n",
      "Epoch 1290\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.2930 - accuracy: 0.8419 - val_loss: 4.3061 - val_accuracy: 0.5054\n",
      "Epoch 1291\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 2.3784 - accuracy: 0.8129 - val_loss: 4.2934 - val_accuracy: 0.4968\n",
      "Epoch 1292\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.3273 - accuracy: 0.8118 - val_loss: 4.2746 - val_accuracy: 0.5032\n",
      "Epoch 1293\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3977 - accuracy: 0.8054 - val_loss: 4.2512 - val_accuracy: 0.5140\n",
      "Epoch 1294\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3254 - accuracy: 0.8323 - val_loss: 4.2693 - val_accuracy: 0.5118\n",
      "Epoch 1295\n",
      "3/3 [==============================] - 3s 573ms/step - loss: 2.4309 - accuracy: 0.7957 - val_loss: 4.2956 - val_accuracy: 0.5118\n",
      "Epoch 1296\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.2887 - accuracy: 0.8226 - val_loss: 4.3317 - val_accuracy: 0.5204\n",
      "Epoch 1297\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3665 - accuracy: 0.8269 - val_loss: 4.3707 - val_accuracy: 0.5204\n",
      "Epoch 1298\n",
      "3/3 [==============================] - 3s 792ms/step - loss: 2.3803 - accuracy: 0.8086 - val_loss: 4.4092 - val_accuracy: 0.5183\n",
      "Epoch 1299\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3289 - accuracy: 0.8247 - val_loss: 4.4065 - val_accuracy: 0.5204\n",
      "Epoch 1300\n",
      "3/3 [==============================] - 3s 718ms/step - loss: 2.3281 - accuracy: 0.8204 - val_loss: 4.3845 - val_accuracy: 0.5118\n",
      "Epoch 1301\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 2.3052 - accuracy: 0.8484 - val_loss: 4.3120 - val_accuracy: 0.5290\n",
      "Epoch 1302\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.3269 - accuracy: 0.8129 - val_loss: 4.2718 - val_accuracy: 0.5355\n",
      "Epoch 1303\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.3157 - accuracy: 0.8333 - val_loss: 4.2542 - val_accuracy: 0.5398\n",
      "Epoch 1304\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3501 - accuracy: 0.8280 - val_loss: 4.2803 - val_accuracy: 0.5333\n",
      "Epoch 1305\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.3507 - accuracy: 0.8301 - val_loss: 4.3087 - val_accuracy: 0.5333\n",
      "Epoch 1306\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.3337 - accuracy: 0.8269 - val_loss: 4.3406 - val_accuracy: 0.5312\n",
      "Epoch 1307\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.2651 - accuracy: 0.8505 - val_loss: 4.3568 - val_accuracy: 0.5376\n",
      "Epoch 1308\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.3397 - accuracy: 0.8172 - val_loss: 4.3200 - val_accuracy: 0.5333\n",
      "Epoch 1309\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3579 - accuracy: 0.8161 - val_loss: 4.2764 - val_accuracy: 0.5355\n",
      "Epoch 1310\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.4190 - accuracy: 0.8172 - val_loss: 4.2044 - val_accuracy: 0.5269\n",
      "Epoch 1311\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.4101 - accuracy: 0.8065 - val_loss: 4.1575 - val_accuracy: 0.5075\n",
      "Epoch 1312\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.4144 - accuracy: 0.7925 - val_loss: 4.1416 - val_accuracy: 0.5355\n",
      "Epoch 1313\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.3880 - accuracy: 0.8258 - val_loss: 4.1576 - val_accuracy: 0.5355\n",
      "Epoch 1314\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3269 - accuracy: 0.8226 - val_loss: 4.1543 - val_accuracy: 0.5269\n",
      "Epoch 1315\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.3869 - accuracy: 0.8215 - val_loss: 4.1351 - val_accuracy: 0.5097\n",
      "Epoch 1316\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.3459 - accuracy: 0.8312 - val_loss: 4.1281 - val_accuracy: 0.5204\n",
      "Epoch 1317\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3621 - accuracy: 0.8312 - val_loss: 4.1763 - val_accuracy: 0.5118\n",
      "Epoch 1318\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 2.3489 - accuracy: 0.8280 - val_loss: 4.2006 - val_accuracy: 0.5118\n",
      "Epoch 1319\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3043 - accuracy: 0.8409 - val_loss: 4.2188 - val_accuracy: 0.5183\n",
      "Epoch 1320\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3105 - accuracy: 0.8290 - val_loss: 4.2209 - val_accuracy: 0.5183\n",
      "Epoch 1321\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3767 - accuracy: 0.8258 - val_loss: 4.2130 - val_accuracy: 0.5333\n",
      "Epoch 1322\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.3365 - accuracy: 0.8323 - val_loss: 4.1764 - val_accuracy: 0.5376\n",
      "Epoch 1323\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.2836 - accuracy: 0.8366 - val_loss: 4.1453 - val_accuracy: 0.5333\n",
      "Epoch 1324\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3699 - accuracy: 0.8097 - val_loss: 4.1341 - val_accuracy: 0.5312\n",
      "Epoch 1325\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.3525 - accuracy: 0.8280 - val_loss: 4.1499 - val_accuracy: 0.5204\n",
      "Epoch 1326\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3055 - accuracy: 0.8269 - val_loss: 4.1895 - val_accuracy: 0.5161\n",
      "Epoch 1327\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.4065 - accuracy: 0.8086 - val_loss: 4.2122 - val_accuracy: 0.5226\n",
      "Epoch 1328\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3226 - accuracy: 0.8183 - val_loss: 4.2299 - val_accuracy: 0.5247\n",
      "Epoch 1329\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3512 - accuracy: 0.8097 - val_loss: 4.2201 - val_accuracy: 0.5247\n",
      "Epoch 1330\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.2102 - accuracy: 0.8505 - val_loss: 4.2007 - val_accuracy: 0.5290\n",
      "Epoch 1331\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.3202 - accuracy: 0.8366 - val_loss: 4.1973 - val_accuracy: 0.5290\n",
      "Epoch 1332\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.3221 - accuracy: 0.8355 - val_loss: 4.2080 - val_accuracy: 0.5204\n",
      "Epoch 1333\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3692 - accuracy: 0.8118 - val_loss: 4.1814 - val_accuracy: 0.5226\n",
      "Epoch 1334\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.2998 - accuracy: 0.8376 - val_loss: 4.1587 - val_accuracy: 0.5226\n",
      "Epoch 1335\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.3320 - accuracy: 0.8204 - val_loss: 4.1323 - val_accuracy: 0.5355\n",
      "Epoch 1336\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.3482 - accuracy: 0.8108 - val_loss: 4.0866 - val_accuracy: 0.5376\n",
      "Epoch 1337\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.2448 - accuracy: 0.8527 - val_loss: 4.0630 - val_accuracy: 0.5505\n",
      "Epoch 1338\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 2.3182 - accuracy: 0.8290 - val_loss: 4.0781 - val_accuracy: 0.5570\n",
      "Epoch 1339\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3093 - accuracy: 0.8376 - val_loss: 4.1298 - val_accuracy: 0.5570\n",
      "Epoch 1340\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.3984 - accuracy: 0.8129 - val_loss: 4.1683 - val_accuracy: 0.5462\n",
      "Epoch 1341\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.3118 - accuracy: 0.8312 - val_loss: 4.1910 - val_accuracy: 0.5290\n",
      "Epoch 1342\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.4356 - accuracy: 0.7892 - val_loss: 4.1849 - val_accuracy: 0.5247\n",
      "Epoch 1343\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.2982 - accuracy: 0.8247 - val_loss: 4.1839 - val_accuracy: 0.5183\n",
      "Epoch 1344\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.3271 - accuracy: 0.8226 - val_loss: 4.1791 - val_accuracy: 0.5269\n",
      "Epoch 1345\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.3854 - accuracy: 0.8172 - val_loss: 4.1621 - val_accuracy: 0.5484\n",
      "Epoch 1346\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3705 - accuracy: 0.8194 - val_loss: 4.1188 - val_accuracy: 0.5441\n",
      "Epoch 1347\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.3169 - accuracy: 0.8387 - val_loss: 4.0888 - val_accuracy: 0.5441\n",
      "Epoch 1348\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.3348 - accuracy: 0.8290 - val_loss: 4.0915 - val_accuracy: 0.5505\n",
      "Epoch 1349\n",
      "3/3 [==============================] - 3s 564ms/step - loss: 2.3574 - accuracy: 0.8140 - val_loss: 4.1052 - val_accuracy: 0.5591\n",
      "Epoch 1350\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.3860 - accuracy: 0.8108 - val_loss: 4.1210 - val_accuracy: 0.5484\n",
      "Epoch 1351\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.2790 - accuracy: 0.8280 - val_loss: 4.1441 - val_accuracy: 0.5376\n",
      "Epoch 1352\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.3359 - accuracy: 0.8204 - val_loss: 4.1621 - val_accuracy: 0.5290\n",
      "Epoch 1353\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3557 - accuracy: 0.8204 - val_loss: 4.1811 - val_accuracy: 0.5183\n",
      "Epoch 1354\n",
      "3/3 [==============================] - 3s 715ms/step - loss: 2.3878 - accuracy: 0.8161 - val_loss: 4.2026 - val_accuracy: 0.5247\n",
      "Epoch 1355\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.4424 - accuracy: 0.8075 - val_loss: 4.1872 - val_accuracy: 0.5226\n",
      "Epoch 1356\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 2.2461 - accuracy: 0.8462 - val_loss: 4.1639 - val_accuracy: 0.5161\n",
      "Epoch 1357\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.2888 - accuracy: 0.8247 - val_loss: 4.1584 - val_accuracy: 0.5075\n",
      "Epoch 1358\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3205 - accuracy: 0.8151 - val_loss: 4.1530 - val_accuracy: 0.5118\n",
      "Epoch 1359\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.3198 - accuracy: 0.8183 - val_loss: 4.1355 - val_accuracy: 0.5054\n",
      "Epoch 1360\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3692 - accuracy: 0.8237 - val_loss: 4.0927 - val_accuracy: 0.5247\n",
      "Epoch 1361\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.3335 - accuracy: 0.8312 - val_loss: 4.0530 - val_accuracy: 0.5376\n",
      "Epoch 1362\n",
      "3/3 [==============================] - 3s 711ms/step - loss: 2.3150 - accuracy: 0.8290 - val_loss: 4.0357 - val_accuracy: 0.5333\n",
      "Epoch 1363\n",
      "3/3 [==============================] - 3s 558ms/step - loss: 2.2993 - accuracy: 0.8355 - val_loss: 4.0242 - val_accuracy: 0.5484\n",
      "Epoch 1364\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3313 - accuracy: 0.8204 - val_loss: 4.0537 - val_accuracy: 0.5333\n",
      "Epoch 1365\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.3543 - accuracy: 0.8172 - val_loss: 4.0860 - val_accuracy: 0.5505\n",
      "Epoch 1366\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 2.3413 - accuracy: 0.8387 - val_loss: 4.1174 - val_accuracy: 0.5441\n",
      "Epoch 1367\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 2.2741 - accuracy: 0.8280 - val_loss: 4.0988 - val_accuracy: 0.5398\n",
      "Epoch 1368\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3114 - accuracy: 0.8183 - val_loss: 4.0574 - val_accuracy: 0.5290\n",
      "Epoch 1369\n",
      "3/3 [==============================] - 3s 717ms/step - loss: 2.3463 - accuracy: 0.8172 - val_loss: 4.0226 - val_accuracy: 0.5312\n",
      "Epoch 1370\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.3887 - accuracy: 0.8172 - val_loss: 4.0251 - val_accuracy: 0.5312\n",
      "Epoch 1371\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.3219 - accuracy: 0.8398 - val_loss: 4.0475 - val_accuracy: 0.5269\n",
      "Epoch 1372\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 2.4173 - accuracy: 0.8129 - val_loss: 4.0736 - val_accuracy: 0.5333\n",
      "Epoch 1373\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.2812 - accuracy: 0.8355 - val_loss: 4.1016 - val_accuracy: 0.5312\n",
      "Epoch 1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 627ms/step - loss: 2.3092 - accuracy: 0.8215 - val_loss: 4.1261 - val_accuracy: 0.5226\n",
      "Epoch 1375\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.2744 - accuracy: 0.8376 - val_loss: 4.1497 - val_accuracy: 0.5140\n",
      "Epoch 1376\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3496 - accuracy: 0.8290 - val_loss: 4.1396 - val_accuracy: 0.5183\n",
      "Epoch 1377\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.2865 - accuracy: 0.8280 - val_loss: 4.1354 - val_accuracy: 0.5204\n",
      "Epoch 1378\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.2568 - accuracy: 0.8258 - val_loss: 4.1063 - val_accuracy: 0.5462\n",
      "Epoch 1379\n",
      "3/3 [==============================] - 3s 718ms/step - loss: 2.3945 - accuracy: 0.8086 - val_loss: 4.0926 - val_accuracy: 0.5505\n",
      "Epoch 1380\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.3215 - accuracy: 0.8366 - val_loss: 4.0780 - val_accuracy: 0.5527\n",
      "Epoch 1381\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 2.3255 - accuracy: 0.8204 - val_loss: 4.0913 - val_accuracy: 0.5527\n",
      "Epoch 1382\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.3569 - accuracy: 0.8108 - val_loss: 4.1028 - val_accuracy: 0.5441\n",
      "Epoch 1383\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3163 - accuracy: 0.8333 - val_loss: 4.1182 - val_accuracy: 0.5570\n",
      "Epoch 1384\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.3096 - accuracy: 0.8247 - val_loss: 4.1476 - val_accuracy: 0.5419\n",
      "Epoch 1385\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.3490 - accuracy: 0.8387 - val_loss: 4.1393 - val_accuracy: 0.5613\n",
      "Epoch 1386\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3295 - accuracy: 0.8161 - val_loss: 4.1329 - val_accuracy: 0.5699\n",
      "Epoch 1387\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 2.3168 - accuracy: 0.8344 - val_loss: 4.1596 - val_accuracy: 0.5656\n",
      "Epoch 1388\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.3160 - accuracy: 0.8312 - val_loss: 4.1956 - val_accuracy: 0.5613\n",
      "Epoch 1389\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3044 - accuracy: 0.8204 - val_loss: 4.2205 - val_accuracy: 0.5505\n",
      "Epoch 1390\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3056 - accuracy: 0.8366 - val_loss: 4.2149 - val_accuracy: 0.5591\n",
      "Epoch 1391\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.4059 - accuracy: 0.8172 - val_loss: 4.1885 - val_accuracy: 0.5613\n",
      "Epoch 1392\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3379 - accuracy: 0.8204 - val_loss: 4.1674 - val_accuracy: 0.5570\n",
      "Epoch 1393\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.3119 - accuracy: 0.8258 - val_loss: 4.1914 - val_accuracy: 0.5613\n",
      "Epoch 1394\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.2934 - accuracy: 0.8269 - val_loss: 4.1875 - val_accuracy: 0.5634\n",
      "Epoch 1395\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.2954 - accuracy: 0.8333 - val_loss: 4.1159 - val_accuracy: 0.5699\n",
      "Epoch 1396\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3436 - accuracy: 0.8312 - val_loss: 4.0842 - val_accuracy: 0.5613\n",
      "Epoch 1397\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3730 - accuracy: 0.8258 - val_loss: 4.0805 - val_accuracy: 0.5570\n",
      "Epoch 1398\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.2958 - accuracy: 0.8323 - val_loss: 4.0802 - val_accuracy: 0.5441\n",
      "Epoch 1399\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.3080 - accuracy: 0.8333 - val_loss: 4.1225 - val_accuracy: 0.5505\n",
      "Epoch 1400\n",
      "3/3 [==============================] - 3s 789ms/step - loss: 2.3066 - accuracy: 0.8312 - val_loss: 4.1639 - val_accuracy: 0.5527\n",
      "Epoch 1401\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.2704 - accuracy: 0.8387 - val_loss: 4.1800 - val_accuracy: 0.5462\n",
      "Epoch 1402\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.2348 - accuracy: 0.8656 - val_loss: 4.2193 - val_accuracy: 0.5441\n",
      "Epoch 1403\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.3183 - accuracy: 0.8290 - val_loss: 4.2505 - val_accuracy: 0.5419\n",
      "Epoch 1404\n",
      "3/3 [==============================] - 3s 642ms/step - loss: 2.3282 - accuracy: 0.8172 - val_loss: 4.2278 - val_accuracy: 0.5441\n",
      "Epoch 1405\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.2328 - accuracy: 0.8516 - val_loss: 4.2010 - val_accuracy: 0.5441\n",
      "Epoch 1406\n",
      "3/3 [==============================] - 3s 568ms/step - loss: 2.3021 - accuracy: 0.8183 - val_loss: 4.1764 - val_accuracy: 0.5484\n",
      "Epoch 1407\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.2967 - accuracy: 0.8344 - val_loss: 4.1816 - val_accuracy: 0.5484\n",
      "Epoch 1408\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.3914 - accuracy: 0.8108 - val_loss: 4.1973 - val_accuracy: 0.5570\n",
      "Epoch 1409\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.2548 - accuracy: 0.8333 - val_loss: 4.2469 - val_accuracy: 0.5613\n",
      "Epoch 1410\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.3383 - accuracy: 0.8172 - val_loss: 4.3020 - val_accuracy: 0.5441\n",
      "Epoch 1411\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3299 - accuracy: 0.8237 - val_loss: 4.3395 - val_accuracy: 0.5462\n",
      "Epoch 1412\n",
      "3/3 [==============================] - 3s 766ms/step - loss: 2.3818 - accuracy: 0.8151 - val_loss: 4.3335 - val_accuracy: 0.5312\n",
      "Epoch 1413\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.2838 - accuracy: 0.8247 - val_loss: 4.3316 - val_accuracy: 0.5226\n",
      "Epoch 1414\n",
      "3/3 [==============================] - 3s 690ms/step - loss: 2.3445 - accuracy: 0.8204 - val_loss: 4.3298 - val_accuracy: 0.5333\n",
      "Epoch 1415\n",
      "3/3 [==============================] - 3s 702ms/step - loss: 2.2997 - accuracy: 0.8280 - val_loss: 4.3285 - val_accuracy: 0.5355\n",
      "Epoch 1416\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.3274 - accuracy: 0.8269 - val_loss: 4.2914 - val_accuracy: 0.5312\n",
      "Epoch 1417\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.2591 - accuracy: 0.8333 - val_loss: 4.2654 - val_accuracy: 0.5333\n",
      "Epoch 1418\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3440 - accuracy: 0.8301 - val_loss: 4.2834 - val_accuracy: 0.5269\n",
      "Epoch 1419\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3368 - accuracy: 0.8194 - val_loss: 4.2953 - val_accuracy: 0.5333\n",
      "Epoch 1420\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3341 - accuracy: 0.8344 - val_loss: 4.3026 - val_accuracy: 0.5290\n",
      "Epoch 1421\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.3192 - accuracy: 0.8323 - val_loss: 4.3180 - val_accuracy: 0.5290\n",
      "Epoch 1422\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.2757 - accuracy: 0.8172 - val_loss: 4.3148 - val_accuracy: 0.5312\n",
      "Epoch 1423\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 2.2772 - accuracy: 0.8333 - val_loss: 4.3499 - val_accuracy: 0.5333\n",
      "Epoch 1424\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.3045 - accuracy: 0.8430 - val_loss: 4.3880 - val_accuracy: 0.5312\n",
      "Epoch 1425\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3712 - accuracy: 0.8022 - val_loss: 4.3895 - val_accuracy: 0.5376\n",
      "Epoch 1426\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 2.4181 - accuracy: 0.8043 - val_loss: 4.3386 - val_accuracy: 0.5333\n",
      "Epoch 1427\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.3565 - accuracy: 0.8043 - val_loss: 4.2626 - val_accuracy: 0.5376\n",
      "Epoch 1428\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 2.3430 - accuracy: 0.8183 - val_loss: 4.2404 - val_accuracy: 0.5290\n",
      "Epoch 1429\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.2673 - accuracy: 0.8344 - val_loss: 4.2790 - val_accuracy: 0.5183\n",
      "Epoch 1430\n",
      "3/3 [==============================] - 3s 566ms/step - loss: 2.3195 - accuracy: 0.8204 - val_loss: 4.3192 - val_accuracy: 0.5118\n",
      "Epoch 1431\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.2858 - accuracy: 0.8398 - val_loss: 4.3482 - val_accuracy: 0.5118\n",
      "Epoch 1432\n",
      "3/3 [==============================] - 3s 577ms/step - loss: 2.2963 - accuracy: 0.8344 - val_loss: 4.3833 - val_accuracy: 0.5183\n",
      "Epoch 1433\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.3676 - accuracy: 0.8129 - val_loss: 4.3879 - val_accuracy: 0.5290\n",
      "Epoch 1434\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.2781 - accuracy: 0.8366 - val_loss: 4.3907 - val_accuracy: 0.5183\n",
      "Epoch 1435\n",
      "3/3 [==============================] - 3s 809ms/step - loss: 2.3371 - accuracy: 0.8215 - val_loss: 4.3729 - val_accuracy: 0.5333\n",
      "Epoch 1436\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3397 - accuracy: 0.8312 - val_loss: 4.3475 - val_accuracy: 0.5290\n",
      "Epoch 1437\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.3368 - accuracy: 0.8280 - val_loss: 4.2954 - val_accuracy: 0.5204\n",
      "Epoch 1438\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3568 - accuracy: 0.8237 - val_loss: 4.2707 - val_accuracy: 0.5140\n",
      "Epoch 1439\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.4375 - accuracy: 0.8108 - val_loss: 4.2732 - val_accuracy: 0.5290\n",
      "Epoch 1440\n",
      "3/3 [==============================] - 3s 567ms/step - loss: 2.2944 - accuracy: 0.8258 - val_loss: 4.2888 - val_accuracy: 0.5333\n",
      "Epoch 1441\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.2814 - accuracy: 0.8333 - val_loss: 4.3031 - val_accuracy: 0.5333\n",
      "Epoch 1442\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.3093 - accuracy: 0.8398 - val_loss: 4.2979 - val_accuracy: 0.5312\n",
      "Epoch 1443\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 2.3365 - accuracy: 0.8376 - val_loss: 4.2627 - val_accuracy: 0.5226\n",
      "Epoch 1444\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3292 - accuracy: 0.8290 - val_loss: 4.2409 - val_accuracy: 0.5226\n",
      "Epoch 1445\n",
      "3/3 [==============================] - 3s 710ms/step - loss: 2.2704 - accuracy: 0.8366 - val_loss: 4.2317 - val_accuracy: 0.5247\n",
      "Epoch 1446\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3843 - accuracy: 0.8204 - val_loss: 4.2671 - val_accuracy: 0.5118\n",
      "Epoch 1447\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.3338 - accuracy: 0.8172 - val_loss: 4.2888 - val_accuracy: 0.5269\n",
      "Epoch 1448\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.3634 - accuracy: 0.8183 - val_loss: 4.3031 - val_accuracy: 0.5161\n",
      "Epoch 1449\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.3712 - accuracy: 0.8032 - val_loss: 4.2710 - val_accuracy: 0.5204\n",
      "Epoch 1450\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.2813 - accuracy: 0.8387 - val_loss: 4.2234 - val_accuracy: 0.5204\n",
      "Epoch 1451\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.2948 - accuracy: 0.8462 - val_loss: 4.2179 - val_accuracy: 0.5290\n",
      "Epoch 1452\n",
      "3/3 [==============================] - 3s 564ms/step - loss: 2.3011 - accuracy: 0.8323 - val_loss: 4.2254 - val_accuracy: 0.5247\n",
      "Epoch 1453\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.4231 - accuracy: 0.8151 - val_loss: 4.1892 - val_accuracy: 0.5312\n",
      "Epoch 1454\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3548 - accuracy: 0.8215 - val_loss: 4.1671 - val_accuracy: 0.5312\n",
      "Epoch 1455\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.3719 - accuracy: 0.8118 - val_loss: 4.1293 - val_accuracy: 0.5290\n",
      "Epoch 1456\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3323 - accuracy: 0.8226 - val_loss: 4.1197 - val_accuracy: 0.5269\n",
      "Epoch 1457\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3349 - accuracy: 0.8280 - val_loss: 4.1483 - val_accuracy: 0.5290\n",
      "Epoch 1458\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.3343 - accuracy: 0.8086 - val_loss: 4.1800 - val_accuracy: 0.5312\n",
      "Epoch 1459\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.2611 - accuracy: 0.8355 - val_loss: 4.1774 - val_accuracy: 0.5247\n",
      "Epoch 1460\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3140 - accuracy: 0.8247 - val_loss: 4.1856 - val_accuracy: 0.5118\n",
      "Epoch 1461\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.2825 - accuracy: 0.8333 - val_loss: 4.2167 - val_accuracy: 0.5032\n",
      "Epoch 1462\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.2930 - accuracy: 0.8183 - val_loss: 4.2627 - val_accuracy: 0.5097\n",
      "Epoch 1463\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.2285 - accuracy: 0.8366 - val_loss: 4.2775 - val_accuracy: 0.5204\n",
      "Epoch 1464\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.3314 - accuracy: 0.8129 - val_loss: 4.2666 - val_accuracy: 0.5290\n",
      "Epoch 1465\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.2933 - accuracy: 0.8398 - val_loss: 4.2444 - val_accuracy: 0.5226\n",
      "Epoch 1466\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3268 - accuracy: 0.8258 - val_loss: 4.2343 - val_accuracy: 0.5204\n",
      "Epoch 1467\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.3500 - accuracy: 0.8172 - val_loss: 4.2555 - val_accuracy: 0.5312\n",
      "Epoch 1468\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.3052 - accuracy: 0.8290 - val_loss: 4.2714 - val_accuracy: 0.5290\n",
      "Epoch 1469\n",
      "3/3 [==============================] - 3s 559ms/step - loss: 2.3595 - accuracy: 0.8194 - val_loss: 4.2710 - val_accuracy: 0.5204\n",
      "Epoch 1470\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.3481 - accuracy: 0.8097 - val_loss: 4.2588 - val_accuracy: 0.5226\n",
      "Epoch 1471\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.3168 - accuracy: 0.8355 - val_loss: 4.2477 - val_accuracy: 0.5290\n",
      "Epoch 1472\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.3168 - accuracy: 0.8258 - val_loss: 4.2452 - val_accuracy: 0.5355\n",
      "Epoch 1473\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3474 - accuracy: 0.8258 - val_loss: 4.2455 - val_accuracy: 0.5419\n",
      "Epoch 1474\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3170 - accuracy: 0.8312 - val_loss: 4.2416 - val_accuracy: 0.5419\n",
      "Epoch 1475\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 2.3235 - accuracy: 0.8226 - val_loss: 4.2194 - val_accuracy: 0.5312\n",
      "Epoch 1476\n",
      "3/3 [==============================] - 3s 769ms/step - loss: 2.3082 - accuracy: 0.8237 - val_loss: 4.1806 - val_accuracy: 0.5204\n",
      "Epoch 1477\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.4393 - accuracy: 0.7989 - val_loss: 4.1232 - val_accuracy: 0.5333\n",
      "Epoch 1478\n",
      "3/3 [==============================] - 3s 560ms/step - loss: 2.3406 - accuracy: 0.8129 - val_loss: 4.0888 - val_accuracy: 0.5484\n",
      "Epoch 1479\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.3586 - accuracy: 0.8011 - val_loss: 4.0986 - val_accuracy: 0.5484\n",
      "Epoch 1480\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 2.2784 - accuracy: 0.8473 - val_loss: 4.1284 - val_accuracy: 0.5462\n",
      "Epoch 1481\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.2898 - accuracy: 0.8226 - val_loss: 4.1584 - val_accuracy: 0.5355\n",
      "Epoch 1482\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.3388 - accuracy: 0.8258 - val_loss: 4.1787 - val_accuracy: 0.5269\n",
      "Epoch 1483\n",
      "3/3 [==============================] - 3s 562ms/step - loss: 2.2986 - accuracy: 0.8344 - val_loss: 4.1937 - val_accuracy: 0.5312\n",
      "Epoch 1484\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.2605 - accuracy: 0.8570 - val_loss: 4.1964 - val_accuracy: 0.5376\n",
      "Epoch 1485\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.3234 - accuracy: 0.8323 - val_loss: 4.1916 - val_accuracy: 0.5355\n",
      "Epoch 1486\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.3724 - accuracy: 0.8140 - val_loss: 4.2099 - val_accuracy: 0.5462\n",
      "Epoch 1487\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.2808 - accuracy: 0.8441 - val_loss: 4.2180 - val_accuracy: 0.5419\n",
      "Epoch 1488\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.3565 - accuracy: 0.8323 - val_loss: 4.2261 - val_accuracy: 0.5355\n",
      "Epoch 1489\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.2778 - accuracy: 0.8333 - val_loss: 4.2289 - val_accuracy: 0.5355\n",
      "Epoch 1490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 607ms/step - loss: 2.3452 - accuracy: 0.8237 - val_loss: 4.2397 - val_accuracy: 0.5247\n",
      "Epoch 1491\n",
      "3/3 [==============================] - 3s 684ms/step - loss: 2.2760 - accuracy: 0.8409 - val_loss: 4.2172 - val_accuracy: 0.5312\n",
      "Epoch 1492\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.4255 - accuracy: 0.8204 - val_loss: 4.1760 - val_accuracy: 0.5441\n",
      "Epoch 1493\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.3471 - accuracy: 0.8237 - val_loss: 4.1354 - val_accuracy: 0.5419\n",
      "Epoch 1494\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.3460 - accuracy: 0.8140 - val_loss: 4.1085 - val_accuracy: 0.5398\n",
      "Epoch 1495\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.3749 - accuracy: 0.8194 - val_loss: 4.1083 - val_accuracy: 0.5269\n",
      "Epoch 1496\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.3891 - accuracy: 0.8226 - val_loss: 4.1172 - val_accuracy: 0.5419\n",
      "Epoch 1497\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.3128 - accuracy: 0.8312 - val_loss: 4.1121 - val_accuracy: 0.5333\n",
      "Epoch 1498\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.2935 - accuracy: 0.8355 - val_loss: 4.1139 - val_accuracy: 0.5269\n",
      "Epoch 1499\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 2.3094 - accuracy: 0.8366 - val_loss: 4.1137 - val_accuracy: 0.5333\n",
      "Epoch 1500\n",
      "3/3 [==============================] - 3s 561ms/step - loss: 2.3601 - accuracy: 0.8065 - val_loss: 4.1262 - val_accuracy: 0.5355\n",
      "Epoch 1501\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.2741 - accuracy: 0.8301 - val_loss: 4.1319 - val_accuracy: 0.5484\n",
      "Epoch 1502\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.2892 - accuracy: 0.8387 - val_loss: 4.1337 - val_accuracy: 0.5441\n",
      "Epoch 1503\n",
      "3/3 [==============================] - 3s 565ms/step - loss: 2.2447 - accuracy: 0.8409 - val_loss: 4.1227 - val_accuracy: 0.5484\n",
      "Epoch 1504\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 2.3831 - accuracy: 0.8194 - val_loss: 4.1178 - val_accuracy: 0.5570\n",
      "Epoch 1505\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 2.3236 - accuracy: 0.8247 - val_loss: 4.0987 - val_accuracy: 0.5570\n",
      "Epoch 1506\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a9ff54501370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sv.train(is_dnn_structure_changned= False, \n\u001b[0m\u001b[1;32m      4\u001b[0m          \u001b[0menabled_trasfer_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SpeechVision/DysarthricCNNRezaTransferLearningSD/DysarthricSpeechVision.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ideal_loss, is_dnn_structure_changned, learning_rate, max_epoch, enabled_trasfer_learning)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mideal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             history=model.fit(\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "sv.set_gpus(\"2\")\n",
    "sv.train(is_dnn_structure_changned= False, \n",
    "         enabled_trasfer_learning=True,\n",
    "         learning_rate=0.0001,\n",
    "         max_epoch=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner_model_M12/dyser_M12_Resnet/oracle.json\n",
      "0.0001\n",
      "input_1  FREEZED\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.2\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "activation  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.2\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "activation_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.2\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "conv2d  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "add  NOT FREEZED\n",
      "activation_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.2\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_4  NOT FREEZED\n",
      "activation_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.2\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "conv2d_1  NOT FREEZED\n",
      "batch_normalization_5  NOT FREEZED\n",
      "batch_normalization_6  NOT FREEZED\n",
      "add_1  NOT FREEZED\n",
      "activation_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "separable_conv2d_5  NOT FREEZED\n",
      "spatial_dropout2d_5 dropout rate updated to 0.2\n",
      "spatial_dropout2d_5  NOT FREEZED\n",
      "batch_normalization_7  NOT FREEZED\n",
      "activation_5  NOT FREEZED\n",
      "separable_conv2d_6  NOT FREEZED\n",
      "spatial_dropout2d_6 dropout rate updated to 0.2\n",
      "spatial_dropout2d_6  NOT FREEZED\n",
      "conv2d_2  NOT FREEZED\n",
      "batch_normalization_8  NOT FREEZED\n",
      "batch_normalization_9  NOT FREEZED\n",
      "add_2  NOT FREEZED\n",
      "activation_6  NOT FREEZED\n",
      "max_pooling2d_3  NOT FREEZED\n",
      "dropout dropout rate updated to 0.2\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "INFO:tensorflow:Reloading Tuner from tuner_model_M12/dyser_M12_Resnet/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search=RandomSearch(get_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=55,directory='tuner_model_M12',\n",
    "                          project_name=\"dyser_M12_Resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004001857503058816\n",
      "input_1  FREEZED\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "activation  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "activation_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "conv2d  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "add  NOT FREEZED\n",
      "activation_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_4  NOT FREEZED\n",
      "activation_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "conv2d_1  NOT FREEZED\n",
      "batch_normalization_5  NOT FREEZED\n",
      "batch_normalization_6  NOT FREEZED\n",
      "add_1  NOT FREEZED\n",
      "activation_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "separable_conv2d_5  NOT FREEZED\n",
      "spatial_dropout2d_5 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_5  NOT FREEZED\n",
      "batch_normalization_7  NOT FREEZED\n",
      "activation_5  NOT FREEZED\n",
      "separable_conv2d_6  NOT FREEZED\n",
      "spatial_dropout2d_6 dropout rate updated to 0.25688887976963115\n",
      "spatial_dropout2d_6  NOT FREEZED\n",
      "conv2d_2  NOT FREEZED\n",
      "batch_normalization_8  NOT FREEZED\n",
      "batch_normalization_9  NOT FREEZED\n",
      "add_2  NOT FREEZED\n",
      "activation_6  NOT FREEZED\n",
      "max_pooling2d_3  NOT FREEZED\n",
      "dropout dropout rate updated to 0.25688887976963115\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "best hyper parameters are:\n",
      "droprate 0.25688887976963115\n",
      "first_train 2\n",
      "lr 0.0004001857503058816\n"
     ]
    }
   ],
   "source": [
    "tuner_search.reload()\n",
    "model=tuner_search.get_best_models(num_models=1)[0]\n",
    "best_hps=tuner_search.get_best_hyperparameters(num_trials=1)[0]\n",
    "print('best hyper parameters are:')\n",
    "print('droprate',best_hps.get('droprate'))\n",
    "print('first_train',best_hps.get('first_train'))\n",
    "print('lr',best_hps.get('lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "droprate (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.75, 'step': None, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "first_train (Choice)\n",
      "{'default': '2', 'conditions': [], 'values': ['2', '3', '4', '5', '6'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 08m 21s]\n",
      "val_accuracy: 0.47526881098747253\n",
      "\n",
      "Best val_accuracy So Far: 0.49677419662475586\n",
      "Total elapsed time: 00h 56m 32s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "droprate          |0.29266           |0.25689           \n",
      "lr                |0.00017803        |0.00040019        \n",
      "first_train       |2                 |2                 \n",
      "\n",
      "0.00017803406703647428\n",
      "input_1  FREEZED\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "activation  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "activation_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "conv2d  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "add  NOT FREEZED\n",
      "activation_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_4  NOT FREEZED\n",
      "activation_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "conv2d_1  NOT FREEZED\n",
      "batch_normalization_5  NOT FREEZED\n",
      "batch_normalization_6  NOT FREEZED\n",
      "add_1  NOT FREEZED\n",
      "activation_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "separable_conv2d_5  NOT FREEZED\n",
      "spatial_dropout2d_5 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_5  NOT FREEZED\n",
      "batch_normalization_7  NOT FREEZED\n",
      "activation_5  NOT FREEZED\n",
      "separable_conv2d_6  NOT FREEZED\n",
      "spatial_dropout2d_6 dropout rate updated to 0.2926635254173455\n",
      "spatial_dropout2d_6  NOT FREEZED\n",
      "conv2d_2  NOT FREEZED\n",
      "batch_normalization_8  NOT FREEZED\n",
      "batch_normalization_9  NOT FREEZED\n",
      "add_2  NOT FREEZED\n",
      "activation_6  NOT FREEZED\n",
      "max_pooling2d_3  NOT FREEZED\n",
      "dropout dropout rate updated to 0.2926635254173455\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "Epoch 1/95\n",
      "3/3 [==============================] - 8s 2s/step - loss: 6.7444 - accuracy: 0.0489 - val_loss: 4.3938 - val_accuracy: 0.1742\n",
      "Epoch 2/95\n",
      "3/3 [==============================] - 5s 989ms/step - loss: 5.2403 - accuracy: 0.0892 - val_loss: 4.0756 - val_accuracy: 0.2344\n",
      "Epoch 3/95\n",
      "3/3 [==============================] - 5s 910ms/step - loss: 4.6314 - accuracy: 0.1538 - val_loss: 4.0041 - val_accuracy: 0.3097\n",
      "Epoch 4/95\n",
      "3/3 [==============================] - 5s 902ms/step - loss: 4.1284 - accuracy: 0.2232 - val_loss: 3.9536 - val_accuracy: 0.3548\n",
      "Epoch 5/95\n",
      "3/3 [==============================] - 5s 884ms/step - loss: 3.9427 - accuracy: 0.3173 - val_loss: 3.8708 - val_accuracy: 0.3527\n",
      "Epoch 6/95\n",
      "3/3 [==============================] - 6s 961ms/step - loss: 3.6992 - accuracy: 0.4067 - val_loss: 3.9560 - val_accuracy: 0.3333\n",
      "Epoch 7/95\n",
      "3/3 [==============================] - 6s 967ms/step - loss: 3.5618 - accuracy: 0.4469 - val_loss: 4.0670 - val_accuracy: 0.3871\n",
      "Epoch 8/95\n",
      "3/3 [==============================] - 6s 961ms/step - loss: 3.3399 - accuracy: 0.5358 - val_loss: 4.2744 - val_accuracy: 0.3892\n",
      "Epoch 9/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 3.0976 - accuracy: 0.5924 - val_loss: 4.4937 - val_accuracy: 0.4043\n",
      "Epoch 10/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.9495 - accuracy: 0.6174 - val_loss: 4.6816 - val_accuracy: 0.4215\n",
      "Epoch 11/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.8443 - accuracy: 0.6523 - val_loss: 4.8319 - val_accuracy: 0.3978\n",
      "Epoch 12/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.6871 - accuracy: 0.7064 - val_loss: 4.7900 - val_accuracy: 0.3806\n",
      "Epoch 13/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.6394 - accuracy: 0.7184 - val_loss: 4.7345 - val_accuracy: 0.3849\n",
      "Epoch 14/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.4567 - accuracy: 0.7382 - val_loss: 4.6400 - val_accuracy: 0.3871\n",
      "Epoch 15/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.4399 - accuracy: 0.7702 - val_loss: 4.5593 - val_accuracy: 0.4043\n",
      "Epoch 16/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.3233 - accuracy: 0.7842 - val_loss: 4.4975 - val_accuracy: 0.3935\n",
      "Epoch 17/95\n",
      "3/3 [==============================] - 5s 1s/step - loss: 2.2053 - accuracy: 0.7994 - val_loss: 4.5215 - val_accuracy: 0.3935\n",
      "Epoch 18/95\n",
      "3/3 [==============================] - 6s 868ms/step - loss: 2.2055 - accuracy: 0.7743 - val_loss: 4.6405 - val_accuracy: 0.4108\n",
      "Epoch 19/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.2264 - accuracy: 0.7922 - val_loss: 4.8073 - val_accuracy: 0.4000\n",
      "Epoch 20/95\n",
      "3/3 [==============================] - 6s 897ms/step - loss: 2.1251 - accuracy: 0.8161 - val_loss: 4.7819 - val_accuracy: 0.4000\n",
      "Epoch 21/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.0275 - accuracy: 0.8212 - val_loss: 4.7649 - val_accuracy: 0.4086\n",
      "Epoch 22/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.9886 - accuracy: 0.8457 - val_loss: 4.7841 - val_accuracy: 0.4022\n",
      "Epoch 23/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 2.0199 - accuracy: 0.8275 - val_loss: 4.8344 - val_accuracy: 0.4043\n",
      "Epoch 24/95\n",
      "3/3 [==============================] - 6s 997ms/step - loss: 1.9269 - accuracy: 0.8469 - val_loss: 4.9494 - val_accuracy: 0.3935\n",
      "Epoch 25/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.8420 - accuracy: 0.8612 - val_loss: 4.8833 - val_accuracy: 0.4172\n",
      "Epoch 26/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.7893 - accuracy: 0.8849 - val_loss: 4.6894 - val_accuracy: 0.4194\n",
      "Epoch 27/95\n",
      "3/3 [==============================] - 5s 1s/step - loss: 1.8239 - accuracy: 0.8641 - val_loss: 4.6627 - val_accuracy: 0.4301\n",
      "Epoch 28/95\n",
      "3/3 [==============================] - 5s 915ms/step - loss: 1.8021 - accuracy: 0.8522 - val_loss: 4.6566 - val_accuracy: 0.4129\n",
      "Epoch 29/95\n",
      "3/3 [==============================] - 6s 849ms/step - loss: 1.7369 - accuracy: 0.8651 - val_loss: 4.6614 - val_accuracy: 0.3978\n",
      "Epoch 30/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.7809 - accuracy: 0.8567 - val_loss: 4.6138 - val_accuracy: 0.4043\n",
      "Epoch 31/95\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 1.7012 - accuracy: 0.8599 - val_loss: 4.5843 - val_accuracy: 0.4086\n",
      "Epoch 32/95\n",
      "3/3 [==============================] - 5s 895ms/step - loss: 1.7011 - accuracy: 0.8685 - val_loss: 4.5781 - val_accuracy: 0.3806\n",
      "Epoch 33/95\n",
      "3/3 [==============================] - 5s 887ms/step - loss: 1.6901 - accuracy: 0.8712 - val_loss: 4.6377 - val_accuracy: 0.4108\n",
      "Epoch 34/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.6837 - accuracy: 0.8831 - val_loss: 4.6078 - val_accuracy: 0.4172\n",
      "Epoch 35/95\n",
      "3/3 [==============================] - 6s 988ms/step - loss: 1.6983 - accuracy: 0.8752 - val_loss: 4.5696 - val_accuracy: 0.4409\n",
      "Epoch 36/95\n",
      "3/3 [==============================] - 6s 997ms/step - loss: 1.6152 - accuracy: 0.8881 - val_loss: 4.6154 - val_accuracy: 0.4129\n",
      "Epoch 37/95\n",
      "3/3 [==============================] - 6s 991ms/step - loss: 1.6181 - accuracy: 0.8843 - val_loss: 4.5954 - val_accuracy: 0.4237\n",
      "Epoch 38/95\n",
      "3/3 [==============================] - 6s 880ms/step - loss: 1.6204 - accuracy: 0.8757 - val_loss: 4.6110 - val_accuracy: 0.4280\n",
      "Epoch 39/95\n",
      "3/3 [==============================] - 6s 948ms/step - loss: 1.5587 - accuracy: 0.9075 - val_loss: 4.6254 - val_accuracy: 0.4237\n",
      "Epoch 40/95\n",
      "3/3 [==============================] - 6s 987ms/step - loss: 1.5716 - accuracy: 0.8812 - val_loss: 4.6265 - val_accuracy: 0.4151\n",
      "Epoch 41/95\n",
      "3/3 [==============================] - 6s 978ms/step - loss: 1.5741 - accuracy: 0.8838 - val_loss: 4.5695 - val_accuracy: 0.3892\n",
      "Epoch 42/95\n",
      "3/3 [==============================] - 6s 920ms/step - loss: 1.5252 - accuracy: 0.8998 - val_loss: 4.5402 - val_accuracy: 0.4065\n",
      "Epoch 43/95\n",
      "3/3 [==============================] - 6s 887ms/step - loss: 1.5443 - accuracy: 0.8834 - val_loss: 4.4356 - val_accuracy: 0.4215\n",
      "Epoch 44/95\n",
      "3/3 [==============================] - 6s 983ms/step - loss: 1.4424 - accuracy: 0.9233 - val_loss: 4.5110 - val_accuracy: 0.4344\n",
      "Epoch 45/95\n",
      "3/3 [==============================] - 6s 989ms/step - loss: 1.5149 - accuracy: 0.8880 - val_loss: 4.5733 - val_accuracy: 0.4215\n",
      "Epoch 46/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4629 - accuracy: 0.9068 - val_loss: 4.6630 - val_accuracy: 0.4129\n",
      "Epoch 47/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4701 - accuracy: 0.9012 - val_loss: 4.6565 - val_accuracy: 0.3978\n",
      "Epoch 48/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4505 - accuracy: 0.9031 - val_loss: 4.6409 - val_accuracy: 0.4065\n",
      "Epoch 49/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.4913 - accuracy: 0.8869 - val_loss: 4.6355 - val_accuracy: 0.4108\n",
      "Epoch 50/95\n",
      "3/3 [==============================] - 6s 995ms/step - loss: 1.4592 - accuracy: 0.9097 - val_loss: 4.6482 - val_accuracy: 0.4215\n",
      "Epoch 51/95\n",
      "3/3 [==============================] - 6s 960ms/step - loss: 1.4241 - accuracy: 0.9164 - val_loss: 4.6437 - val_accuracy: 0.4022\n",
      "Epoch 52/95\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.3496 - accuracy: 0.9271 - val_loss: 4.6298 - val_accuracy: 0.3978\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(training_set,epochs=95,\n",
    "                    steps_per_epoch=training_set.samples/batch_size,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=test_set.samples/batch_size,\n",
    "                    workers=10,\n",
    "                    max_queue_size=10\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv.visualize_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "sv.set_gpus(\"1\")\n",
    "sv.test_generator(sv.test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
