{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which speaker do you want to train/test? M01\n",
      "Vocabulary Size: 155\n",
      "Setting training date...\n",
      "Found 930 images belonging to 155 classes.\n",
      "Setting testing date...\n",
      "Found 465 images belonging to 155 classes.\n"
     ]
    }
   ],
   "source": [
    "import utilities\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout , SpatialDropout2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Activation\n",
    "from tensorflow.keras.callbacks import History\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from  tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.regularizers import l1_l2, l1,l2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.utils import class_weight\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import pyprog\n",
    "import os\n",
    "\n",
    "def set_gpus(gpus_number=\"1,2\"):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus_number\n",
    "    \n",
    "SETTINGS_DIR = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "speaker_name=input(\"Which speaker do you want to train/test? \")\n",
    "train_set_path = SETTINGS_DIR+'/images/Dysarthric/Train/'+speaker_name\n",
    "test_set_path = SETTINGS_DIR+\"/images/Dysarthric/Test/\"+speaker_name\n",
    "dnn_file_name_structure = SETTINGS_DIR +\"/Models/cnn_\"+speaker_name+\".json\"\n",
    "training_dynamics_path = SETTINGS_DIR+'/Training Performance/TrainingDynamics'+speaker_name+'.csv'\n",
    "dnn_file_name_weights = SETTINGS_DIR +  \"/Models/cnn_weight_\"+speaker_name+\".h5\"\n",
    "\n",
    "batch_size=256\n",
    "image_input_size=(150,150)\n",
    "vocab_size = utilities.get_no_folders_in_path(test_set_path)\n",
    "print (\"Vocabulary Size:\",vocab_size)\n",
    "\n",
    "def model_compile(model,lr=0.001):\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                          optimizer=optimizers.Adam(lr),\n",
    "                          metrics=['accuracy'])\n",
    "    \n",
    "def get_model(hp):\n",
    "    droprates=hp.Float('droprate', 0.2, 0.75, sampling='linear')\n",
    "    learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
    "    first_train=hp.Choice('first_train', values=['2','3','4'])\n",
    "    model = FreezeLayers(droprates, load_model(learning_rate=learning_rate), top_unfrozen_layer_name=\"separable_conv2d_\"+ first_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_an_image(image_path, model):\n",
    "    \n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    test_image = image.load_img(image_path, target_size = image_input_size)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0) \n",
    "\n",
    "    y_pred = model.predict_classes(test_image,batch_size)[0]\n",
    "    classes =training_set.class_indices\n",
    "    for key, value in classes.items():\n",
    "        if value==y_pred:\n",
    "            break       \n",
    "\n",
    "    pred_key=utilities.dictionary .index [ utilities.dictionary  ['FILE NAME'] == key ] \n",
    "    predicted_word=utilities.dictionary .iloc[pred_key[0],0]\n",
    "    # Get true label\n",
    "    true_key=true_key=utilities.file_to_index(image_path)\n",
    "    true_word = utilities.dictionary .iloc[true_key,0]\n",
    "    #print(\"Predicted:\",predicted_word,\", True:\",true_word)\n",
    "    return predicted_word, true_word\n",
    "\n",
    "def read_epoch():\n",
    "    if os.path.exists(training_dynamics_path):\n",
    "        \n",
    "        # First check the csv file has headres and add then if missing\n",
    "        try:\n",
    "            training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "            training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        except:\n",
    "            df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "            df.columns = columns=[\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "            df.to_csv(training_dynamics_path, index=False)\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)               \n",
    "        return training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_model(learning_rate=0.001):\n",
    "    # Loading the CNN\n",
    "    json_file = open(dnn_file_name_structure, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(dnn_file_name_weights)\n",
    "    print(learning_rate)\n",
    "    model_compile(model,learning_rate)\n",
    "    return model\n",
    "\n",
    "def save_model(model,is_max_val_inclluded=False,max_val=None, ep=None):\n",
    "    # Save/overwrite the model\n",
    "    if (is_max_val_inclluded):\n",
    "        json_file_name = SETTINGS_DIR+\"/Models/cnn_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".json\"\n",
    "        wights_file_name = SETTINGS_DIR+\"/Models/cnn_weight_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".h5\"\n",
    "        # Delete previously stored models for this speaker\n",
    "        for directory, s, files in os.walk(SETTINGS_DIR+\"/Models/\"):\n",
    "            for f in files:\n",
    "                if speaker_name in f:\n",
    "                    file_path=directory+\"/\"+f\n",
    "                    os.remove(file_path)\n",
    "    else:\n",
    "        json_file_name = dnn_file_name_structure\n",
    "        wights_file_name = dnn_file_name_weights\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(json_file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(wights_file_name)\n",
    "    \n",
    "def save_training_dynamics(epoch,history,with_header=False):\n",
    "    training_dynamics=pd.DataFrame(\n",
    "        data = [ [epoch, history.history['loss'][0] ,  history.history['accuracy'][0],  \n",
    "                history.history['val_loss'][0],  history.history['val_accuracy'][0] ]],\n",
    "        columns=[\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "    )\n",
    "    if (with_header):\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=True)\n",
    "    else:\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=False)\n",
    "            \n",
    "def visualize_training():\n",
    "    import matplotlib.pyplot as plt\n",
    "    if (os.path.isfile(training_dynamics_path) == False ):\n",
    "        print (\"Training dynamics file is not found.\")\n",
    "        return\n",
    "    try:\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "        loss_values = training_dynamics[\"TrainingLoss\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationLoss\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Ploting Accuracy\n",
    "        loss_values = training_dynamics[\"TrainingAccuracy\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationAccuracy\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "     \n",
    "    except:\n",
    "        df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "        df.columns = [\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "        df.to_csv(training_dynamics_path, index=False)\n",
    "        visualize_training()\n",
    "    \n",
    "def get_train_test_sets():\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "        \n",
    "        # https://fairyonice.github.io/Learn-about-ImageDataGenerator.html\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "            width_shift_range=0.30,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=False)\n",
    "        \n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # If shuffle=False then the validation results will be different from classifier.predict_generator()\n",
    "        print (\"Setting training date...\")\n",
    "        training_set = train_datagen.flow_from_directory(\n",
    "            train_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True)\n",
    "        \n",
    "        print (\"Setting testing date...\")\n",
    "        test_set = test_datagen.flow_from_directory(\n",
    "           test_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "        return training_set, test_set\n",
    "    \n",
    "def test_generator(test_set_generator):\n",
    "    steps=test_set_generator.samples/batch_size\n",
    "    model = load_model()\n",
    "\n",
    "    y_pred = model.evaluate_generator(test_set_generator, steps = steps, verbose = 1)\n",
    "    y_test = test_set_generator.classes\n",
    "    correct_classifications=0\n",
    "    for pred,label in zip(y_pred, y_test):\n",
    "        if pred.argmax()==label:\n",
    "            correct_classifications+=1\n",
    "    print (\"Loss:\", y_pred[0])\n",
    "    print (\"Acuracy:\", y_pred[1] *100,\"%\")\n",
    "    return \n",
    "\n",
    "def manual_testing():\n",
    "    model = load_model() \n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/F05\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M06\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M10\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    test_path=test_set_path\n",
    "    \n",
    "    correct_classifications=0\n",
    "    i=0\n",
    "    prog = pyprog.ProgressBar(\"Predicting \", \" Done\", utilities.get_no_files_in_path(test_path))\n",
    "    # Show the initial status\n",
    "    prog.update()\n",
    "    no_processed=i\n",
    "    for directory, s, files in os.walk(test_path):\n",
    "            for f in files:\n",
    "                file_path=directory+\"/\"+f\n",
    "                if (\"jpg\" in f):                \n",
    "                    predicted_word, true_word = predict_an_image(file_path,model)\n",
    "                    #print (predicted_word,true_word)\n",
    "                    if (predicted_word==true_word):\n",
    "                        correct_classifications+=1\n",
    "                    i+=1\n",
    "                    prog.set_stat(i)\n",
    "                    prog.update()\n",
    "\n",
    "    prog.end()\n",
    "    print (\"Testing acuracy:\", correct_classifications/i *100,\"%\")\n",
    "    \n",
    "def train(ideal_loss=0.01, is_dnn_structure_changned=False, learning_rate=0.001, max_epoch=50, enabled_trasfer_learning=False):\n",
    "        \n",
    "        # Check if speaker_name is set\n",
    "        if (speaker_name==\"\"):\n",
    "            print (\"Please set speaker_name and try again.\")\n",
    "            return\n",
    "            \n",
    "        is_new_dnn=False\n",
    "        \n",
    "        history = History()\n",
    "        \n",
    "        print(\"=================================================\")\n",
    "        \n",
    "        if (os.path.isfile(dnn_file_name_structure) and\n",
    "                (os.path.isfile(dnn_file_name_weights)) and \n",
    "                (is_dnn_structure_changned == False)):\n",
    "            # load the previosly trained DNN\n",
    "            if (enabled_trasfer_learning):\n",
    "                # Enable Transfer Learning\n",
    "                print (\"Transfer learning is enabled.\")\n",
    "                model = FreezeLayers(load_model(learning_rate=learning_rate),\n",
    "                                     top_unfrozen_layer_name=\"separable_conv2d_3\" ) \n",
    "            else:\n",
    "                print (\"Transer learning is disabled.\")\n",
    "                model = load_model(learning_rate=learning_rate)\n",
    "            print(\"CNN is loaded.\")\n",
    "        else:\n",
    "            # Create a new model\n",
    "            model =  get_model()                    \n",
    "            print(\"CNN is created\")\n",
    "            # Erase the training_dynamic_csv file\n",
    "            if os.path.exists(training_dynamics_path):\n",
    "                os.remove(training_dynamics_path)\n",
    "            is_new_dnn=True\n",
    "            model_compile(model)\n",
    "        \n",
    "        ep= read_epoch()+1\n",
    "        PringFrozenLayers(model)\n",
    "        history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size, epochs=1,                            \n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10, \n",
    "                             max_queue_size=10)\n",
    "        \n",
    "        save_training_dynamics(ep,history,with_header=is_new_dnn)\n",
    "       \n",
    "        max_val = history.history['val_accuracy'][0]\n",
    "        \n",
    "        while (history.history['loss'][0] >= ideal_loss):\n",
    "            print(\"Epoch\", ep)\n",
    "            history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size,epochs=1,\n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10,\n",
    "                             max_queue_size=10)\n",
    "\n",
    "            # Save the max model, if any            \n",
    "            if (history.history['val_accuracy'][0]>max_val):\n",
    "                max_val= history.history['val_accuracy'][0]\n",
    "                save_model(model=model,is_max_val_inclluded=True,max_val=max_val,ep=ep)\n",
    "             \n",
    "            # Save/overwrite the model\n",
    "            save_model(model)\n",
    "               \n",
    "            ep += 1\n",
    "            save_training_dynamics(ep,history,with_header=False)        \n",
    "\n",
    "            # stop the traning if certain accuracy is reached\n",
    "            #if (ep%10==0):\n",
    "                #manual_testing()   \n",
    "            #if   (history.history['val_accuracy'][0]>0.92):\n",
    "              #  break\n",
    "            if (history.history['loss'][0]<ideal_loss):\n",
    "                   break\n",
    "            \n",
    "            if (ep > max_epoch):\n",
    "                break\n",
    "\n",
    "        return history\n",
    "    \n",
    "    # Transfer learning: freeze top layers but unfreeze all layers below the given layer   \n",
    "def FreezeLayers(droprate, model, top_unfrozen_layer_name):\n",
    "    \n",
    "    model.trainable=True\n",
    "    set_trainable = False\n",
    "    for layer in model.layers:\n",
    "        # Increase dropout rate\n",
    "        if \"dropout\" in layer.name:\n",
    "            layer.rate=droprate\n",
    "            print (layer.name,\"dropout rate updated to\",layer.rate)\n",
    "        if (layer.name==top_unfrozen_layer_name):\n",
    "            set_trainable=True\n",
    "\n",
    "        if (set_trainable):\n",
    "            print (layer.name,\" NOT FREEZED\")\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            print (layer.name,\" FREEZED\")\n",
    "            layer.trainable=False\n",
    "        #if (layer.name==\"dense_1\"):\n",
    "            #layer.trainable = False\n",
    "    #model = add_new_dense(model)\n",
    "    model_compile(model)\n",
    "    return model\n",
    "\n",
    "# add a new dense layer\n",
    "def add_new_dense(model):\n",
    "    new_model=Sequential()\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.name=layer.name+\"_old\"\n",
    "        new_model.add(layer)\n",
    "    new_model.add(Dense(units = 1024, activation='relu' ))\n",
    "    new_model.add(Dropout(0.5))\n",
    "    new_model.add(Dense (units=vocab_size, activation='softmax' ))\n",
    "    return new_model\n",
    "\n",
    "def PringFrozenLayers(model):\n",
    "     for layer in model.layers:\n",
    "            print (\"Layer:\",layer.name, \"Frozen:\",not layer.trainable)\n",
    "            \n",
    "def training_restart_initalize():\n",
    "    import shutil\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_control.json\", dnn_file_name_structure)\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_weight_control.h5\", dnn_file_name_weights)\n",
    "    if (os.path.isfile(training_dynamics_path)):\n",
    "        os.remove(training_dynamics_path)\n",
    "    print (\"Ready for training...\")\n",
    "\n",
    "# Load X and y\n",
    "training_set, test_set =get_train_test_sets()\n",
    "\n",
    "\n",
    "!find '.' -name '*.ipynb_checkpoints' -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training...\n"
     ]
    }
   ],
   "source": [
    "# Enable this if you want to train the model for this speaker from scracth. \n",
    "# Otherwise, the previously trained model is continued training.\n",
    "# This loads the base, control model.\n",
    "training_restart_initalize()\n",
    "set_gpus(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Transfer learning is enabled.\n",
      "0.001\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.58\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.58\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "separable_conv2d_2  FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.58\n",
      "spatial_dropout2d_2  FREEZED\n",
      "batch_normalization_2  FREEZED\n",
      "max_pooling2d_1  FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.58\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.58\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "dropout dropout rate updated to 0.58\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "CNN is loaded.\n",
      "Layer: separable_conv2d Frozen: True\n",
      "Layer: spatial_dropout2d Frozen: True\n",
      "Layer: batch_normalization Frozen: True\n",
      "Layer: max_pooling2d Frozen: True\n",
      "Layer: separable_conv2d_1 Frozen: True\n",
      "Layer: spatial_dropout2d_1 Frozen: True\n",
      "Layer: batch_normalization_1 Frozen: True\n",
      "Layer: separable_conv2d_2 Frozen: True\n",
      "Layer: spatial_dropout2d_2 Frozen: True\n",
      "Layer: batch_normalization_2 Frozen: True\n",
      "Layer: max_pooling2d_1 Frozen: True\n",
      "Layer: separable_conv2d_3 Frozen: False\n",
      "Layer: spatial_dropout2d_3 Frozen: False\n",
      "Layer: batch_normalization_3 Frozen: False\n",
      "Layer: separable_conv2d_4 Frozen: False\n",
      "Layer: spatial_dropout2d_4 Frozen: False\n",
      "Layer: max_pooling2d_2 Frozen: False\n",
      "Layer: dropout Frozen: False\n",
      "Layer: flatten Frozen: False\n",
      "Layer: dense Frozen: False\n",
      "3/3 [==============================] - 6s 1s/step - loss: 7.0396 - accuracy: 0.0301 - val_loss: 2.9907 - val_accuracy: 0.3484\n",
      "Epoch 1\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 6.4233 - accuracy: 0.0183 - val_loss: 2.9483 - val_accuracy: 0.3290\n",
      "Epoch 2\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 6.0130 - accuracy: 0.0226 - val_loss: 3.2338 - val_accuracy: 0.2968\n",
      "Epoch 3\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 5.8470 - accuracy: 0.0140 - val_loss: 3.6403 - val_accuracy: 0.2452\n",
      "Epoch 4\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 5.7399 - accuracy: 0.0172 - val_loss: 4.0170 - val_accuracy: 0.1828\n",
      "Epoch 5\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 5.6669 - accuracy: 0.0172 - val_loss: 4.3222 - val_accuracy: 0.1312\n",
      "Epoch 6\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 5.5764 - accuracy: 0.0215 - val_loss: 4.5532 - val_accuracy: 0.0903\n",
      "Epoch 7\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 5.6558 - accuracy: 0.0226 - val_loss: 4.7361 - val_accuracy: 0.0667\n",
      "Epoch 8\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 5.6248 - accuracy: 0.0151 - val_loss: 4.8784 - val_accuracy: 0.0538\n",
      "Epoch 9\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 5.5245 - accuracy: 0.0183 - val_loss: 4.9821 - val_accuracy: 0.0452\n",
      "Epoch 10\n",
      "3/3 [==============================] - 3s 653ms/step - loss: 5.5731 - accuracy: 0.0151 - val_loss: 5.0548 - val_accuracy: 0.0301\n",
      "Epoch 11\n",
      "3/3 [==============================] - 3s 809ms/step - loss: 5.5380 - accuracy: 0.0151 - val_loss: 5.1040 - val_accuracy: 0.0215\n",
      "Epoch 12\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 5.5374 - accuracy: 0.0140 - val_loss: 5.1461 - val_accuracy: 0.0194\n",
      "Epoch 13\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 5.5103 - accuracy: 0.0129 - val_loss: 5.1689 - val_accuracy: 0.0215\n",
      "Epoch 14\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 5.5322 - accuracy: 0.0097 - val_loss: 5.1848 - val_accuracy: 0.0237\n",
      "Epoch 15\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 5.4771 - accuracy: 0.0172 - val_loss: 5.1974 - val_accuracy: 0.0258\n",
      "Epoch 16\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 5.4814 - accuracy: 0.0215 - val_loss: 5.2023 - val_accuracy: 0.0258\n",
      "Epoch 17\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 5.5200 - accuracy: 0.0118 - val_loss: 5.2011 - val_accuracy: 0.0258\n",
      "Epoch 18\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 5.4642 - accuracy: 0.0183 - val_loss: 5.2006 - val_accuracy: 0.0301\n",
      "Epoch 19\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 5.4761 - accuracy: 0.0269 - val_loss: 5.2183 - val_accuracy: 0.0301\n",
      "Epoch 20\n",
      "3/3 [==============================] - 3s 652ms/step - loss: 5.4643 - accuracy: 0.0301 - val_loss: 5.2421 - val_accuracy: 0.0323\n",
      "Epoch 21\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 5.5568 - accuracy: 0.0161 - val_loss: 5.2616 - val_accuracy: 0.0344\n",
      "Epoch 22\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 5.5491 - accuracy: 0.0333 - val_loss: 5.2885 - val_accuracy: 0.0323\n",
      "Epoch 23\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 5.5821 - accuracy: 0.0366 - val_loss: 5.3163 - val_accuracy: 0.0344\n",
      "Epoch 24\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 5.6197 - accuracy: 0.0355 - val_loss: 5.3454 - val_accuracy: 0.0387\n",
      "Epoch 25\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 5.6780 - accuracy: 0.0280 - val_loss: 5.3765 - val_accuracy: 0.0452\n",
      "Epoch 26\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 5.6799 - accuracy: 0.0398 - val_loss: 5.4257 - val_accuracy: 0.0538\n",
      "Epoch 27\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 5.7176 - accuracy: 0.0409 - val_loss: 5.4727 - val_accuracy: 0.0538\n",
      "Epoch 28\n",
      "3/3 [==============================] - 3s 652ms/step - loss: 5.8365 - accuracy: 0.0312 - val_loss: 5.5300 - val_accuracy: 0.0473\n",
      "Epoch 29\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.8841 - accuracy: 0.0258 - val_loss: 5.6027 - val_accuracy: 0.0430\n",
      "Epoch 30\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 5.8689 - accuracy: 0.0387 - val_loss: 5.6601 - val_accuracy: 0.0409\n",
      "Epoch 31\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 5.9543 - accuracy: 0.0366 - val_loss: 5.7115 - val_accuracy: 0.0409\n",
      "Epoch 32\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 5.9775 - accuracy: 0.0366 - val_loss: 5.7597 - val_accuracy: 0.0409\n",
      "Epoch 33\n",
      "3/3 [==============================] - 3s 652ms/step - loss: 5.9356 - accuracy: 0.0462 - val_loss: 5.7856 - val_accuracy: 0.0452\n",
      "Epoch 34\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 6.0792 - accuracy: 0.0430 - val_loss: 5.8044 - val_accuracy: 0.0473\n",
      "Epoch 35\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 6.1804 - accuracy: 0.0462 - val_loss: 5.8488 - val_accuracy: 0.0473\n",
      "Epoch 36\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 6.1914 - accuracy: 0.0366 - val_loss: 5.8916 - val_accuracy: 0.0452\n",
      "Epoch 37\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 6.1163 - accuracy: 0.0452 - val_loss: 5.9111 - val_accuracy: 0.0473\n",
      "Epoch 38\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 6.2135 - accuracy: 0.0548 - val_loss: 5.9379 - val_accuracy: 0.0473\n",
      "Epoch 39\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 6.0768 - accuracy: 0.0581 - val_loss: 5.9466 - val_accuracy: 0.0538\n",
      "Epoch 40\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 6.1490 - accuracy: 0.0710 - val_loss: 5.9439 - val_accuracy: 0.0538\n",
      "Epoch 41\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 6.2175 - accuracy: 0.0516 - val_loss: 5.9497 - val_accuracy: 0.0559\n",
      "Epoch 42\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 6.2952 - accuracy: 0.0398 - val_loss: 5.9795 - val_accuracy: 0.0538\n",
      "Epoch 43\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 6.2496 - accuracy: 0.0613 - val_loss: 6.0042 - val_accuracy: 0.0559\n",
      "Epoch 44\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 6.2083 - accuracy: 0.0613 - val_loss: 6.0185 - val_accuracy: 0.0581\n",
      "Epoch 45\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 6.2603 - accuracy: 0.0538 - val_loss: 6.0268 - val_accuracy: 0.0602\n",
      "Epoch 46\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 6.2743 - accuracy: 0.0645 - val_loss: 6.0333 - val_accuracy: 0.0688\n",
      "Epoch 47\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 6.2951 - accuracy: 0.0559 - val_loss: 6.0605 - val_accuracy: 0.0688\n",
      "Epoch 48\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 6.2896 - accuracy: 0.0656 - val_loss: 6.0914 - val_accuracy: 0.0710\n",
      "Epoch 49\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 6.3105 - accuracy: 0.0624 - val_loss: 6.0975 - val_accuracy: 0.0753\n",
      "Epoch 50\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 6.2876 - accuracy: 0.0645 - val_loss: 6.0797 - val_accuracy: 0.0796\n",
      "Epoch 51\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 6.3029 - accuracy: 0.0699 - val_loss: 6.0615 - val_accuracy: 0.0796\n",
      "Epoch 52\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 6.2917 - accuracy: 0.0796 - val_loss: 6.0427 - val_accuracy: 0.0882\n",
      "Epoch 53\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 6.3423 - accuracy: 0.0602 - val_loss: 6.0621 - val_accuracy: 0.0860\n",
      "Epoch 54\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 6.3097 - accuracy: 0.0774 - val_loss: 6.1017 - val_accuracy: 0.0882\n",
      "Epoch 55\n",
      "3/3 [==============================] - 3s 769ms/step - loss: 6.3273 - accuracy: 0.0871 - val_loss: 6.1319 - val_accuracy: 0.0882\n",
      "Epoch 56\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 6.3515 - accuracy: 0.0763 - val_loss: 6.1299 - val_accuracy: 0.0925\n",
      "Epoch 57\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 6.3145 - accuracy: 0.0849 - val_loss: 6.0973 - val_accuracy: 0.1032\n",
      "Epoch 58\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 6.3915 - accuracy: 0.0925 - val_loss: 6.0719 - val_accuracy: 0.1075\n",
      "Epoch 59\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 6.4254 - accuracy: 0.0914 - val_loss: 6.0672 - val_accuracy: 0.1140\n",
      "Epoch 60\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 6.3709 - accuracy: 0.0828 - val_loss: 6.0555 - val_accuracy: 0.1183\n",
      "Epoch 61\n",
      "3/3 [==============================] - 3s 759ms/step - loss: 6.3019 - accuracy: 0.1086 - val_loss: 6.0442 - val_accuracy: 0.1269\n",
      "Epoch 62\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 6.3360 - accuracy: 0.0957 - val_loss: 6.0231 - val_accuracy: 0.1376\n",
      "Epoch 63\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 6.4428 - accuracy: 0.0989 - val_loss: 5.9989 - val_accuracy: 0.1505\n",
      "Epoch 64\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 6.4667 - accuracy: 0.0957 - val_loss: 6.0269 - val_accuracy: 0.1462\n",
      "Epoch 65\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 6.4653 - accuracy: 0.1108 - val_loss: 6.0593 - val_accuracy: 0.1484\n",
      "Epoch 66\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 6.3648 - accuracy: 0.1118 - val_loss: 6.0596 - val_accuracy: 0.1548\n",
      "Epoch 67\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 6.3420 - accuracy: 0.1108 - val_loss: 6.0427 - val_accuracy: 0.1591\n",
      "Epoch 68\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 6.4432 - accuracy: 0.1129 - val_loss: 6.0269 - val_accuracy: 0.1699\n",
      "Epoch 69\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 6.4019 - accuracy: 0.1129 - val_loss: 5.9988 - val_accuracy: 0.1935\n",
      "Epoch 70\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 6.4629 - accuracy: 0.0817 - val_loss: 5.9869 - val_accuracy: 0.2000\n",
      "Epoch 71\n",
      "3/3 [==============================] - 3s 774ms/step - loss: 6.4689 - accuracy: 0.1269 - val_loss: 5.9983 - val_accuracy: 0.1957\n",
      "Epoch 72\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 6.4498 - accuracy: 0.1204 - val_loss: 6.0379 - val_accuracy: 0.1914\n",
      "Epoch 73\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 6.4418 - accuracy: 0.1140 - val_loss: 6.0466 - val_accuracy: 0.1914\n",
      "Epoch 74\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 6.4393 - accuracy: 0.1215 - val_loss: 6.0604 - val_accuracy: 0.1806\n",
      "Epoch 75\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 6.3396 - accuracy: 0.1290 - val_loss: 6.0673 - val_accuracy: 0.1914\n",
      "Epoch 76\n",
      "3/3 [==============================] - 3s 787ms/step - loss: 6.5047 - accuracy: 0.1000 - val_loss: 6.0543 - val_accuracy: 0.2000\n",
      "Epoch 77\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 6.3713 - accuracy: 0.1344 - val_loss: 6.0289 - val_accuracy: 0.2129\n",
      "Epoch 78\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 6.4380 - accuracy: 0.1376 - val_loss: 6.0021 - val_accuracy: 0.2215\n",
      "Epoch 79\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 6.4705 - accuracy: 0.1280 - val_loss: 5.9646 - val_accuracy: 0.2430\n",
      "Epoch 80\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 6.3293 - accuracy: 0.1484 - val_loss: 5.9380 - val_accuracy: 0.2516\n",
      "Epoch 81\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 6.5025 - accuracy: 0.1441 - val_loss: 5.9520 - val_accuracy: 0.2516\n",
      "Epoch 82\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 6.3977 - accuracy: 0.1495 - val_loss: 5.9816 - val_accuracy: 0.2409\n",
      "Epoch 83\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 6.5544 - accuracy: 0.1194 - val_loss: 5.9847 - val_accuracy: 0.2409\n",
      "Epoch 84\n",
      "3/3 [==============================] - 3s 767ms/step - loss: 6.4652 - accuracy: 0.1570 - val_loss: 5.9899 - val_accuracy: 0.2430\n",
      "Epoch 85\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 6.4380 - accuracy: 0.1570 - val_loss: 5.9939 - val_accuracy: 0.2495\n",
      "Epoch 86\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 6.4796 - accuracy: 0.1473 - val_loss: 5.9969 - val_accuracy: 0.2473\n",
      "Epoch 87\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 6.4615 - accuracy: 0.1409 - val_loss: 5.9820 - val_accuracy: 0.2473\n",
      "Epoch 88\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 6.3754 - accuracy: 0.1613 - val_loss: 5.9666 - val_accuracy: 0.2516\n",
      "Epoch 89\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 6.2930 - accuracy: 0.1806 - val_loss: 5.9262 - val_accuracy: 0.2774\n",
      "Epoch 90\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 6.4546 - accuracy: 0.1473 - val_loss: 5.9016 - val_accuracy: 0.2968\n",
      "Epoch 91\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 6.4163 - accuracy: 0.1677 - val_loss: 5.8993 - val_accuracy: 0.2968\n",
      "Epoch 92\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 6.2729 - accuracy: 0.1946 - val_loss: 5.8865 - val_accuracy: 0.2903\n",
      "Epoch 93\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 6.3253 - accuracy: 0.1731 - val_loss: 5.9208 - val_accuracy: 0.2860\n",
      "Epoch 94\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 6.2030 - accuracy: 0.1903 - val_loss: 5.9481 - val_accuracy: 0.2796\n",
      "Epoch 95\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 6.3912 - accuracy: 0.1774 - val_loss: 5.9393 - val_accuracy: 0.2817\n",
      "Epoch 96\n",
      "3/3 [==============================] - 3s 785ms/step - loss: 6.3968 - accuracy: 0.1699 - val_loss: 5.9382 - val_accuracy: 0.2968\n",
      "Epoch 97\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 6.3326 - accuracy: 0.2011 - val_loss: 5.9103 - val_accuracy: 0.3204\n",
      "Epoch 98\n",
      "3/3 [==============================] - 3s 807ms/step - loss: 6.3703 - accuracy: 0.2000 - val_loss: 5.9059 - val_accuracy: 0.3140\n",
      "Epoch 99\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 6.3933 - accuracy: 0.1989 - val_loss: 5.9288 - val_accuracy: 0.3075\n",
      "Epoch 100\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 6.1784 - accuracy: 0.2344 - val_loss: 5.9532 - val_accuracy: 0.3118\n",
      "Epoch 101\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 6.4810 - accuracy: 0.1828 - val_loss: 5.9811 - val_accuracy: 0.3161\n",
      "Epoch 102\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 6.3825 - accuracy: 0.1968 - val_loss: 5.9872 - val_accuracy: 0.3269\n",
      "Epoch 103\n",
      "3/3 [==============================] - 3s 775ms/step - loss: 6.4152 - accuracy: 0.1839 - val_loss: 5.9873 - val_accuracy: 0.3226\n",
      "Epoch 104\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 6.1974 - accuracy: 0.2258 - val_loss: 5.9634 - val_accuracy: 0.3247\n",
      "Epoch 105\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 6.2252 - accuracy: 0.2247 - val_loss: 5.9472 - val_accuracy: 0.3269\n",
      "Epoch 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 759ms/step - loss: 6.2808 - accuracy: 0.2301 - val_loss: 5.9192 - val_accuracy: 0.3419\n",
      "Epoch 107\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 6.4226 - accuracy: 0.2065 - val_loss: 5.9127 - val_accuracy: 0.3376\n",
      "Epoch 108\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 6.2577 - accuracy: 0.2355 - val_loss: 5.9441 - val_accuracy: 0.3290\n",
      "Epoch 109\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 6.2281 - accuracy: 0.2269 - val_loss: 5.9607 - val_accuracy: 0.3290\n",
      "Epoch 110\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 6.2043 - accuracy: 0.2376 - val_loss: 5.9320 - val_accuracy: 0.3398\n",
      "Epoch 111\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 6.1729 - accuracy: 0.2796 - val_loss: 5.8982 - val_accuracy: 0.3419\n",
      "Epoch 112\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 6.1092 - accuracy: 0.2505 - val_loss: 5.8911 - val_accuracy: 0.3570\n",
      "Epoch 113\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 6.2827 - accuracy: 0.2570 - val_loss: 5.9186 - val_accuracy: 0.3527\n",
      "Epoch 114\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 6.2658 - accuracy: 0.2452 - val_loss: 5.9535 - val_accuracy: 0.3398\n",
      "Epoch 115\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 6.3498 - accuracy: 0.2312 - val_loss: 5.9538 - val_accuracy: 0.3355\n",
      "Epoch 116\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 6.3567 - accuracy: 0.2441 - val_loss: 5.9400 - val_accuracy: 0.3355\n",
      "Epoch 117\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 6.2043 - accuracy: 0.2656 - val_loss: 5.9345 - val_accuracy: 0.3376\n",
      "Epoch 118\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 6.2891 - accuracy: 0.2505 - val_loss: 5.9347 - val_accuracy: 0.3398\n",
      "Epoch 119\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 6.1988 - accuracy: 0.2516 - val_loss: 5.9591 - val_accuracy: 0.3355\n",
      "Epoch 120\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 6.1566 - accuracy: 0.2677 - val_loss: 5.9678 - val_accuracy: 0.3269\n",
      "Epoch 121\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 6.0815 - accuracy: 0.2839 - val_loss: 5.9892 - val_accuracy: 0.3226\n",
      "Epoch 122\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 6.1600 - accuracy: 0.2516 - val_loss: 5.9828 - val_accuracy: 0.3333\n",
      "Epoch 123\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 6.1499 - accuracy: 0.2591 - val_loss: 5.9665 - val_accuracy: 0.3398\n",
      "Epoch 124\n",
      "3/3 [==============================] - 3s 649ms/step - loss: 6.2462 - accuracy: 0.2656 - val_loss: 5.9423 - val_accuracy: 0.3376\n",
      "Epoch 125\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 6.2197 - accuracy: 0.2591 - val_loss: 5.9297 - val_accuracy: 0.3419\n",
      "Epoch 126\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 6.1689 - accuracy: 0.2925 - val_loss: 5.9342 - val_accuracy: 0.3376\n",
      "Epoch 127\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 5.9424 - accuracy: 0.3237 - val_loss: 5.9395 - val_accuracy: 0.3269\n",
      "Epoch 128\n",
      "3/3 [==============================] - 3s 802ms/step - loss: 6.2407 - accuracy: 0.2570 - val_loss: 5.9294 - val_accuracy: 0.3290\n",
      "Epoch 129\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 6.0669 - accuracy: 0.2806 - val_loss: 5.9180 - val_accuracy: 0.3247\n",
      "Epoch 130\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 5.9755 - accuracy: 0.3022 - val_loss: 5.9120 - val_accuracy: 0.3226\n",
      "Epoch 131\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 6.0906 - accuracy: 0.2591 - val_loss: 5.9041 - val_accuracy: 0.3118\n",
      "Epoch 132\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 6.0672 - accuracy: 0.2935 - val_loss: 5.9032 - val_accuracy: 0.3204\n",
      "Epoch 133\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 5.9655 - accuracy: 0.3129 - val_loss: 5.8906 - val_accuracy: 0.3161\n",
      "Epoch 134\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 6.1299 - accuracy: 0.2742 - val_loss: 5.8944 - val_accuracy: 0.3247\n",
      "Epoch 135\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.8879 - accuracy: 0.3280 - val_loss: 5.8942 - val_accuracy: 0.3204\n",
      "Epoch 136\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 6.0344 - accuracy: 0.2978 - val_loss: 5.8930 - val_accuracy: 0.3204\n",
      "Epoch 137\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 5.9258 - accuracy: 0.3258 - val_loss: 5.8994 - val_accuracy: 0.3161\n",
      "Epoch 138\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 5.7708 - accuracy: 0.3419 - val_loss: 5.8918 - val_accuracy: 0.3290\n",
      "Epoch 139\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 5.8617 - accuracy: 0.3441 - val_loss: 5.8952 - val_accuracy: 0.3269\n",
      "Epoch 140\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 5.9661 - accuracy: 0.3194 - val_loss: 5.9056 - val_accuracy: 0.3183\n",
      "Epoch 141\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 5.8247 - accuracy: 0.3559 - val_loss: 5.9030 - val_accuracy: 0.3290\n",
      "Epoch 142\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 5.9590 - accuracy: 0.3290 - val_loss: 5.8885 - val_accuracy: 0.3226\n",
      "Epoch 143\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 5.8201 - accuracy: 0.3484 - val_loss: 5.8764 - val_accuracy: 0.3312\n",
      "Epoch 144\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 5.8804 - accuracy: 0.3613 - val_loss: 5.8733 - val_accuracy: 0.3333\n",
      "Epoch 145\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 5.8381 - accuracy: 0.3538 - val_loss: 5.8742 - val_accuracy: 0.3333\n",
      "Epoch 146\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 5.8645 - accuracy: 0.3376 - val_loss: 5.8700 - val_accuracy: 0.3376\n",
      "Epoch 147\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 5.8752 - accuracy: 0.3387 - val_loss: 5.8661 - val_accuracy: 0.3484\n",
      "Epoch 148\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 5.8972 - accuracy: 0.3344 - val_loss: 5.8624 - val_accuracy: 0.3484\n",
      "Epoch 149\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 5.7596 - accuracy: 0.3731 - val_loss: 5.8540 - val_accuracy: 0.3462\n",
      "Epoch 150\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 5.8548 - accuracy: 0.3409 - val_loss: 5.8526 - val_accuracy: 0.3441\n",
      "Epoch 151\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 5.7923 - accuracy: 0.3688 - val_loss: 5.8518 - val_accuracy: 0.3505\n",
      "Epoch 152\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 5.9285 - accuracy: 0.3355 - val_loss: 5.8484 - val_accuracy: 0.3398\n",
      "Epoch 153\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 5.8616 - accuracy: 0.3559 - val_loss: 5.8498 - val_accuracy: 0.3355\n",
      "Epoch 154\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 5.7215 - accuracy: 0.3710 - val_loss: 5.8466 - val_accuracy: 0.3312\n",
      "Epoch 155\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 5.8423 - accuracy: 0.3634 - val_loss: 5.8495 - val_accuracy: 0.3290\n",
      "Epoch 156\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 5.6309 - accuracy: 0.3882 - val_loss: 5.8548 - val_accuracy: 0.3376\n",
      "Epoch 157\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 5.7485 - accuracy: 0.3688 - val_loss: 5.8559 - val_accuracy: 0.3398\n",
      "Epoch 158\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 5.6392 - accuracy: 0.3882 - val_loss: 5.8591 - val_accuracy: 0.3355\n",
      "Epoch 159\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 5.7015 - accuracy: 0.3914 - val_loss: 5.8457 - val_accuracy: 0.3441\n",
      "Epoch 160\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 5.6483 - accuracy: 0.3839 - val_loss: 5.8281 - val_accuracy: 0.3505\n",
      "Epoch 161\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.7438 - accuracy: 0.3935 - val_loss: 5.8314 - val_accuracy: 0.3505\n",
      "Epoch 162\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 5.7103 - accuracy: 0.4032 - val_loss: 5.8343 - val_accuracy: 0.3462\n",
      "Epoch 163\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 5.6402 - accuracy: 0.3882 - val_loss: 5.8292 - val_accuracy: 0.3441\n",
      "Epoch 164\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 5.6886 - accuracy: 0.3989 - val_loss: 5.8212 - val_accuracy: 0.3419\n",
      "Epoch 165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 655ms/step - loss: 5.7859 - accuracy: 0.3774 - val_loss: 5.8195 - val_accuracy: 0.3505\n",
      "Epoch 166\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 5.7272 - accuracy: 0.3925 - val_loss: 5.8295 - val_accuracy: 0.3591\n",
      "Epoch 167\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 5.5441 - accuracy: 0.4280 - val_loss: 5.8429 - val_accuracy: 0.3613\n",
      "Epoch 168\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.7127 - accuracy: 0.3774 - val_loss: 5.8558 - val_accuracy: 0.3591\n",
      "Epoch 169\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.6127 - accuracy: 0.4183 - val_loss: 5.8562 - val_accuracy: 0.3570\n",
      "Epoch 170\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.5604 - accuracy: 0.4194 - val_loss: 5.8542 - val_accuracy: 0.3484\n",
      "Epoch 171\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 5.5483 - accuracy: 0.3882 - val_loss: 5.8462 - val_accuracy: 0.3441\n",
      "Epoch 172\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 5.5637 - accuracy: 0.4000 - val_loss: 5.8422 - val_accuracy: 0.3462\n",
      "Epoch 173\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 5.4603 - accuracy: 0.4247 - val_loss: 5.8459 - val_accuracy: 0.3548\n",
      "Epoch 174\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 5.4586 - accuracy: 0.4237 - val_loss: 5.8522 - val_accuracy: 0.3441\n",
      "Epoch 175\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 5.5670 - accuracy: 0.4269 - val_loss: 5.8556 - val_accuracy: 0.3290\n",
      "Epoch 176\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 5.5502 - accuracy: 0.4183 - val_loss: 5.8737 - val_accuracy: 0.3247\n",
      "Epoch 177\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.5563 - accuracy: 0.4452 - val_loss: 5.8914 - val_accuracy: 0.3269\n",
      "Epoch 178\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 5.5384 - accuracy: 0.4419 - val_loss: 5.8947 - val_accuracy: 0.3312\n",
      "Epoch 179\n",
      "3/3 [==============================] - 3s 652ms/step - loss: 5.4282 - accuracy: 0.4462 - val_loss: 5.9097 - val_accuracy: 0.3333\n",
      "Epoch 180\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 5.5615 - accuracy: 0.4376 - val_loss: 5.9167 - val_accuracy: 0.3333\n",
      "Epoch 181\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 5.6388 - accuracy: 0.4247 - val_loss: 5.9175 - val_accuracy: 0.3333\n",
      "Epoch 182\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 5.5407 - accuracy: 0.4430 - val_loss: 5.9149 - val_accuracy: 0.3355\n",
      "Epoch 183\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 5.3815 - accuracy: 0.4473 - val_loss: 5.9176 - val_accuracy: 0.3226\n",
      "Epoch 184\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 5.4342 - accuracy: 0.4344 - val_loss: 5.9173 - val_accuracy: 0.3290\n",
      "Epoch 185\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 5.4539 - accuracy: 0.4355 - val_loss: 5.9207 - val_accuracy: 0.3312\n",
      "Epoch 186\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.3060 - accuracy: 0.4570 - val_loss: 5.9014 - val_accuracy: 0.3398\n",
      "Epoch 187\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 5.3716 - accuracy: 0.4581 - val_loss: 5.8846 - val_accuracy: 0.3505\n",
      "Epoch 188\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 5.3714 - accuracy: 0.4570 - val_loss: 5.8802 - val_accuracy: 0.3591\n",
      "Epoch 189\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 5.3829 - accuracy: 0.4430 - val_loss: 5.8763 - val_accuracy: 0.3634\n",
      "Epoch 190\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 5.3264 - accuracy: 0.4602 - val_loss: 5.8843 - val_accuracy: 0.3570\n",
      "Epoch 191\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 5.3231 - accuracy: 0.4645 - val_loss: 5.8811 - val_accuracy: 0.3570\n",
      "Epoch 192\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 5.2873 - accuracy: 0.4591 - val_loss: 5.8764 - val_accuracy: 0.3505\n",
      "Epoch 193\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 5.3263 - accuracy: 0.4613 - val_loss: 5.8728 - val_accuracy: 0.3527\n",
      "Epoch 194\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 5.3603 - accuracy: 0.4591 - val_loss: 5.8825 - val_accuracy: 0.3398\n",
      "Epoch 195\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 5.2960 - accuracy: 0.4817 - val_loss: 5.8852 - val_accuracy: 0.3290\n",
      "Epoch 196\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 5.3708 - accuracy: 0.4495 - val_loss: 5.8952 - val_accuracy: 0.3269\n",
      "Epoch 197\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 5.3291 - accuracy: 0.4753 - val_loss: 5.9039 - val_accuracy: 0.3290\n",
      "Epoch 198\n",
      "3/3 [==============================] - 3s 777ms/step - loss: 5.2142 - accuracy: 0.4731 - val_loss: 5.9037 - val_accuracy: 0.3398\n",
      "Epoch 199\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 5.4023 - accuracy: 0.4591 - val_loss: 5.8935 - val_accuracy: 0.3376\n",
      "Epoch 200\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 5.4271 - accuracy: 0.4516 - val_loss: 5.8893 - val_accuracy: 0.3333\n",
      "Epoch 201\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 5.2297 - accuracy: 0.4806 - val_loss: 5.8901 - val_accuracy: 0.3376\n",
      "Epoch 202\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 5.2163 - accuracy: 0.4753 - val_loss: 5.8842 - val_accuracy: 0.3376\n",
      "Epoch 203\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 5.2044 - accuracy: 0.4688 - val_loss: 5.8811 - val_accuracy: 0.3376\n",
      "Epoch 204\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 5.3215 - accuracy: 0.4763 - val_loss: 5.8901 - val_accuracy: 0.3333\n",
      "Epoch 205\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 5.1681 - accuracy: 0.4989 - val_loss: 5.8887 - val_accuracy: 0.3441\n",
      "Epoch 206\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 5.2106 - accuracy: 0.4892 - val_loss: 5.8830 - val_accuracy: 0.3419\n",
      "Epoch 207\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 5.1370 - accuracy: 0.5032 - val_loss: 5.8558 - val_accuracy: 0.3462\n",
      "Epoch 208\n",
      "3/3 [==============================] - 3s 787ms/step - loss: 5.2570 - accuracy: 0.4860 - val_loss: 5.8393 - val_accuracy: 0.3484\n",
      "Epoch 209\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 5.1860 - accuracy: 0.4935 - val_loss: 5.8351 - val_accuracy: 0.3591\n",
      "Epoch 210\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 5.2319 - accuracy: 0.4849 - val_loss: 5.8431 - val_accuracy: 0.3548\n",
      "Epoch 211\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 5.2450 - accuracy: 0.5065 - val_loss: 5.8502 - val_accuracy: 0.3548\n",
      "Epoch 212\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 5.1154 - accuracy: 0.5075 - val_loss: 5.8641 - val_accuracy: 0.3441\n",
      "Epoch 213\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 5.1374 - accuracy: 0.5172 - val_loss: 5.8742 - val_accuracy: 0.3376\n",
      "Epoch 214\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 5.1834 - accuracy: 0.5032 - val_loss: 5.8796 - val_accuracy: 0.3312\n",
      "Epoch 215\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 5.0867 - accuracy: 0.5000 - val_loss: 5.8694 - val_accuracy: 0.3312\n",
      "Epoch 216\n",
      "3/3 [==============================] - 3s 718ms/step - loss: 5.0769 - accuracy: 0.4871 - val_loss: 5.8544 - val_accuracy: 0.3376\n",
      "Epoch 217\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 5.1381 - accuracy: 0.5065 - val_loss: 5.8423 - val_accuracy: 0.3398\n",
      "Epoch 218\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 5.0543 - accuracy: 0.5151 - val_loss: 5.8396 - val_accuracy: 0.3355\n",
      "Epoch 219\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 5.0426 - accuracy: 0.5258 - val_loss: 5.8485 - val_accuracy: 0.3441\n",
      "Epoch 220\n",
      "3/3 [==============================] - 3s 706ms/step - loss: 5.1504 - accuracy: 0.4914 - val_loss: 5.8453 - val_accuracy: 0.3441\n",
      "Epoch 221\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 5.1465 - accuracy: 0.4935 - val_loss: 5.8378 - val_accuracy: 0.3419\n",
      "Epoch 222\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 4.9664 - accuracy: 0.5194 - val_loss: 5.8272 - val_accuracy: 0.3355\n",
      "Epoch 223\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 5.0708 - accuracy: 0.4968 - val_loss: 5.8329 - val_accuracy: 0.3376\n",
      "Epoch 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 613ms/step - loss: 4.8991 - accuracy: 0.5194 - val_loss: 5.8306 - val_accuracy: 0.3376\n",
      "Epoch 225\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 4.9685 - accuracy: 0.5118 - val_loss: 5.8289 - val_accuracy: 0.3333\n",
      "Epoch 226\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 4.9840 - accuracy: 0.5194 - val_loss: 5.8160 - val_accuracy: 0.3505\n",
      "Epoch 227\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 5.0829 - accuracy: 0.5215 - val_loss: 5.7910 - val_accuracy: 0.3505\n",
      "Epoch 228\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 5.0589 - accuracy: 0.5108 - val_loss: 5.7748 - val_accuracy: 0.3570\n",
      "Epoch 229\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.1229 - accuracy: 0.5204 - val_loss: 5.7760 - val_accuracy: 0.3505\n",
      "Epoch 230\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 5.0013 - accuracy: 0.5247 - val_loss: 5.7806 - val_accuracy: 0.3613\n",
      "Epoch 231\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 4.8667 - accuracy: 0.5419 - val_loss: 5.7724 - val_accuracy: 0.3591\n",
      "Epoch 232\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 4.9179 - accuracy: 0.5430 - val_loss: 5.7539 - val_accuracy: 0.3591\n",
      "Epoch 233\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 4.8835 - accuracy: 0.5398 - val_loss: 5.7304 - val_accuracy: 0.3634\n",
      "Epoch 234\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 4.8997 - accuracy: 0.5441 - val_loss: 5.7059 - val_accuracy: 0.3742\n",
      "Epoch 235\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 4.8491 - accuracy: 0.5398 - val_loss: 5.6970 - val_accuracy: 0.3699\n",
      "Epoch 236\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 4.8892 - accuracy: 0.5581 - val_loss: 5.6998 - val_accuracy: 0.3613\n",
      "Epoch 237\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 4.8726 - accuracy: 0.5419 - val_loss: 5.7051 - val_accuracy: 0.3656\n",
      "Epoch 238\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 4.8603 - accuracy: 0.5301 - val_loss: 5.7009 - val_accuracy: 0.3634\n",
      "Epoch 239\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 4.9315 - accuracy: 0.5333 - val_loss: 5.6980 - val_accuracy: 0.3656\n",
      "Epoch 240\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 4.9098 - accuracy: 0.5258 - val_loss: 5.7003 - val_accuracy: 0.3656\n",
      "Epoch 241\n",
      "3/3 [==============================] - 3s 717ms/step - loss: 4.8035 - accuracy: 0.5570 - val_loss: 5.7093 - val_accuracy: 0.3720\n",
      "Epoch 242\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 4.6991 - accuracy: 0.5763 - val_loss: 5.7208 - val_accuracy: 0.3613\n",
      "Epoch 243\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 4.7820 - accuracy: 0.5645 - val_loss: 5.7368 - val_accuracy: 0.3527\n",
      "Epoch 244\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 4.9688 - accuracy: 0.5376 - val_loss: 5.7684 - val_accuracy: 0.3441\n",
      "Epoch 245\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 4.7437 - accuracy: 0.5538 - val_loss: 5.7575 - val_accuracy: 0.3484\n",
      "Epoch 246\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 4.7975 - accuracy: 0.5419 - val_loss: 5.7407 - val_accuracy: 0.3505\n",
      "Epoch 247\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 4.9578 - accuracy: 0.5548 - val_loss: 5.7296 - val_accuracy: 0.3419\n",
      "Epoch 248\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.7468 - accuracy: 0.5323 - val_loss: 5.7263 - val_accuracy: 0.3419\n",
      "Epoch 249\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 4.7354 - accuracy: 0.5656 - val_loss: 5.7375 - val_accuracy: 0.3484\n",
      "Epoch 250\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 4.7163 - accuracy: 0.5548 - val_loss: 5.7613 - val_accuracy: 0.3548\n",
      "Epoch 251\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 4.6574 - accuracy: 0.5892 - val_loss: 5.7727 - val_accuracy: 0.3591\n",
      "Epoch 252\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 4.8173 - accuracy: 0.5204 - val_loss: 5.7742 - val_accuracy: 0.3613\n",
      "Epoch 253\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 4.6493 - accuracy: 0.5710 - val_loss: 5.7542 - val_accuracy: 0.3484\n",
      "Epoch 254\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 4.8704 - accuracy: 0.5581 - val_loss: 5.7452 - val_accuracy: 0.3355\n",
      "Epoch 255\n",
      "3/3 [==============================] - 3s 665ms/step - loss: 4.6189 - accuracy: 0.5699 - val_loss: 5.7368 - val_accuracy: 0.3312\n",
      "Epoch 256\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 4.7022 - accuracy: 0.5613 - val_loss: 5.7432 - val_accuracy: 0.3376\n",
      "Epoch 257\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 4.6459 - accuracy: 0.5624 - val_loss: 5.7632 - val_accuracy: 0.3355\n",
      "Epoch 258\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 4.6281 - accuracy: 0.5817 - val_loss: 5.7812 - val_accuracy: 0.3355\n",
      "Epoch 259\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 4.7218 - accuracy: 0.5538 - val_loss: 5.7709 - val_accuracy: 0.3269\n",
      "Epoch 260\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 4.7572 - accuracy: 0.5581 - val_loss: 5.7478 - val_accuracy: 0.3312\n",
      "Epoch 261\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 4.7057 - accuracy: 0.5419 - val_loss: 5.7483 - val_accuracy: 0.3312\n",
      "Epoch 262\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 4.6618 - accuracy: 0.5602 - val_loss: 5.7515 - val_accuracy: 0.3312\n",
      "Epoch 263\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 4.6633 - accuracy: 0.5473 - val_loss: 5.7548 - val_accuracy: 0.3290\n",
      "Epoch 264\n",
      "3/3 [==============================] - 3s 783ms/step - loss: 4.5959 - accuracy: 0.5849 - val_loss: 5.7602 - val_accuracy: 0.3376\n",
      "Epoch 265\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 4.5405 - accuracy: 0.5989 - val_loss: 5.7531 - val_accuracy: 0.3441\n",
      "Epoch 266\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 4.6362 - accuracy: 0.5828 - val_loss: 5.7365 - val_accuracy: 0.3570\n",
      "Epoch 267\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 4.6397 - accuracy: 0.5645 - val_loss: 5.7160 - val_accuracy: 0.3677\n",
      "Epoch 268\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 4.4241 - accuracy: 0.6032 - val_loss: 5.7095 - val_accuracy: 0.3634\n",
      "Epoch 269\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 4.6766 - accuracy: 0.5634 - val_loss: 5.7132 - val_accuracy: 0.3591\n",
      "Epoch 270\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 4.6221 - accuracy: 0.5817 - val_loss: 5.7085 - val_accuracy: 0.3591\n",
      "Epoch 271\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 4.6003 - accuracy: 0.5774 - val_loss: 5.6973 - val_accuracy: 0.3548\n",
      "Epoch 272\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 4.5370 - accuracy: 0.5699 - val_loss: 5.6829 - val_accuracy: 0.3527\n",
      "Epoch 273\n",
      "3/3 [==============================] - 3s 774ms/step - loss: 4.5762 - accuracy: 0.5677 - val_loss: 5.6829 - val_accuracy: 0.3570\n",
      "Epoch 274\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 4.6910 - accuracy: 0.5645 - val_loss: 5.6915 - val_accuracy: 0.3527\n",
      "Epoch 275\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 4.6625 - accuracy: 0.5892 - val_loss: 5.6962 - val_accuracy: 0.3527\n",
      "Epoch 276\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 4.5495 - accuracy: 0.6011 - val_loss: 5.7065 - val_accuracy: 0.3720\n",
      "Epoch 277\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 4.5393 - accuracy: 0.5903 - val_loss: 5.6890 - val_accuracy: 0.3806\n",
      "Epoch 278\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 4.4471 - accuracy: 0.5892 - val_loss: 5.6689 - val_accuracy: 0.3849\n",
      "Epoch 279\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 4.5035 - accuracy: 0.6086 - val_loss: 5.6689 - val_accuracy: 0.3828\n",
      "Epoch 280\n",
      "3/3 [==============================] - 3s 787ms/step - loss: 4.5427 - accuracy: 0.5720 - val_loss: 5.6770 - val_accuracy: 0.3849\n",
      "Epoch 281\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 4.4552 - accuracy: 0.6129 - val_loss: 5.6830 - val_accuracy: 0.3742\n",
      "Epoch 282\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 4.3403 - accuracy: 0.6183 - val_loss: 5.6770 - val_accuracy: 0.3785\n",
      "Epoch 283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 714ms/step - loss: 4.3733 - accuracy: 0.6118 - val_loss: 5.6523 - val_accuracy: 0.3677\n",
      "Epoch 284\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 4.4082 - accuracy: 0.6140 - val_loss: 5.6358 - val_accuracy: 0.3699\n",
      "Epoch 285\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 4.3656 - accuracy: 0.5968 - val_loss: 5.6329 - val_accuracy: 0.3591\n",
      "Epoch 286\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 4.4293 - accuracy: 0.6108 - val_loss: 5.6397 - val_accuracy: 0.3570\n",
      "Epoch 287\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 4.3925 - accuracy: 0.6075 - val_loss: 5.6566 - val_accuracy: 0.3613\n",
      "Epoch 288\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 4.3517 - accuracy: 0.6172 - val_loss: 5.6697 - val_accuracy: 0.3613\n",
      "Epoch 289\n",
      "3/3 [==============================] - 3s 781ms/step - loss: 4.3835 - accuracy: 0.6000 - val_loss: 5.6817 - val_accuracy: 0.3656\n",
      "Epoch 290\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 4.4188 - accuracy: 0.5903 - val_loss: 5.6829 - val_accuracy: 0.3613\n",
      "Epoch 291\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 4.3744 - accuracy: 0.6065 - val_loss: 5.6850 - val_accuracy: 0.3613\n",
      "Epoch 292\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 4.4076 - accuracy: 0.6161 - val_loss: 5.6780 - val_accuracy: 0.3634\n",
      "Epoch 293\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 4.3154 - accuracy: 0.6151 - val_loss: 5.6785 - val_accuracy: 0.3634\n",
      "Epoch 294\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 4.3174 - accuracy: 0.6022 - val_loss: 5.6774 - val_accuracy: 0.3527\n",
      "Epoch 295\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 4.4956 - accuracy: 0.5882 - val_loss: 5.6589 - val_accuracy: 0.3570\n",
      "Epoch 296\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 4.3596 - accuracy: 0.6172 - val_loss: 5.6473 - val_accuracy: 0.3548\n",
      "Epoch 297\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 4.3673 - accuracy: 0.6075 - val_loss: 5.6417 - val_accuracy: 0.3591\n",
      "Epoch 298\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 4.2634 - accuracy: 0.6366 - val_loss: 5.6377 - val_accuracy: 0.3613\n",
      "Epoch 299\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 4.3130 - accuracy: 0.6183 - val_loss: 5.6311 - val_accuracy: 0.3634\n",
      "Epoch 300\n",
      "3/3 [==============================] - 3s 665ms/step - loss: 4.3714 - accuracy: 0.6032 - val_loss: 5.6310 - val_accuracy: 0.3720\n",
      "Epoch 301\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 4.3105 - accuracy: 0.6215 - val_loss: 5.6255 - val_accuracy: 0.3785\n",
      "Epoch 302\n",
      "3/3 [==============================] - 3s 667ms/step - loss: 4.2774 - accuracy: 0.6204 - val_loss: 5.6158 - val_accuracy: 0.3763\n",
      "Epoch 303\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.2658 - accuracy: 0.6215 - val_loss: 5.6176 - val_accuracy: 0.3720\n",
      "Epoch 304\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 4.3811 - accuracy: 0.5946 - val_loss: 5.6325 - val_accuracy: 0.3484\n",
      "Epoch 305\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 4.2559 - accuracy: 0.6129 - val_loss: 5.6308 - val_accuracy: 0.3419\n",
      "Epoch 306\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 4.2870 - accuracy: 0.6258 - val_loss: 5.6478 - val_accuracy: 0.3398\n",
      "Epoch 307\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 4.2630 - accuracy: 0.6269 - val_loss: 5.6679 - val_accuracy: 0.3441\n",
      "Epoch 308\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 4.2056 - accuracy: 0.6280 - val_loss: 5.6683 - val_accuracy: 0.3505\n",
      "Epoch 309\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 4.2839 - accuracy: 0.6226 - val_loss: 5.6623 - val_accuracy: 0.3484\n",
      "Epoch 310\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 4.1485 - accuracy: 0.6570 - val_loss: 5.6542 - val_accuracy: 0.3548\n",
      "Epoch 311\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 4.2201 - accuracy: 0.6247 - val_loss: 5.6430 - val_accuracy: 0.3613\n",
      "Epoch 312\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 4.2911 - accuracy: 0.6237 - val_loss: 5.6292 - val_accuracy: 0.3548\n",
      "Epoch 313\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 4.1980 - accuracy: 0.6194 - val_loss: 5.6317 - val_accuracy: 0.3505\n",
      "Epoch 314\n",
      "3/3 [==============================] - 3s 776ms/step - loss: 4.2439 - accuracy: 0.6280 - val_loss: 5.6428 - val_accuracy: 0.3484\n",
      "Epoch 315\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 4.1530 - accuracy: 0.6333 - val_loss: 5.6435 - val_accuracy: 0.3441\n",
      "Epoch 316\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 4.2571 - accuracy: 0.6258 - val_loss: 5.6317 - val_accuracy: 0.3505\n",
      "Epoch 317\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 4.1829 - accuracy: 0.6237 - val_loss: 5.6000 - val_accuracy: 0.3462\n",
      "Epoch 318\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 4.0873 - accuracy: 0.6473 - val_loss: 5.5757 - val_accuracy: 0.3484\n",
      "Epoch 319\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 4.1642 - accuracy: 0.6366 - val_loss: 5.5653 - val_accuracy: 0.3484\n",
      "Epoch 320\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 4.1503 - accuracy: 0.6387 - val_loss: 5.5762 - val_accuracy: 0.3419\n",
      "Epoch 321\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 4.1922 - accuracy: 0.6387 - val_loss: 5.5997 - val_accuracy: 0.3441\n",
      "Epoch 322\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 4.2731 - accuracy: 0.6151 - val_loss: 5.6207 - val_accuracy: 0.3441\n",
      "Epoch 323\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 4.1224 - accuracy: 0.6473 - val_loss: 5.6404 - val_accuracy: 0.3527\n",
      "Epoch 324\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 4.1465 - accuracy: 0.6484 - val_loss: 5.6228 - val_accuracy: 0.3634\n",
      "Epoch 325\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 4.1436 - accuracy: 0.6559 - val_loss: 5.6001 - val_accuracy: 0.3484\n",
      "Epoch 326\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 4.1214 - accuracy: 0.6269 - val_loss: 5.5796 - val_accuracy: 0.3548\n",
      "Epoch 327\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 4.0634 - accuracy: 0.6548 - val_loss: 5.5948 - val_accuracy: 0.3441\n",
      "Epoch 328\n",
      "3/3 [==============================] - 3s 802ms/step - loss: 4.0252 - accuracy: 0.6548 - val_loss: 5.6344 - val_accuracy: 0.3419\n",
      "Epoch 329\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 4.1902 - accuracy: 0.6269 - val_loss: 5.6566 - val_accuracy: 0.3441\n",
      "Epoch 330\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 4.1041 - accuracy: 0.6398 - val_loss: 5.6460 - val_accuracy: 0.3333\n",
      "Epoch 331\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 4.0351 - accuracy: 0.6258 - val_loss: 5.6031 - val_accuracy: 0.3441\n",
      "Epoch 332\n",
      "3/3 [==============================] - 3s 766ms/step - loss: 4.0030 - accuracy: 0.6559 - val_loss: 5.5926 - val_accuracy: 0.3398\n",
      "Epoch 333\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 4.0878 - accuracy: 0.6581 - val_loss: 5.5999 - val_accuracy: 0.3376\n",
      "Epoch 334\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 3.9866 - accuracy: 0.6688 - val_loss: 5.6244 - val_accuracy: 0.3441\n",
      "Epoch 335\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 4.1272 - accuracy: 0.6280 - val_loss: 5.6621 - val_accuracy: 0.3505\n",
      "Epoch 336\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 4.0571 - accuracy: 0.6333 - val_loss: 5.6606 - val_accuracy: 0.3462\n",
      "Epoch 337\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 4.0840 - accuracy: 0.6624 - val_loss: 5.6251 - val_accuracy: 0.3419\n",
      "Epoch 338\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.0843 - accuracy: 0.6430 - val_loss: 5.6034 - val_accuracy: 0.3505\n",
      "Epoch 339\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 3.9651 - accuracy: 0.6677 - val_loss: 5.6137 - val_accuracy: 0.3548\n",
      "Epoch 340\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 4.1145 - accuracy: 0.6441 - val_loss: 5.6375 - val_accuracy: 0.3591\n",
      "Epoch 341\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 4.0117 - accuracy: 0.6495 - val_loss: 5.6332 - val_accuracy: 0.3548\n",
      "Epoch 342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 633ms/step - loss: 4.0094 - accuracy: 0.6462 - val_loss: 5.6156 - val_accuracy: 0.3656\n",
      "Epoch 343\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 4.0262 - accuracy: 0.6624 - val_loss: 5.5932 - val_accuracy: 0.3677\n",
      "Epoch 344\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 4.0312 - accuracy: 0.6484 - val_loss: 5.5742 - val_accuracy: 0.3634\n",
      "Epoch 345\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 3.9616 - accuracy: 0.6484 - val_loss: 5.5623 - val_accuracy: 0.3591\n",
      "Epoch 346\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 3.9879 - accuracy: 0.6409 - val_loss: 5.5638 - val_accuracy: 0.3570\n",
      "Epoch 347\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 4.1092 - accuracy: 0.6204 - val_loss: 5.5560 - val_accuracy: 0.3613\n",
      "Epoch 348\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 4.0093 - accuracy: 0.6527 - val_loss: 5.5582 - val_accuracy: 0.3634\n",
      "Epoch 349\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 4.0018 - accuracy: 0.6430 - val_loss: 5.5926 - val_accuracy: 0.3699\n",
      "Epoch 350\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 4.1225 - accuracy: 0.6366 - val_loss: 5.5958 - val_accuracy: 0.3613\n",
      "Epoch 351\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.0016 - accuracy: 0.6452 - val_loss: 5.5733 - val_accuracy: 0.3591\n",
      "Epoch 352\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.9925 - accuracy: 0.6527 - val_loss: 5.5592 - val_accuracy: 0.3484\n",
      "Epoch 353\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.9304 - accuracy: 0.6645 - val_loss: 5.5548 - val_accuracy: 0.3441\n",
      "Epoch 354\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.9376 - accuracy: 0.6667 - val_loss: 5.5605 - val_accuracy: 0.3505\n",
      "Epoch 355\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 4.0086 - accuracy: 0.6731 - val_loss: 5.5558 - val_accuracy: 0.3462\n",
      "Epoch 356\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 3.9268 - accuracy: 0.6581 - val_loss: 5.5495 - val_accuracy: 0.3441\n",
      "Epoch 357\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.9794 - accuracy: 0.6484 - val_loss: 5.5412 - val_accuracy: 0.3462\n",
      "Epoch 358\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.9152 - accuracy: 0.6624 - val_loss: 5.5313 - val_accuracy: 0.3484\n",
      "Epoch 359\n",
      "3/3 [==============================] - 3s 653ms/step - loss: 4.0362 - accuracy: 0.6323 - val_loss: 5.5138 - val_accuracy: 0.3548\n",
      "Epoch 360\n",
      "3/3 [==============================] - 3s 655ms/step - loss: 3.9361 - accuracy: 0.6559 - val_loss: 5.4863 - val_accuracy: 0.3441\n",
      "Epoch 361\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.8363 - accuracy: 0.6774 - val_loss: 5.4836 - val_accuracy: 0.3419\n",
      "Epoch 362\n",
      "3/3 [==============================] - 3s 642ms/step - loss: 3.9371 - accuracy: 0.6430 - val_loss: 5.4838 - val_accuracy: 0.3419\n",
      "Epoch 363\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 3.9564 - accuracy: 0.6602 - val_loss: 5.4874 - val_accuracy: 0.3527\n",
      "Epoch 364\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.9042 - accuracy: 0.6602 - val_loss: 5.4815 - val_accuracy: 0.3505\n",
      "Epoch 365\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.8763 - accuracy: 0.6645 - val_loss: 5.4861 - val_accuracy: 0.3548\n",
      "Epoch 366\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 3.8018 - accuracy: 0.6839 - val_loss: 5.5173 - val_accuracy: 0.3591\n",
      "Epoch 367\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 3.8046 - accuracy: 0.6753 - val_loss: 5.5233 - val_accuracy: 0.3591\n",
      "Epoch 368\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.9455 - accuracy: 0.6462 - val_loss: 5.5090 - val_accuracy: 0.3570\n",
      "Epoch 369\n",
      "3/3 [==============================] - 3s 655ms/step - loss: 3.8190 - accuracy: 0.6742 - val_loss: 5.5134 - val_accuracy: 0.3527\n",
      "Epoch 370\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 3.8675 - accuracy: 0.6720 - val_loss: 5.5390 - val_accuracy: 0.3527\n",
      "Epoch 371\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 3.7763 - accuracy: 0.6817 - val_loss: 5.5635 - val_accuracy: 0.3527\n",
      "Epoch 372\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 3.7640 - accuracy: 0.6688 - val_loss: 5.5720 - val_accuracy: 0.3527\n",
      "Epoch 373\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.7162 - accuracy: 0.6968 - val_loss: 5.5742 - val_accuracy: 0.3441\n",
      "Epoch 374\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.8276 - accuracy: 0.6645 - val_loss: 5.5921 - val_accuracy: 0.3548\n",
      "Epoch 375\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 3.8745 - accuracy: 0.6677 - val_loss: 5.5954 - val_accuracy: 0.3484\n",
      "Epoch 376\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.9170 - accuracy: 0.6516 - val_loss: 5.5787 - val_accuracy: 0.3570\n",
      "Epoch 377\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.8829 - accuracy: 0.6624 - val_loss: 5.5619 - val_accuracy: 0.3527\n",
      "Epoch 378\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.8712 - accuracy: 0.6505 - val_loss: 5.5384 - val_accuracy: 0.3462\n",
      "Epoch 379\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 3.8131 - accuracy: 0.6849 - val_loss: 5.5226 - val_accuracy: 0.3527\n",
      "Epoch 380\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.7271 - accuracy: 0.6925 - val_loss: 5.5200 - val_accuracy: 0.3548\n",
      "Epoch 381\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.7021 - accuracy: 0.6989 - val_loss: 5.5277 - val_accuracy: 0.3484\n",
      "Epoch 382\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.7341 - accuracy: 0.6849 - val_loss: 5.5437 - val_accuracy: 0.3462\n",
      "Epoch 383\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 3.7375 - accuracy: 0.6774 - val_loss: 5.5436 - val_accuracy: 0.3505\n",
      "Epoch 384\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.6881 - accuracy: 0.6892 - val_loss: 5.5659 - val_accuracy: 0.3462\n",
      "Epoch 385\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.7410 - accuracy: 0.6957 - val_loss: 5.5773 - val_accuracy: 0.3355\n",
      "Epoch 386\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.6261 - accuracy: 0.7000 - val_loss: 5.5604 - val_accuracy: 0.3312\n",
      "Epoch 387\n",
      "3/3 [==============================] - 3s 813ms/step - loss: 3.7769 - accuracy: 0.6914 - val_loss: 5.5313 - val_accuracy: 0.3376\n",
      "Epoch 388\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 3.7317 - accuracy: 0.6731 - val_loss: 5.4807 - val_accuracy: 0.3376\n",
      "Epoch 389\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.7269 - accuracy: 0.6978 - val_loss: 5.4594 - val_accuracy: 0.3376\n",
      "Epoch 390\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.7133 - accuracy: 0.6785 - val_loss: 5.4632 - val_accuracy: 0.3441\n",
      "Epoch 391\n",
      "3/3 [==============================] - 3s 814ms/step - loss: 3.7453 - accuracy: 0.6753 - val_loss: 5.4691 - val_accuracy: 0.3441\n",
      "Epoch 392\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.7515 - accuracy: 0.6602 - val_loss: 5.4521 - val_accuracy: 0.3441\n",
      "Epoch 393\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.6575 - accuracy: 0.6957 - val_loss: 5.4286 - val_accuracy: 0.3441\n",
      "Epoch 394\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 3.6793 - accuracy: 0.6785 - val_loss: 5.4273 - val_accuracy: 0.3484\n",
      "Epoch 395\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 3.6732 - accuracy: 0.6753 - val_loss: 5.4623 - val_accuracy: 0.3376\n",
      "Epoch 396\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 3.6872 - accuracy: 0.6817 - val_loss: 5.4920 - val_accuracy: 0.3462\n",
      "Epoch 397\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 3.7092 - accuracy: 0.6914 - val_loss: 5.5017 - val_accuracy: 0.3484\n",
      "Epoch 398\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.6768 - accuracy: 0.6925 - val_loss: 5.4814 - val_accuracy: 0.3462\n",
      "Epoch 399\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.6804 - accuracy: 0.6860 - val_loss: 5.4750 - val_accuracy: 0.3441\n",
      "Epoch 400\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.5440 - accuracy: 0.7387 - val_loss: 5.4868 - val_accuracy: 0.3505\n",
      "Epoch 401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 624ms/step - loss: 3.7136 - accuracy: 0.6914 - val_loss: 5.4762 - val_accuracy: 0.3462\n",
      "Epoch 402\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.7328 - accuracy: 0.6839 - val_loss: 5.4333 - val_accuracy: 0.3548\n",
      "Epoch 403\n",
      "3/3 [==============================] - 3s 801ms/step - loss: 3.7107 - accuracy: 0.6914 - val_loss: 5.4022 - val_accuracy: 0.3484\n",
      "Epoch 404\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 3.6988 - accuracy: 0.7011 - val_loss: 5.4066 - val_accuracy: 0.3656\n",
      "Epoch 405\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.8214 - accuracy: 0.6570 - val_loss: 5.4127 - val_accuracy: 0.3634\n",
      "Epoch 406\n",
      "3/3 [==============================] - 3s 805ms/step - loss: 3.6602 - accuracy: 0.6806 - val_loss: 5.4206 - val_accuracy: 0.3527\n",
      "Epoch 407\n",
      "3/3 [==============================] - 3s 665ms/step - loss: 3.4994 - accuracy: 0.7161 - val_loss: 5.4423 - val_accuracy: 0.3527\n",
      "Epoch 408\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 3.7350 - accuracy: 0.6613 - val_loss: 5.4329 - val_accuracy: 0.3527\n",
      "Epoch 409\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 3.6392 - accuracy: 0.6806 - val_loss: 5.4457 - val_accuracy: 0.3591\n",
      "Epoch 410\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.5831 - accuracy: 0.7065 - val_loss: 5.4767 - val_accuracy: 0.3591\n",
      "Epoch 411\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.6707 - accuracy: 0.6806 - val_loss: 5.4740 - val_accuracy: 0.3548\n",
      "Epoch 412\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 3.6686 - accuracy: 0.6903 - val_loss: 5.4511 - val_accuracy: 0.3548\n",
      "Epoch 413\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 3.6923 - accuracy: 0.6860 - val_loss: 5.4454 - val_accuracy: 0.3462\n",
      "Epoch 414\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.6570 - accuracy: 0.6688 - val_loss: 5.4454 - val_accuracy: 0.3398\n",
      "Epoch 415\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.5771 - accuracy: 0.6957 - val_loss: 5.4489 - val_accuracy: 0.3312\n",
      "Epoch 416\n",
      "3/3 [==============================] - 3s 652ms/step - loss: 3.6616 - accuracy: 0.6925 - val_loss: 5.4277 - val_accuracy: 0.3312\n",
      "Epoch 417\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 3.5623 - accuracy: 0.6989 - val_loss: 5.3998 - val_accuracy: 0.3376\n",
      "Epoch 418\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 3.6060 - accuracy: 0.6978 - val_loss: 5.3933 - val_accuracy: 0.3355\n",
      "Epoch 419\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 3.5161 - accuracy: 0.7043 - val_loss: 5.4069 - val_accuracy: 0.3398\n",
      "Epoch 420\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.6231 - accuracy: 0.6903 - val_loss: 5.4372 - val_accuracy: 0.3376\n",
      "Epoch 421\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 3.6187 - accuracy: 0.6925 - val_loss: 5.4568 - val_accuracy: 0.3462\n",
      "Epoch 422\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.5632 - accuracy: 0.6978 - val_loss: 5.4206 - val_accuracy: 0.3591\n",
      "Epoch 423\n",
      "3/3 [==============================] - 3s 655ms/step - loss: 3.5080 - accuracy: 0.7183 - val_loss: 5.3906 - val_accuracy: 0.3634\n",
      "Epoch 424\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 3.5026 - accuracy: 0.6925 - val_loss: 5.3644 - val_accuracy: 0.3656\n",
      "Epoch 425\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 3.5931 - accuracy: 0.7011 - val_loss: 5.3494 - val_accuracy: 0.3699\n",
      "Epoch 426\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 3.6643 - accuracy: 0.6839 - val_loss: 5.3451 - val_accuracy: 0.3699\n",
      "Epoch 427\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 3.5887 - accuracy: 0.6946 - val_loss: 5.3548 - val_accuracy: 0.3656\n",
      "Epoch 428\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 3.5880 - accuracy: 0.6882 - val_loss: 5.3778 - val_accuracy: 0.3656\n",
      "Epoch 429\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 3.4764 - accuracy: 0.7022 - val_loss: 5.3931 - val_accuracy: 0.3591\n",
      "Epoch 430\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.4898 - accuracy: 0.7032 - val_loss: 5.3933 - val_accuracy: 0.3591\n",
      "Epoch 431\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.5630 - accuracy: 0.7086 - val_loss: 5.3730 - val_accuracy: 0.3591\n",
      "Epoch 432\n",
      "3/3 [==============================] - 3s 786ms/step - loss: 3.6539 - accuracy: 0.6785 - val_loss: 5.3422 - val_accuracy: 0.3613\n",
      "Epoch 433\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 3.7401 - accuracy: 0.6602 - val_loss: 5.3411 - val_accuracy: 0.3634\n",
      "Epoch 434\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.6303 - accuracy: 0.6796 - val_loss: 5.3367 - val_accuracy: 0.3699\n",
      "Epoch 435\n",
      "3/3 [==============================] - 3s 773ms/step - loss: 3.5899 - accuracy: 0.6957 - val_loss: 5.3355 - val_accuracy: 0.3742\n",
      "Epoch 436\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 3.5468 - accuracy: 0.7075 - val_loss: 5.3269 - val_accuracy: 0.3763\n",
      "Epoch 437\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.4311 - accuracy: 0.7280 - val_loss: 5.3413 - val_accuracy: 0.3720\n",
      "Epoch 438\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 3.5329 - accuracy: 0.6978 - val_loss: 5.3505 - val_accuracy: 0.3763\n",
      "Epoch 439\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 3.5660 - accuracy: 0.6914 - val_loss: 5.3694 - val_accuracy: 0.3785\n",
      "Epoch 440\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 3.4730 - accuracy: 0.7054 - val_loss: 5.3829 - val_accuracy: 0.3634\n",
      "Epoch 441\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 3.5013 - accuracy: 0.6989 - val_loss: 5.3981 - val_accuracy: 0.3677\n",
      "Epoch 442\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 3.5568 - accuracy: 0.6860 - val_loss: 5.4098 - val_accuracy: 0.3785\n",
      "Epoch 443\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 3.5168 - accuracy: 0.7054 - val_loss: 5.4130 - val_accuracy: 0.3720\n",
      "Epoch 444\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 3.4962 - accuracy: 0.7108 - val_loss: 5.3851 - val_accuracy: 0.3763\n",
      "Epoch 445\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 3.4749 - accuracy: 0.7151 - val_loss: 5.3671 - val_accuracy: 0.3677\n",
      "Epoch 446\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 3.4748 - accuracy: 0.7075 - val_loss: 5.3644 - val_accuracy: 0.3763\n",
      "Epoch 447\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 3.5543 - accuracy: 0.7032 - val_loss: 5.3694 - val_accuracy: 0.3742\n",
      "Epoch 448\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 3.4829 - accuracy: 0.6968 - val_loss: 5.3722 - val_accuracy: 0.3699\n",
      "Epoch 449\n",
      "3/3 [==============================] - 3s 782ms/step - loss: 3.5037 - accuracy: 0.6882 - val_loss: 5.3604 - val_accuracy: 0.3634\n",
      "Epoch 450\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 3.5189 - accuracy: 0.6871 - val_loss: 5.3653 - val_accuracy: 0.3527\n",
      "Epoch 451\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 3.5316 - accuracy: 0.7000 - val_loss: 5.3744 - val_accuracy: 0.3398\n",
      "Epoch 452\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 3.5352 - accuracy: 0.7054 - val_loss: 5.3713 - val_accuracy: 0.3441\n",
      "Epoch 453\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.4423 - accuracy: 0.7000 - val_loss: 5.3865 - val_accuracy: 0.3419\n",
      "Epoch 454\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.5414 - accuracy: 0.7011 - val_loss: 5.3821 - val_accuracy: 0.3484\n",
      "Epoch 455\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.4914 - accuracy: 0.6957 - val_loss: 5.3618 - val_accuracy: 0.3527\n",
      "Epoch 456\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.3865 - accuracy: 0.7204 - val_loss: 5.3408 - val_accuracy: 0.3548\n",
      "Epoch 457\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.4726 - accuracy: 0.7108 - val_loss: 5.3254 - val_accuracy: 0.3613\n",
      "Epoch 458\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 3.4069 - accuracy: 0.7108 - val_loss: 5.3456 - val_accuracy: 0.3570\n",
      "Epoch 459\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 3.4912 - accuracy: 0.6978 - val_loss: 5.3673 - val_accuracy: 0.3462\n",
      "Epoch 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 603ms/step - loss: 3.4295 - accuracy: 0.7204 - val_loss: 5.3763 - val_accuracy: 0.3462\n",
      "Epoch 461\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.4322 - accuracy: 0.7140 - val_loss: 5.3663 - val_accuracy: 0.3548\n",
      "Epoch 462\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 3.3822 - accuracy: 0.7355 - val_loss: 5.3597 - val_accuracy: 0.3505\n",
      "Epoch 463\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 3.4184 - accuracy: 0.7280 - val_loss: 5.3746 - val_accuracy: 0.3484\n",
      "Epoch 464\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 3.4866 - accuracy: 0.7140 - val_loss: 5.3764 - val_accuracy: 0.3505\n",
      "Epoch 465\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.4562 - accuracy: 0.7355 - val_loss: 5.3726 - val_accuracy: 0.3505\n",
      "Epoch 466\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.4998 - accuracy: 0.7022 - val_loss: 5.3792 - val_accuracy: 0.3591\n",
      "Epoch 467\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 3.3369 - accuracy: 0.7430 - val_loss: 5.3576 - val_accuracy: 0.3591\n",
      "Epoch 468\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 3.4270 - accuracy: 0.7172 - val_loss: 5.3325 - val_accuracy: 0.3634\n",
      "Epoch 469\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 3.3852 - accuracy: 0.7108 - val_loss: 5.3223 - val_accuracy: 0.3677\n",
      "Epoch 470\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 3.3727 - accuracy: 0.7161 - val_loss: 5.3151 - val_accuracy: 0.3613\n",
      "Epoch 471\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 3.3826 - accuracy: 0.7344 - val_loss: 5.3380 - val_accuracy: 0.3527\n",
      "Epoch 472\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 3.4701 - accuracy: 0.7065 - val_loss: 5.3423 - val_accuracy: 0.3527\n",
      "Epoch 473\n",
      "3/3 [==============================] - 3s 785ms/step - loss: 3.4247 - accuracy: 0.7032 - val_loss: 5.3217 - val_accuracy: 0.3591\n",
      "Epoch 474\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.3100 - accuracy: 0.7204 - val_loss: 5.3176 - val_accuracy: 0.3527\n",
      "Epoch 475\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.3334 - accuracy: 0.7075 - val_loss: 5.3169 - val_accuracy: 0.3527\n",
      "Epoch 476\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.3395 - accuracy: 0.7290 - val_loss: 5.2970 - val_accuracy: 0.3591\n",
      "Epoch 477\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 3.2851 - accuracy: 0.7398 - val_loss: 5.2789 - val_accuracy: 0.3613\n",
      "Epoch 478\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 3.3831 - accuracy: 0.7269 - val_loss: 5.2544 - val_accuracy: 0.3613\n",
      "Epoch 479\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 3.3334 - accuracy: 0.7172 - val_loss: 5.2447 - val_accuracy: 0.3613\n",
      "Epoch 480\n",
      "3/3 [==============================] - 3s 772ms/step - loss: 3.3466 - accuracy: 0.7183 - val_loss: 5.2556 - val_accuracy: 0.3742\n",
      "Epoch 481\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.2433 - accuracy: 0.7376 - val_loss: 5.2739 - val_accuracy: 0.3720\n",
      "Epoch 482\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.3892 - accuracy: 0.7000 - val_loss: 5.2850 - val_accuracy: 0.3763\n",
      "Epoch 483\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.3967 - accuracy: 0.7269 - val_loss: 5.2621 - val_accuracy: 0.3699\n",
      "Epoch 484\n",
      "3/3 [==============================] - 3s 767ms/step - loss: 3.2984 - accuracy: 0.7430 - val_loss: 5.2521 - val_accuracy: 0.3742\n",
      "Epoch 485\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 3.2818 - accuracy: 0.7161 - val_loss: 5.2482 - val_accuracy: 0.3656\n",
      "Epoch 486\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 3.3860 - accuracy: 0.7097 - val_loss: 5.2411 - val_accuracy: 0.3548\n",
      "Epoch 487\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 3.2940 - accuracy: 0.7183 - val_loss: 5.2523 - val_accuracy: 0.3441\n",
      "Epoch 488\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 3.3292 - accuracy: 0.7333 - val_loss: 5.2634 - val_accuracy: 0.3462\n",
      "Epoch 489\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 3.2577 - accuracy: 0.7559 - val_loss: 5.2744 - val_accuracy: 0.3548\n",
      "Epoch 490\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 3.2723 - accuracy: 0.7247 - val_loss: 5.2846 - val_accuracy: 0.3505\n",
      "Epoch 491\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 3.3570 - accuracy: 0.7215 - val_loss: 5.2955 - val_accuracy: 0.3484\n",
      "Epoch 492\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.2587 - accuracy: 0.7376 - val_loss: 5.2935 - val_accuracy: 0.3591\n",
      "Epoch 493\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.2284 - accuracy: 0.7441 - val_loss: 5.2938 - val_accuracy: 0.3613\n",
      "Epoch 494\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 3.2824 - accuracy: 0.7452 - val_loss: 5.2614 - val_accuracy: 0.3677\n",
      "Epoch 495\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 3.2615 - accuracy: 0.7290 - val_loss: 5.2334 - val_accuracy: 0.3720\n",
      "Epoch 496\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.2808 - accuracy: 0.7462 - val_loss: 5.2389 - val_accuracy: 0.3828\n",
      "Epoch 497\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 3.2596 - accuracy: 0.7204 - val_loss: 5.2559 - val_accuracy: 0.3806\n",
      "Epoch 498\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 3.2225 - accuracy: 0.7462 - val_loss: 5.2447 - val_accuracy: 0.3742\n",
      "Epoch 499\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 3.2372 - accuracy: 0.7409 - val_loss: 5.2333 - val_accuracy: 0.3828\n",
      "Epoch 500\n",
      "3/3 [==============================] - 3s 786ms/step - loss: 3.2494 - accuracy: 0.7387 - val_loss: 5.2518 - val_accuracy: 0.3699\n",
      "Epoch 501\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 3.3324 - accuracy: 0.7151 - val_loss: 5.2439 - val_accuracy: 0.3634\n",
      "Epoch 502\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 3.2663 - accuracy: 0.7333 - val_loss: 5.2233 - val_accuracy: 0.3613\n",
      "Epoch 503\n",
      "3/3 [==============================] - 3s 806ms/step - loss: 3.2345 - accuracy: 0.7333 - val_loss: 5.2120 - val_accuracy: 0.3613\n",
      "Epoch 504\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 3.2703 - accuracy: 0.7355 - val_loss: 5.2065 - val_accuracy: 0.3505\n",
      "Epoch 505\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 3.2808 - accuracy: 0.7247 - val_loss: 5.1912 - val_accuracy: 0.3742\n",
      "Epoch 506\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 3.2534 - accuracy: 0.7269 - val_loss: 5.1735 - val_accuracy: 0.3742\n",
      "Epoch 507\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.1851 - accuracy: 0.7441 - val_loss: 5.1686 - val_accuracy: 0.3677\n",
      "Epoch 508\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.3831 - accuracy: 0.7043 - val_loss: 5.1687 - val_accuracy: 0.3785\n",
      "Epoch 509\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.2021 - accuracy: 0.7419 - val_loss: 5.1868 - val_accuracy: 0.3806\n",
      "Epoch 510\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 3.3222 - accuracy: 0.7398 - val_loss: 5.2180 - val_accuracy: 0.3806\n",
      "Epoch 511\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 3.3206 - accuracy: 0.7204 - val_loss: 5.2018 - val_accuracy: 0.3763\n",
      "Epoch 512\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 3.3050 - accuracy: 0.7204 - val_loss: 5.1797 - val_accuracy: 0.3699\n",
      "Epoch 513\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 3.2324 - accuracy: 0.7237 - val_loss: 5.1637 - val_accuracy: 0.3656\n",
      "Epoch 514\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 3.2839 - accuracy: 0.7161 - val_loss: 5.1842 - val_accuracy: 0.3548\n",
      "Epoch 515\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 3.3220 - accuracy: 0.7226 - val_loss: 5.2112 - val_accuracy: 0.3591\n",
      "Epoch 516\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 3.2488 - accuracy: 0.7269 - val_loss: 5.1992 - val_accuracy: 0.3720\n",
      "Epoch 517\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 3.2511 - accuracy: 0.7441 - val_loss: 5.1830 - val_accuracy: 0.3763\n",
      "Epoch 518\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.2205 - accuracy: 0.7473 - val_loss: 5.1765 - val_accuracy: 0.3742\n",
      "Epoch 519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 663ms/step - loss: 3.3900 - accuracy: 0.6925 - val_loss: 5.1682 - val_accuracy: 0.3613\n",
      "Epoch 520\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.3074 - accuracy: 0.7151 - val_loss: 5.1709 - val_accuracy: 0.3548\n",
      "Epoch 521\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 3.2965 - accuracy: 0.7344 - val_loss: 5.1806 - val_accuracy: 0.3613\n",
      "Epoch 522\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 3.3289 - accuracy: 0.7355 - val_loss: 5.1949 - val_accuracy: 0.3656\n",
      "Epoch 523\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.2375 - accuracy: 0.7323 - val_loss: 5.2110 - val_accuracy: 0.3677\n",
      "Epoch 524\n",
      "3/3 [==============================] - 3s 788ms/step - loss: 3.1657 - accuracy: 0.7548 - val_loss: 5.2355 - val_accuracy: 0.3720\n",
      "Epoch 525\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 3.1685 - accuracy: 0.7473 - val_loss: 5.2335 - val_accuracy: 0.3699\n",
      "Epoch 526\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 3.2080 - accuracy: 0.7290 - val_loss: 5.2159 - val_accuracy: 0.3634\n",
      "Epoch 527\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 3.1826 - accuracy: 0.7419 - val_loss: 5.2058 - val_accuracy: 0.3570\n",
      "Epoch 528\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 3.1520 - accuracy: 0.7548 - val_loss: 5.2109 - val_accuracy: 0.3613\n",
      "Epoch 529\n",
      "3/3 [==============================] - 3s 668ms/step - loss: 3.2046 - accuracy: 0.7258 - val_loss: 5.2224 - val_accuracy: 0.3634\n",
      "Epoch 530\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.2178 - accuracy: 0.7247 - val_loss: 5.2449 - val_accuracy: 0.3613\n",
      "Epoch 531\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.1882 - accuracy: 0.7344 - val_loss: 5.2345 - val_accuracy: 0.3527\n",
      "Epoch 532\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.1657 - accuracy: 0.7527 - val_loss: 5.2102 - val_accuracy: 0.3462\n",
      "Epoch 533\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.1703 - accuracy: 0.7473 - val_loss: 5.1962 - val_accuracy: 0.3441\n",
      "Epoch 534\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.2700 - accuracy: 0.7075 - val_loss: 5.2012 - val_accuracy: 0.3527\n",
      "Epoch 535\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 3.2709 - accuracy: 0.7452 - val_loss: 5.2004 - val_accuracy: 0.3570\n",
      "Epoch 536\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.2304 - accuracy: 0.7323 - val_loss: 5.1961 - val_accuracy: 0.3570\n",
      "Epoch 537\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 3.2252 - accuracy: 0.7387 - val_loss: 5.1762 - val_accuracy: 0.3613\n",
      "Epoch 538\n",
      "3/3 [==============================] - 3s 650ms/step - loss: 3.1491 - accuracy: 0.7387 - val_loss: 5.1327 - val_accuracy: 0.3742\n",
      "Epoch 539\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 3.1680 - accuracy: 0.7280 - val_loss: 5.1094 - val_accuracy: 0.3720\n",
      "Epoch 540\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 3.1571 - accuracy: 0.7312 - val_loss: 5.1299 - val_accuracy: 0.3656\n",
      "Epoch 541\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 3.1799 - accuracy: 0.7419 - val_loss: 5.1648 - val_accuracy: 0.3548\n",
      "Epoch 542\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 3.0988 - accuracy: 0.7516 - val_loss: 5.2096 - val_accuracy: 0.3656\n",
      "Epoch 543\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 3.2114 - accuracy: 0.7430 - val_loss: 5.2342 - val_accuracy: 0.3656\n",
      "Epoch 544\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 3.1987 - accuracy: 0.7129 - val_loss: 5.2270 - val_accuracy: 0.3720\n",
      "Epoch 545\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.1582 - accuracy: 0.7462 - val_loss: 5.2115 - val_accuracy: 0.3763\n",
      "Epoch 546\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.1492 - accuracy: 0.7355 - val_loss: 5.2311 - val_accuracy: 0.3763\n",
      "Epoch 547\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 3.1863 - accuracy: 0.7548 - val_loss: 5.2308 - val_accuracy: 0.3656\n",
      "Epoch 548\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 3.1856 - accuracy: 0.7344 - val_loss: 5.2159 - val_accuracy: 0.3656\n",
      "Epoch 549\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 3.2447 - accuracy: 0.7419 - val_loss: 5.2045 - val_accuracy: 0.3613\n",
      "Epoch 550\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 3.1683 - accuracy: 0.7398 - val_loss: 5.1879 - val_accuracy: 0.3634\n",
      "Epoch 551\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 3.1502 - accuracy: 0.7495 - val_loss: 5.1881 - val_accuracy: 0.3613\n",
      "Epoch 552\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.1682 - accuracy: 0.7505 - val_loss: 5.1865 - val_accuracy: 0.3548\n",
      "Epoch 553\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 3.1716 - accuracy: 0.7441 - val_loss: 5.2000 - val_accuracy: 0.3591\n",
      "Epoch 554\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 3.0305 - accuracy: 0.7699 - val_loss: 5.2108 - val_accuracy: 0.3548\n",
      "Epoch 555\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.0834 - accuracy: 0.7624 - val_loss: 5.2201 - val_accuracy: 0.3656\n",
      "Epoch 556\n",
      "3/3 [==============================] - 3s 671ms/step - loss: 3.0303 - accuracy: 0.7645 - val_loss: 5.2137 - val_accuracy: 0.3677\n",
      "Epoch 557\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 3.1057 - accuracy: 0.7430 - val_loss: 5.1992 - val_accuracy: 0.3699\n",
      "Epoch 558\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.0578 - accuracy: 0.7559 - val_loss: 5.1924 - val_accuracy: 0.3806\n",
      "Epoch 559\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.2073 - accuracy: 0.7140 - val_loss: 5.1848 - val_accuracy: 0.3849\n",
      "Epoch 560\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 3.2230 - accuracy: 0.7269 - val_loss: 5.1851 - val_accuracy: 0.3914\n",
      "Epoch 561\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 3.1896 - accuracy: 0.7269 - val_loss: 5.1859 - val_accuracy: 0.3871\n",
      "Epoch 562\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.0230 - accuracy: 0.7581 - val_loss: 5.1959 - val_accuracy: 0.3892\n",
      "Epoch 563\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.1356 - accuracy: 0.7441 - val_loss: 5.2203 - val_accuracy: 0.3720\n",
      "Epoch 564\n",
      "3/3 [==============================] - 3s 667ms/step - loss: 3.0116 - accuracy: 0.7688 - val_loss: 5.2399 - val_accuracy: 0.3742\n",
      "Epoch 565\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 3.0485 - accuracy: 0.7591 - val_loss: 5.2529 - val_accuracy: 0.3656\n",
      "Epoch 566\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 3.0871 - accuracy: 0.7548 - val_loss: 5.2627 - val_accuracy: 0.3677\n",
      "Epoch 567\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 3.0267 - accuracy: 0.7538 - val_loss: 5.2597 - val_accuracy: 0.3570\n",
      "Epoch 568\n",
      "3/3 [==============================] - 3s 790ms/step - loss: 3.1423 - accuracy: 0.7419 - val_loss: 5.2535 - val_accuracy: 0.3527\n",
      "Epoch 569\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 3.0500 - accuracy: 0.7634 - val_loss: 5.2489 - val_accuracy: 0.3591\n",
      "Epoch 570\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 3.1457 - accuracy: 0.7430 - val_loss: 5.2405 - val_accuracy: 0.3677\n",
      "Epoch 571\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 3.1358 - accuracy: 0.7376 - val_loss: 5.2382 - val_accuracy: 0.3656\n",
      "Epoch 572\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.0826 - accuracy: 0.7430 - val_loss: 5.2609 - val_accuracy: 0.3720\n",
      "Epoch 573\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 3.2361 - accuracy: 0.7043 - val_loss: 5.2824 - val_accuracy: 0.3677\n",
      "Epoch 574\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 3.0510 - accuracy: 0.7387 - val_loss: 5.2960 - val_accuracy: 0.3548\n",
      "Epoch 575\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.0707 - accuracy: 0.7559 - val_loss: 5.3153 - val_accuracy: 0.3548\n",
      "Epoch 576\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.1257 - accuracy: 0.7505 - val_loss: 5.3098 - val_accuracy: 0.3591\n",
      "Epoch 577\n",
      "3/3 [==============================] - 3s 774ms/step - loss: 3.1028 - accuracy: 0.7333 - val_loss: 5.2835 - val_accuracy: 0.3634\n",
      "Epoch 578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 629ms/step - loss: 3.0727 - accuracy: 0.7495 - val_loss: 5.2688 - val_accuracy: 0.3634\n",
      "Epoch 579\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 3.0828 - accuracy: 0.7516 - val_loss: 5.2575 - val_accuracy: 0.3634\n",
      "Epoch 580\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 3.0359 - accuracy: 0.7785 - val_loss: 5.2658 - val_accuracy: 0.3677\n",
      "Epoch 581\n",
      "3/3 [==============================] - 3s 670ms/step - loss: 3.1240 - accuracy: 0.7441 - val_loss: 5.2513 - val_accuracy: 0.3591\n",
      "Epoch 582\n",
      "3/3 [==============================] - 3s 801ms/step - loss: 3.0025 - accuracy: 0.7731 - val_loss: 5.2263 - val_accuracy: 0.3613\n",
      "Epoch 583\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 3.2135 - accuracy: 0.7237 - val_loss: 5.2061 - val_accuracy: 0.3548\n",
      "Epoch 584\n",
      "3/3 [==============================] - 3s 797ms/step - loss: 3.1251 - accuracy: 0.7409 - val_loss: 5.1787 - val_accuracy: 0.3570\n",
      "Epoch 585\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 3.1039 - accuracy: 0.7301 - val_loss: 5.1592 - val_accuracy: 0.3484\n",
      "Epoch 586\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 3.0696 - accuracy: 0.7344 - val_loss: 5.1483 - val_accuracy: 0.3634\n",
      "Epoch 587\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.0273 - accuracy: 0.7527 - val_loss: 5.1682 - val_accuracy: 0.3677\n",
      "Epoch 588\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 3.1124 - accuracy: 0.7333 - val_loss: 5.1980 - val_accuracy: 0.3677\n",
      "Epoch 589\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 3.0598 - accuracy: 0.7323 - val_loss: 5.2111 - val_accuracy: 0.3699\n",
      "Epoch 590\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 3.0716 - accuracy: 0.7441 - val_loss: 5.2205 - val_accuracy: 0.3742\n",
      "Epoch 591\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 3.1081 - accuracy: 0.7323 - val_loss: 5.2288 - val_accuracy: 0.3699\n",
      "Epoch 592\n",
      "3/3 [==============================] - 3s 733ms/step - loss: 2.9757 - accuracy: 0.7667 - val_loss: 5.2123 - val_accuracy: 0.3806\n",
      "Epoch 593\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 3.0639 - accuracy: 0.7538 - val_loss: 5.2071 - val_accuracy: 0.3742\n",
      "Epoch 594\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.1027 - accuracy: 0.7570 - val_loss: 5.2101 - val_accuracy: 0.3828\n",
      "Epoch 595\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.0437 - accuracy: 0.7613 - val_loss: 5.2203 - val_accuracy: 0.3871\n",
      "Epoch 596\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 3.0747 - accuracy: 0.7656 - val_loss: 5.1987 - val_accuracy: 0.3892\n",
      "Epoch 597\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.0125 - accuracy: 0.7484 - val_loss: 5.1749 - val_accuracy: 0.3763\n",
      "Epoch 598\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.0891 - accuracy: 0.7355 - val_loss: 5.1714 - val_accuracy: 0.3656\n",
      "Epoch 599\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 3.0204 - accuracy: 0.7667 - val_loss: 5.1994 - val_accuracy: 0.3505\n",
      "Epoch 600\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 3.1412 - accuracy: 0.7387 - val_loss: 5.2381 - val_accuracy: 0.3441\n",
      "Epoch 601\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.0702 - accuracy: 0.7548 - val_loss: 5.2321 - val_accuracy: 0.3548\n",
      "Epoch 602\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.0337 - accuracy: 0.7806 - val_loss: 5.2274 - val_accuracy: 0.3548\n",
      "Epoch 603\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.9656 - accuracy: 0.7763 - val_loss: 5.2628 - val_accuracy: 0.3570\n",
      "Epoch 604\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 3.0626 - accuracy: 0.7538 - val_loss: 5.2501 - val_accuracy: 0.3548\n",
      "Epoch 605\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.9567 - accuracy: 0.7656 - val_loss: 5.2266 - val_accuracy: 0.3548\n",
      "Epoch 606\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 3.0421 - accuracy: 0.7731 - val_loss: 5.1936 - val_accuracy: 0.3505\n",
      "Epoch 607\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.0003 - accuracy: 0.7645 - val_loss: 5.1859 - val_accuracy: 0.3419\n",
      "Epoch 608\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 2.9562 - accuracy: 0.7839 - val_loss: 5.1590 - val_accuracy: 0.3355\n",
      "Epoch 609\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 3.0102 - accuracy: 0.7505 - val_loss: 5.1499 - val_accuracy: 0.3441\n",
      "Epoch 610\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 3.0451 - accuracy: 0.7344 - val_loss: 5.1472 - val_accuracy: 0.3484\n",
      "Epoch 611\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.9580 - accuracy: 0.7570 - val_loss: 5.1452 - val_accuracy: 0.3548\n",
      "Epoch 612\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.0089 - accuracy: 0.7559 - val_loss: 5.1396 - val_accuracy: 0.3699\n",
      "Epoch 613\n",
      "3/3 [==============================] - 3s 642ms/step - loss: 3.0135 - accuracy: 0.7667 - val_loss: 5.1468 - val_accuracy: 0.3613\n",
      "Epoch 614\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 2.9429 - accuracy: 0.7613 - val_loss: 5.1607 - val_accuracy: 0.3634\n",
      "Epoch 615\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 2.9038 - accuracy: 0.7796 - val_loss: 5.2142 - val_accuracy: 0.3634\n",
      "Epoch 616\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 3.0230 - accuracy: 0.7462 - val_loss: 5.2273 - val_accuracy: 0.3613\n",
      "Epoch 617\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.0429 - accuracy: 0.7591 - val_loss: 5.2111 - val_accuracy: 0.3699\n",
      "Epoch 618\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.9578 - accuracy: 0.7688 - val_loss: 5.1892 - val_accuracy: 0.3677\n",
      "Epoch 619\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 2.9592 - accuracy: 0.7699 - val_loss: 5.1686 - val_accuracy: 0.3656\n",
      "Epoch 620\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.9827 - accuracy: 0.7656 - val_loss: 5.1626 - val_accuracy: 0.3677\n",
      "Epoch 621\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.0575 - accuracy: 0.7505 - val_loss: 5.1805 - val_accuracy: 0.3699\n",
      "Epoch 622\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 3.0137 - accuracy: 0.7398 - val_loss: 5.1869 - val_accuracy: 0.3591\n",
      "Epoch 623\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.9164 - accuracy: 0.7548 - val_loss: 5.1924 - val_accuracy: 0.3613\n",
      "Epoch 624\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 3.0100 - accuracy: 0.7570 - val_loss: 5.1951 - val_accuracy: 0.3591\n",
      "Epoch 625\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.9865 - accuracy: 0.7602 - val_loss: 5.1876 - val_accuracy: 0.3613\n",
      "Epoch 626\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 3.0443 - accuracy: 0.7419 - val_loss: 5.1797 - val_accuracy: 0.3656\n",
      "Epoch 627\n",
      "3/3 [==============================] - 3s 636ms/step - loss: 3.0003 - accuracy: 0.7473 - val_loss: 5.1697 - val_accuracy: 0.3699\n",
      "Epoch 628\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.9408 - accuracy: 0.7710 - val_loss: 5.1457 - val_accuracy: 0.3720\n",
      "Epoch 629\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 2.9238 - accuracy: 0.7742 - val_loss: 5.1189 - val_accuracy: 0.3699\n",
      "Epoch 630\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.0405 - accuracy: 0.7430 - val_loss: 5.1047 - val_accuracy: 0.3570\n",
      "Epoch 631\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 3.1152 - accuracy: 0.7387 - val_loss: 5.0932 - val_accuracy: 0.3656\n",
      "Epoch 632\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 3.0731 - accuracy: 0.7516 - val_loss: 5.0881 - val_accuracy: 0.3570\n",
      "Epoch 633\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.9903 - accuracy: 0.7882 - val_loss: 5.0852 - val_accuracy: 0.3548\n",
      "Epoch 634\n",
      "3/3 [==============================] - 3s 774ms/step - loss: 2.9911 - accuracy: 0.7591 - val_loss: 5.1127 - val_accuracy: 0.3634\n",
      "Epoch 635\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 3.0517 - accuracy: 0.7538 - val_loss: 5.1117 - val_accuracy: 0.3677\n",
      "Epoch 636\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.1148 - accuracy: 0.7344 - val_loss: 5.0800 - val_accuracy: 0.3548\n",
      "Epoch 637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 615ms/step - loss: 2.9645 - accuracy: 0.7731 - val_loss: 5.0901 - val_accuracy: 0.3570\n",
      "Epoch 638\n",
      "3/3 [==============================] - 3s 785ms/step - loss: 3.0118 - accuracy: 0.7527 - val_loss: 5.1071 - val_accuracy: 0.3591\n",
      "Epoch 639\n",
      "3/3 [==============================] - 3s 649ms/step - loss: 2.9888 - accuracy: 0.7634 - val_loss: 5.1352 - val_accuracy: 0.3613\n",
      "Epoch 640\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.9748 - accuracy: 0.7667 - val_loss: 5.1567 - val_accuracy: 0.3699\n",
      "Epoch 641\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.8606 - accuracy: 0.7785 - val_loss: 5.1575 - val_accuracy: 0.3720\n",
      "Epoch 642\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.9592 - accuracy: 0.7731 - val_loss: 5.1375 - val_accuracy: 0.3742\n",
      "Epoch 643\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 2.9506 - accuracy: 0.7731 - val_loss: 5.1219 - val_accuracy: 0.3720\n",
      "Epoch 644\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.9475 - accuracy: 0.7720 - val_loss: 5.1145 - val_accuracy: 0.3613\n",
      "Epoch 645\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.8657 - accuracy: 0.7914 - val_loss: 5.1331 - val_accuracy: 0.3613\n",
      "Epoch 646\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 2.9303 - accuracy: 0.7806 - val_loss: 5.1292 - val_accuracy: 0.3591\n",
      "Epoch 647\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.9480 - accuracy: 0.7581 - val_loss: 5.1433 - val_accuracy: 0.3527\n",
      "Epoch 648\n",
      "3/3 [==============================] - 3s 668ms/step - loss: 2.9826 - accuracy: 0.7656 - val_loss: 5.1573 - val_accuracy: 0.3462\n",
      "Epoch 649\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 2.8410 - accuracy: 0.7796 - val_loss: 5.1810 - val_accuracy: 0.3548\n",
      "Epoch 650\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 3.0207 - accuracy: 0.7548 - val_loss: 5.1585 - val_accuracy: 0.3505\n",
      "Epoch 651\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.9487 - accuracy: 0.7774 - val_loss: 5.1118 - val_accuracy: 0.3656\n",
      "Epoch 652\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.9538 - accuracy: 0.7452 - val_loss: 5.0915 - val_accuracy: 0.3591\n",
      "Epoch 653\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.9186 - accuracy: 0.7774 - val_loss: 5.0961 - val_accuracy: 0.3548\n",
      "Epoch 654\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.8790 - accuracy: 0.7699 - val_loss: 5.1210 - val_accuracy: 0.3484\n",
      "Epoch 655\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.9185 - accuracy: 0.7688 - val_loss: 5.1569 - val_accuracy: 0.3570\n",
      "Epoch 656\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 2.9788 - accuracy: 0.7376 - val_loss: 5.1887 - val_accuracy: 0.3548\n",
      "Epoch 657\n",
      "3/3 [==============================] - 3s 893ms/step - loss: 2.9476 - accuracy: 0.7710 - val_loss: 5.1823 - val_accuracy: 0.3548\n",
      "Epoch 658\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 2.9618 - accuracy: 0.7763 - val_loss: 5.1723 - val_accuracy: 0.3462\n",
      "Epoch 659\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.9856 - accuracy: 0.7602 - val_loss: 5.1857 - val_accuracy: 0.3462\n",
      "Epoch 660\n",
      "3/3 [==============================] - 3s 812ms/step - loss: 3.0262 - accuracy: 0.7505 - val_loss: 5.1950 - val_accuracy: 0.3441\n",
      "Epoch 661\n",
      "3/3 [==============================] - 3s 785ms/step - loss: 3.0235 - accuracy: 0.7538 - val_loss: 5.1929 - val_accuracy: 0.3548\n",
      "Epoch 662\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 2.9752 - accuracy: 0.7452 - val_loss: 5.1955 - val_accuracy: 0.3613\n",
      "Epoch 663\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.9271 - accuracy: 0.7624 - val_loss: 5.2145 - val_accuracy: 0.3634\n",
      "Epoch 664\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.9819 - accuracy: 0.7602 - val_loss: 5.2425 - val_accuracy: 0.3656\n",
      "Epoch 665\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.8901 - accuracy: 0.7763 - val_loss: 5.2630 - val_accuracy: 0.3720\n",
      "Epoch 666\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 2.9147 - accuracy: 0.7796 - val_loss: 5.2719 - val_accuracy: 0.3742\n",
      "Epoch 667\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 2.9534 - accuracy: 0.7570 - val_loss: 5.2544 - val_accuracy: 0.3720\n",
      "Epoch 668\n",
      "3/3 [==============================] - 3s 664ms/step - loss: 2.9865 - accuracy: 0.7570 - val_loss: 5.2311 - val_accuracy: 0.3699\n",
      "Epoch 669\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.9099 - accuracy: 0.7710 - val_loss: 5.2336 - val_accuracy: 0.3677\n",
      "Epoch 670\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.9022 - accuracy: 0.7763 - val_loss: 5.2542 - val_accuracy: 0.3742\n",
      "Epoch 671\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.9886 - accuracy: 0.7688 - val_loss: 5.2676 - val_accuracy: 0.3806\n",
      "Epoch 672\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.9462 - accuracy: 0.7710 - val_loss: 5.2409 - val_accuracy: 0.3763\n",
      "Epoch 673\n",
      "3/3 [==============================] - 3s 784ms/step - loss: 2.8107 - accuracy: 0.7946 - val_loss: 5.2081 - val_accuracy: 0.3785\n",
      "Epoch 674\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.0039 - accuracy: 0.7355 - val_loss: 5.2001 - val_accuracy: 0.3742\n",
      "Epoch 675\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 3.0378 - accuracy: 0.7538 - val_loss: 5.2052 - val_accuracy: 0.3828\n",
      "Epoch 676\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.9455 - accuracy: 0.7570 - val_loss: 5.2235 - val_accuracy: 0.3806\n",
      "Epoch 677\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.9942 - accuracy: 0.7677 - val_loss: 5.2434 - val_accuracy: 0.3634\n",
      "Epoch 678\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 2.8719 - accuracy: 0.7957 - val_loss: 5.2647 - val_accuracy: 0.3591\n",
      "Epoch 679\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.9399 - accuracy: 0.7624 - val_loss: 5.2664 - val_accuracy: 0.3613\n",
      "Epoch 680\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.9152 - accuracy: 0.7602 - val_loss: 5.2535 - val_accuracy: 0.3570\n",
      "Epoch 681\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.8992 - accuracy: 0.7731 - val_loss: 5.2343 - val_accuracy: 0.3699\n",
      "Epoch 682\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.9478 - accuracy: 0.7591 - val_loss: 5.2190 - val_accuracy: 0.3656\n",
      "Epoch 683\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.9162 - accuracy: 0.7656 - val_loss: 5.2075 - val_accuracy: 0.3763\n",
      "Epoch 684\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.9515 - accuracy: 0.7484 - val_loss: 5.2225 - val_accuracy: 0.3828\n",
      "Epoch 685\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 2.9190 - accuracy: 0.7634 - val_loss: 5.2620 - val_accuracy: 0.3763\n",
      "Epoch 686\n",
      "3/3 [==============================] - 3s 655ms/step - loss: 2.8898 - accuracy: 0.7677 - val_loss: 5.2879 - val_accuracy: 0.3613\n",
      "Epoch 687\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.9277 - accuracy: 0.7505 - val_loss: 5.2867 - val_accuracy: 0.3548\n",
      "Epoch 688\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.9113 - accuracy: 0.7699 - val_loss: 5.2850 - val_accuracy: 0.3548\n",
      "Epoch 689\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.9363 - accuracy: 0.7677 - val_loss: 5.2759 - val_accuracy: 0.3591\n",
      "Epoch 690\n",
      "3/3 [==============================] - 3s 670ms/step - loss: 2.8858 - accuracy: 0.7806 - val_loss: 5.2485 - val_accuracy: 0.3677\n",
      "Epoch 691\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 3.0172 - accuracy: 0.7301 - val_loss: 5.2033 - val_accuracy: 0.3699\n",
      "Epoch 692\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.8919 - accuracy: 0.7796 - val_loss: 5.1667 - val_accuracy: 0.3785\n",
      "Epoch 693\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.9069 - accuracy: 0.7710 - val_loss: 5.1446 - val_accuracy: 0.3699\n",
      "Epoch 694\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 2.8949 - accuracy: 0.7796 - val_loss: 5.1379 - val_accuracy: 0.3785\n",
      "Epoch 695\n",
      "3/3 [==============================] - 3s 803ms/step - loss: 3.0179 - accuracy: 0.7613 - val_loss: 5.1629 - val_accuracy: 0.3763\n",
      "Epoch 696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 664ms/step - loss: 2.9860 - accuracy: 0.7570 - val_loss: 5.2046 - val_accuracy: 0.3720\n",
      "Epoch 697\n",
      "3/3 [==============================] - 3s 793ms/step - loss: 2.8393 - accuracy: 0.7946 - val_loss: 5.2400 - val_accuracy: 0.3591\n",
      "Epoch 698\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 2.8667 - accuracy: 0.7828 - val_loss: 5.2412 - val_accuracy: 0.3441\n",
      "Epoch 699\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.9148 - accuracy: 0.7548 - val_loss: 5.2458 - val_accuracy: 0.3441\n",
      "Epoch 700\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.7568 - accuracy: 0.8054 - val_loss: 5.2601 - val_accuracy: 0.3570\n",
      "Epoch 701\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.8196 - accuracy: 0.7946 - val_loss: 5.2388 - val_accuracy: 0.3570\n",
      "Epoch 702\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.8606 - accuracy: 0.7742 - val_loss: 5.2135 - val_accuracy: 0.3548\n",
      "Epoch 703\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.8318 - accuracy: 0.7849 - val_loss: 5.1715 - val_accuracy: 0.3570\n",
      "Epoch 704\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.8423 - accuracy: 0.7785 - val_loss: 5.1529 - val_accuracy: 0.3527\n",
      "Epoch 705\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.8586 - accuracy: 0.7720 - val_loss: 5.1448 - val_accuracy: 0.3484\n",
      "Epoch 706\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.8819 - accuracy: 0.7763 - val_loss: 5.1783 - val_accuracy: 0.3333\n",
      "Epoch 707\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.9572 - accuracy: 0.7495 - val_loss: 5.1840 - val_accuracy: 0.3355\n",
      "Epoch 708\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.7975 - accuracy: 0.7806 - val_loss: 5.1943 - val_accuracy: 0.3355\n",
      "Epoch 709\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.9270 - accuracy: 0.7505 - val_loss: 5.2094 - val_accuracy: 0.3484\n",
      "Epoch 710\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.9339 - accuracy: 0.7667 - val_loss: 5.1896 - val_accuracy: 0.3527\n",
      "Epoch 711\n",
      "3/3 [==============================] - 3s 791ms/step - loss: 2.9163 - accuracy: 0.7688 - val_loss: 5.1956 - val_accuracy: 0.3527\n",
      "Epoch 712\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.7999 - accuracy: 0.7860 - val_loss: 5.1999 - val_accuracy: 0.3548\n",
      "Epoch 713\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 2.8853 - accuracy: 0.7753 - val_loss: 5.1989 - val_accuracy: 0.3548\n",
      "Epoch 714\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.8887 - accuracy: 0.7602 - val_loss: 5.1737 - val_accuracy: 0.3613\n",
      "Epoch 715\n",
      "3/3 [==============================] - 3s 661ms/step - loss: 2.9330 - accuracy: 0.7505 - val_loss: 5.1346 - val_accuracy: 0.3720\n",
      "Epoch 716\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.7735 - accuracy: 0.7817 - val_loss: 5.0919 - val_accuracy: 0.3742\n",
      "Epoch 717\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 2.8606 - accuracy: 0.7839 - val_loss: 5.0702 - val_accuracy: 0.3742\n",
      "Epoch 718\n",
      "3/3 [==============================] - 3s 668ms/step - loss: 2.8740 - accuracy: 0.7882 - val_loss: 5.0985 - val_accuracy: 0.3763\n",
      "Epoch 719\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.8845 - accuracy: 0.7710 - val_loss: 5.1287 - val_accuracy: 0.3548\n",
      "Epoch 720\n",
      "3/3 [==============================] - 3s 784ms/step - loss: 2.9009 - accuracy: 0.7742 - val_loss: 5.1555 - val_accuracy: 0.3484\n",
      "Epoch 721\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.8739 - accuracy: 0.7624 - val_loss: 5.1853 - val_accuracy: 0.3462\n",
      "Epoch 722\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.8713 - accuracy: 0.7882 - val_loss: 5.1768 - val_accuracy: 0.3355\n",
      "Epoch 723\n",
      "3/3 [==============================] - 3s 785ms/step - loss: 2.8436 - accuracy: 0.7624 - val_loss: 5.1839 - val_accuracy: 0.3419\n",
      "Epoch 724\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.8956 - accuracy: 0.7699 - val_loss: 5.2065 - val_accuracy: 0.3398\n",
      "Epoch 725\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.9004 - accuracy: 0.7634 - val_loss: 5.2170 - val_accuracy: 0.3484\n",
      "Epoch 726\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 2.8966 - accuracy: 0.7667 - val_loss: 5.1927 - val_accuracy: 0.3570\n",
      "Epoch 727\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 2.9074 - accuracy: 0.7742 - val_loss: 5.1923 - val_accuracy: 0.3548\n",
      "Epoch 728\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.8620 - accuracy: 0.7570 - val_loss: 5.1617 - val_accuracy: 0.3548\n",
      "Epoch 729\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.8078 - accuracy: 0.7925 - val_loss: 5.1219 - val_accuracy: 0.3570\n",
      "Epoch 730\n",
      "3/3 [==============================] - 3s 799ms/step - loss: 2.9188 - accuracy: 0.7742 - val_loss: 5.0957 - val_accuracy: 0.3548\n",
      "Epoch 731\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 2.8484 - accuracy: 0.7849 - val_loss: 5.1204 - val_accuracy: 0.3613\n",
      "Epoch 732\n",
      "3/3 [==============================] - 3s 670ms/step - loss: 2.8345 - accuracy: 0.7742 - val_loss: 5.1327 - val_accuracy: 0.3742\n",
      "Epoch 733\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 2.8258 - accuracy: 0.7774 - val_loss: 5.1482 - val_accuracy: 0.3656\n",
      "Epoch 734\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 2.8168 - accuracy: 0.7753 - val_loss: 5.1446 - val_accuracy: 0.3677\n",
      "Epoch 735\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.8599 - accuracy: 0.7860 - val_loss: 5.1395 - val_accuracy: 0.3720\n",
      "Epoch 736\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.9241 - accuracy: 0.7720 - val_loss: 5.1099 - val_accuracy: 0.3699\n",
      "Epoch 737\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 2.8629 - accuracy: 0.7548 - val_loss: 5.0891 - val_accuracy: 0.3763\n",
      "Epoch 738\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.8263 - accuracy: 0.7925 - val_loss: 5.0923 - val_accuracy: 0.3849\n",
      "Epoch 739\n",
      "3/3 [==============================] - 3s 671ms/step - loss: 2.8507 - accuracy: 0.7753 - val_loss: 5.0844 - val_accuracy: 0.3828\n",
      "Epoch 740\n",
      "3/3 [==============================] - 3s 639ms/step - loss: 2.8637 - accuracy: 0.7613 - val_loss: 5.0623 - val_accuracy: 0.3806\n",
      "Epoch 741\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.8066 - accuracy: 0.7925 - val_loss: 5.0542 - val_accuracy: 0.3957\n",
      "Epoch 742\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.7924 - accuracy: 0.7849 - val_loss: 5.0563 - val_accuracy: 0.3849\n",
      "Epoch 743\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.8764 - accuracy: 0.7774 - val_loss: 5.0784 - val_accuracy: 0.3742\n",
      "Epoch 744\n",
      "3/3 [==============================] - 3s 669ms/step - loss: 2.7756 - accuracy: 0.7860 - val_loss: 5.0860 - val_accuracy: 0.3677\n",
      "Epoch 745\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 2.8965 - accuracy: 0.7731 - val_loss: 5.0933 - val_accuracy: 0.3699\n",
      "Epoch 746\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.7991 - accuracy: 0.7785 - val_loss: 5.1101 - val_accuracy: 0.3656\n",
      "Epoch 747\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 2.9290 - accuracy: 0.7473 - val_loss: 5.0935 - val_accuracy: 0.3591\n",
      "Epoch 748\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.8934 - accuracy: 0.7645 - val_loss: 5.1032 - val_accuracy: 0.3785\n",
      "Epoch 749\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.8889 - accuracy: 0.7613 - val_loss: 5.1156 - val_accuracy: 0.3871\n",
      "Epoch 750\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 2.7903 - accuracy: 0.7763 - val_loss: 5.1091 - val_accuracy: 0.3785\n",
      "Epoch 751\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 2.7788 - accuracy: 0.7817 - val_loss: 5.1290 - val_accuracy: 0.3892\n",
      "Epoch 752\n",
      "3/3 [==============================] - 3s 797ms/step - loss: 2.9106 - accuracy: 0.7699 - val_loss: 5.1660 - val_accuracy: 0.3763\n",
      "Epoch 753\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.7400 - accuracy: 0.7978 - val_loss: 5.1636 - val_accuracy: 0.3785\n",
      "Epoch 754\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.7444 - accuracy: 0.7914 - val_loss: 5.1499 - val_accuracy: 0.3849\n",
      "Epoch 755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 641ms/step - loss: 2.8587 - accuracy: 0.7753 - val_loss: 5.1114 - val_accuracy: 0.3806\n",
      "Epoch 756\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.7703 - accuracy: 0.7731 - val_loss: 5.1044 - val_accuracy: 0.3742\n",
      "Epoch 757\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.9541 - accuracy: 0.7452 - val_loss: 5.0966 - val_accuracy: 0.3785\n",
      "Epoch 758\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.7380 - accuracy: 0.7989 - val_loss: 5.1134 - val_accuracy: 0.3785\n",
      "Epoch 759\n",
      "3/3 [==============================] - 3s 811ms/step - loss: 2.8857 - accuracy: 0.7677 - val_loss: 5.1242 - val_accuracy: 0.3785\n",
      "Epoch 760\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.7670 - accuracy: 0.7871 - val_loss: 5.1199 - val_accuracy: 0.3785\n",
      "Epoch 761\n",
      "3/3 [==============================] - 3s 664ms/step - loss: 2.8010 - accuracy: 0.7839 - val_loss: 5.1331 - val_accuracy: 0.3785\n",
      "Epoch 762\n",
      "3/3 [==============================] - 3s 668ms/step - loss: 2.7614 - accuracy: 0.7871 - val_loss: 5.1734 - val_accuracy: 0.3828\n",
      "Epoch 763\n",
      "3/3 [==============================] - 3s 667ms/step - loss: 2.7702 - accuracy: 0.7817 - val_loss: 5.2139 - val_accuracy: 0.3763\n",
      "Epoch 764\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.8155 - accuracy: 0.8011 - val_loss: 5.2296 - val_accuracy: 0.3763\n",
      "Epoch 765\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 2.8137 - accuracy: 0.7763 - val_loss: 5.2135 - val_accuracy: 0.3634\n",
      "Epoch 766\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.7902 - accuracy: 0.7946 - val_loss: 5.1989 - val_accuracy: 0.3548\n",
      "Epoch 767\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.7570 - accuracy: 0.7860 - val_loss: 5.1777 - val_accuracy: 0.3570\n",
      "Epoch 768\n",
      "3/3 [==============================] - 3s 665ms/step - loss: 2.7953 - accuracy: 0.7892 - val_loss: 5.1669 - val_accuracy: 0.3570\n",
      "Epoch 769\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 2.7668 - accuracy: 0.7968 - val_loss: 5.1545 - val_accuracy: 0.3613\n",
      "Epoch 770\n",
      "3/3 [==============================] - 3s 668ms/step - loss: 2.7761 - accuracy: 0.7806 - val_loss: 5.1527 - val_accuracy: 0.3634\n",
      "Epoch 771\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.9263 - accuracy: 0.7645 - val_loss: 5.1435 - val_accuracy: 0.3613\n",
      "Epoch 772\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 2.8379 - accuracy: 0.7699 - val_loss: 5.1516 - val_accuracy: 0.3591\n",
      "Epoch 773\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 2.8068 - accuracy: 0.7731 - val_loss: 5.1596 - val_accuracy: 0.3591\n",
      "Epoch 774\n",
      "3/3 [==============================] - 3s 776ms/step - loss: 2.7937 - accuracy: 0.7763 - val_loss: 5.1683 - val_accuracy: 0.3699\n",
      "Epoch 775\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.7525 - accuracy: 0.7946 - val_loss: 5.1866 - val_accuracy: 0.3591\n",
      "Epoch 776\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.8132 - accuracy: 0.7806 - val_loss: 5.1869 - val_accuracy: 0.3419\n",
      "Epoch 777\n",
      "3/3 [==============================] - 3s 664ms/step - loss: 2.7416 - accuracy: 0.7957 - val_loss: 5.1846 - val_accuracy: 0.3441\n",
      "Epoch 778\n",
      "3/3 [==============================] - 3s 630ms/step - loss: 2.7670 - accuracy: 0.7957 - val_loss: 5.1947 - val_accuracy: 0.3484\n",
      "Epoch 779\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 2.7447 - accuracy: 0.7849 - val_loss: 5.1846 - val_accuracy: 0.3462\n",
      "Epoch 780\n",
      "3/3 [==============================] - 3s 662ms/step - loss: 2.7921 - accuracy: 0.7796 - val_loss: 5.1644 - val_accuracy: 0.3527\n",
      "Epoch 781\n",
      "3/3 [==============================] - 3s 660ms/step - loss: 2.9124 - accuracy: 0.7667 - val_loss: 5.1478 - val_accuracy: 0.3591\n",
      "Epoch 782\n",
      "3/3 [==============================] - 3s 670ms/step - loss: 2.8075 - accuracy: 0.7828 - val_loss: 5.1592 - val_accuracy: 0.3591\n",
      "Epoch 783\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.7949 - accuracy: 0.7935 - val_loss: 5.1796 - val_accuracy: 0.3613\n",
      "Epoch 784\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.7826 - accuracy: 0.7871 - val_loss: 5.2023 - val_accuracy: 0.3570\n",
      "Epoch 785\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.7407 - accuracy: 0.7656 - val_loss: 5.2176 - val_accuracy: 0.3613\n",
      "Epoch 786\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.8041 - accuracy: 0.7774 - val_loss: 5.2259 - val_accuracy: 0.3613\n",
      "Epoch 787\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 2.8072 - accuracy: 0.7871 - val_loss: 5.2461 - val_accuracy: 0.3527\n",
      "Epoch 788\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 2.7950 - accuracy: 0.7806 - val_loss: 5.2567 - val_accuracy: 0.3527\n",
      "Epoch 789\n",
      "3/3 [==============================] - 3s 671ms/step - loss: 2.7361 - accuracy: 0.8011 - val_loss: 5.2561 - val_accuracy: 0.3505\n",
      "Epoch 790\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.7832 - accuracy: 0.7774 - val_loss: 5.2107 - val_accuracy: 0.3505\n",
      "Epoch 791\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 2.7317 - accuracy: 0.7925 - val_loss: 5.1660 - val_accuracy: 0.3570\n",
      "Epoch 792\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.8593 - accuracy: 0.7731 - val_loss: 5.1492 - val_accuracy: 0.3656\n",
      "Epoch 793\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 2.8494 - accuracy: 0.7720 - val_loss: 5.1556 - val_accuracy: 0.3720\n",
      "Epoch 794\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.8407 - accuracy: 0.7677 - val_loss: 5.1611 - val_accuracy: 0.3720\n",
      "Epoch 795\n",
      "3/3 [==============================] - 3s 718ms/step - loss: 2.8063 - accuracy: 0.7742 - val_loss: 5.1203 - val_accuracy: 0.3699\n",
      "Epoch 796\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.8421 - accuracy: 0.7602 - val_loss: 5.0720 - val_accuracy: 0.3720\n",
      "Epoch 797\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.7626 - accuracy: 0.7914 - val_loss: 5.0501 - val_accuracy: 0.3720\n",
      "Epoch 798\n",
      "3/3 [==============================] - 3s 796ms/step - loss: 2.8074 - accuracy: 0.7785 - val_loss: 5.0867 - val_accuracy: 0.3699\n",
      "Epoch 799\n",
      "3/3 [==============================] - 3s 663ms/step - loss: 2.7802 - accuracy: 0.7871 - val_loss: 5.1487 - val_accuracy: 0.3656\n",
      "Epoch 800\n",
      "3/3 [==============================] - 3s 664ms/step - loss: 2.7116 - accuracy: 0.8043 - val_loss: 5.2011 - val_accuracy: 0.3613\n",
      "Epoch 801\n",
      "3/3 [==============================] - 3s 667ms/step - loss: 2.7336 - accuracy: 0.8022 - val_loss: 5.2224 - val_accuracy: 0.3656\n",
      "Epoch 802\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 2.6990 - accuracy: 0.8043 - val_loss: 5.2439 - val_accuracy: 0.3505\n",
      "Epoch 803\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.7781 - accuracy: 0.7839 - val_loss: 5.2690 - val_accuracy: 0.3591\n",
      "Epoch 804\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.7723 - accuracy: 0.7946 - val_loss: 5.2802 - val_accuracy: 0.3484\n",
      "Epoch 805\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.7686 - accuracy: 0.7839 - val_loss: 5.2762 - val_accuracy: 0.3570\n",
      "Epoch 806\n",
      "3/3 [==============================] - 3s 665ms/step - loss: 2.7254 - accuracy: 0.8022 - val_loss: 5.2483 - val_accuracy: 0.3527\n",
      "Epoch 807\n",
      "3/3 [==============================] - 3s 793ms/step - loss: 2.7987 - accuracy: 0.7699 - val_loss: 5.1974 - val_accuracy: 0.3527\n",
      "Epoch 808\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.8784 - accuracy: 0.7742 - val_loss: 5.1396 - val_accuracy: 0.3484\n",
      "Epoch 809\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.7980 - accuracy: 0.7753 - val_loss: 5.1395 - val_accuracy: 0.3548\n",
      "Epoch 810\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.7380 - accuracy: 0.7968 - val_loss: 5.1688 - val_accuracy: 0.3548\n",
      "Epoch 811\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 2.7666 - accuracy: 0.7806 - val_loss: 5.1818 - val_accuracy: 0.3634\n",
      "Epoch 812\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.7662 - accuracy: 0.7774 - val_loss: 5.1755 - val_accuracy: 0.3591\n",
      "Epoch 813\n",
      "3/3 [==============================] - 3s 781ms/step - loss: 2.7177 - accuracy: 0.8032 - val_loss: 5.1415 - val_accuracy: 0.3548\n",
      "Epoch 814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 665ms/step - loss: 2.8263 - accuracy: 0.7753 - val_loss: 5.1303 - val_accuracy: 0.3591\n",
      "Epoch 815\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 2.7922 - accuracy: 0.7796 - val_loss: 5.1336 - val_accuracy: 0.3591\n",
      "Epoch 816\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.8058 - accuracy: 0.7871 - val_loss: 5.1606 - val_accuracy: 0.3570\n",
      "Epoch 817\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.7461 - accuracy: 0.7989 - val_loss: 5.1673 - val_accuracy: 0.3591\n",
      "Epoch 818\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 2.7291 - accuracy: 0.7817 - val_loss: 5.1714 - val_accuracy: 0.3613\n",
      "Epoch 819\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.6454 - accuracy: 0.8108 - val_loss: 5.1989 - val_accuracy: 0.3634\n",
      "Epoch 820\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.8760 - accuracy: 0.7581 - val_loss: 5.1950 - val_accuracy: 0.3720\n",
      "Epoch 821\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.8148 - accuracy: 0.7677 - val_loss: 5.1496 - val_accuracy: 0.3656\n",
      "Epoch 822\n",
      "3/3 [==============================] - 3s 676ms/step - loss: 2.7237 - accuracy: 0.8097 - val_loss: 5.1458 - val_accuracy: 0.3591\n",
      "Epoch 823\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.8443 - accuracy: 0.7817 - val_loss: 5.1559 - val_accuracy: 0.3419\n",
      "Epoch 824\n",
      "3/3 [==============================] - 3s 658ms/step - loss: 2.7339 - accuracy: 0.7839 - val_loss: 5.1763 - val_accuracy: 0.3505\n",
      "Epoch 825\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.8095 - accuracy: 0.7699 - val_loss: 5.1857 - val_accuracy: 0.3527\n",
      "Epoch 826\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.7471 - accuracy: 0.8022 - val_loss: 5.1657 - val_accuracy: 0.3527\n",
      "Epoch 827\n",
      "3/3 [=======================>......] - ETA: 0s - loss: 2.8030 - accuracy: 0.7611"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-725526ec24f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dnn_structure_changned\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled_trasfer_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SpeechVision/DyysarthricCNNRezaTransferLearningSD/DysarthricSpeechVision.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ideal_loss, is_dnn_structure_changned, learning_rate, max_epoch, enabled_trasfer_learning)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mideal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             history=model.fit(\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "sv.set_gpus(\"1\")\n",
    "sv.train(is_dnn_structure_changned= False, enabled_trasfer_learning=True, learning_rate=0.001, max_epoch=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner_model_M01/dyser_M01/oracle.json\n",
      "0.0001\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.2\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.2\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.2\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.2\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.2\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "dropout dropout rate updated to 0.2\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "INFO:tensorflow:Reloading Tuner from tuner_model_M01/dyser_M01/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search=RandomSearch(get_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=40,directory='tuner_model_M01',\n",
    "                          project_name=\"dyser_M01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009226604447116867\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.23488318588937973\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.23488318588937973\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.23488318588937973\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.23488318588937973\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.23488318588937973\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "dropout dropout rate updated to 0.23488318588937973\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "best hyper parameters are:\n",
      "droprate 0.23488318588937973\n",
      "first_train 2\n",
      "lr 0.009226604447116867\n"
     ]
    }
   ],
   "source": [
    "tuner_search.reload()\n",
    "model=tuner_search.get_best_models(num_models=1)[0]\n",
    "best_hps=tuner_search.get_best_hyperparameters(num_trials=1)[0]\n",
    "print('best hyper parameters are:')\n",
    "print('droprate',best_hps.get('droprate'))\n",
    "print('first_train',best_hps.get('first_train'))\n",
    "print('lr',best_hps.get('lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "droprate (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.75, 'step': None, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "first_train (Choice)\n",
      "{'default': '2', 'conditions': [], 'values': ['2', '3', '4'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 Complete [00h 03m 53s]\n",
      "val_accuracy: 0.08817204087972641\n",
      "\n",
      "Best val_accuracy So Far: 0.38279569149017334\n",
      "Total elapsed time: 02h 53m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(training_set,epochs=90,\n",
    "                    steps_per_epoch=training_set.samples/batch_size,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=test_set.samples/batch_size,\n",
    "                    workers=10,\n",
    "                    max_queue_size=10\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv.visualize_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "sv.set_gpus(\"1\")\n",
    "sv.test_generator(sv.test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
