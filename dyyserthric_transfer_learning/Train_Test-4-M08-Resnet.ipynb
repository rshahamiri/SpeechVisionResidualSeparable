{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which speaker do you want to train/test? M08\n",
      "Vocabulary Size: 155\n",
      "Setting training date...\n",
      "Found 930 images belonging to 155 classes.\n",
      "Setting testing date...\n",
      "Found 465 images belonging to 155 classes.\n"
     ]
    }
   ],
   "source": [
    "# Selected cnn-control-testing82percent with 0.5 droprate for all layers.\n",
    "# Control Training Accuracy: 92%\n",
    "# Control Validation Accuracy: 84.87\n",
    "# Control Testing Accuracy: 81.64\n",
    "# You must set speaker_name\n",
    "import utilities\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout , SpatialDropout2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Activation\n",
    "from tensorflow.keras.callbacks import History\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from  tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.regularizers import l1_l2, l1,l2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.utils import class_weight\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import pyprog\n",
    "import os\n",
    "\n",
    "def set_gpus(gpus_number=\"1,2\"):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus_number\n",
    "    \n",
    "SETTINGS_DIR = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "speaker_name=input(\"Which speaker do you want to train/test? \")\n",
    "train_set_path = SETTINGS_DIR+'/images/Dysarthric/Train/'+speaker_name\n",
    "test_set_path = SETTINGS_DIR+\"/images/Dysarthric/Test/\"+speaker_name\n",
    "dnn_file_name_structure = SETTINGS_DIR +\"/Models/cnn_\"+speaker_name+\".json\"\n",
    "training_dynamics_path = SETTINGS_DIR+'/Training Performance/TrainingDynamics'+speaker_name+'.csv'\n",
    "dnn_file_name_weights = SETTINGS_DIR +  \"/Models/cnn_weight_\"+speaker_name+\".h5\"\n",
    "\n",
    "batch_size=256\n",
    "image_input_size=(150,150)\n",
    "vocab_size = utilities.get_no_folders_in_path(test_set_path)\n",
    "print (\"Vocabulary Size:\",vocab_size)\n",
    "\n",
    "def model_compile(model,lr=0.001):\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                          optimizer=optimizers.Adam(lr),\n",
    "                          metrics=['accuracy'])\n",
    "    \n",
    "def get_model(hp):\n",
    "    droprates=hp.Float('droprate', 0.2, 0.75, sampling='linear')\n",
    "    learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
    "    first_train=hp.Choice('first_train', values=['2','3','4','5','6'])\n",
    "    model = FreezeLayers(droprates, load_model(learning_rate=learning_rate), top_unfrozen_layer_name=\"separable_conv2d_\"+ first_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_an_image(image_path, model):\n",
    "    \n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    test_image = image.load_img(image_path, target_size = image_input_size)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0) \n",
    "\n",
    "    y_pred = model.predict_classes(test_image,batch_size)[0]\n",
    "    classes =training_set.class_indices\n",
    "    for key, value in classes.items():\n",
    "        if value==y_pred:\n",
    "            break       \n",
    "\n",
    "    pred_key=utilities.dictionary .index [ utilities.dictionary  ['FILE NAME'] == key ] \n",
    "    predicted_word=utilities.dictionary .iloc[pred_key[0],0]\n",
    "    # Get true label\n",
    "    true_key=true_key=utilities.file_to_index(image_path)\n",
    "    true_word = utilities.dictionary .iloc[true_key,0]\n",
    "    #print(\"Predicted:\",predicted_word,\", True:\",true_word)\n",
    "    return predicted_word, true_word\n",
    "\n",
    "def read_epoch():\n",
    "    if os.path.exists(training_dynamics_path):\n",
    "        \n",
    "        # First check the csv file has headres and add then if missing\n",
    "        try:\n",
    "            training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "            training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        except:\n",
    "            df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "            df.columns = columns=[\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "            df.to_csv(training_dynamics_path, index=False)\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)               \n",
    "        return training_dynamics[\"Epoch\"][len(training_dynamics)-1]\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_model(learning_rate=0.001):\n",
    "    # Loading the CNN\n",
    "    json_file = open(dnn_file_name_structure, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(dnn_file_name_weights)\n",
    "    print(learning_rate)\n",
    "    model_compile(model,learning_rate)\n",
    "    return model\n",
    "\n",
    "def save_model(model,is_max_val_inclluded=False,max_val=None, ep=None):\n",
    "    # Save/overwrite the model\n",
    "    if (is_max_val_inclluded):\n",
    "        json_file_name = SETTINGS_DIR+\"/Models/cnn_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".json\"\n",
    "        wights_file_name = SETTINGS_DIR+\"/Models/cnn_weight_\"+speaker_name+\"_\"+str(max_val)+\"_\"+str(ep)+\".h5\"\n",
    "        # Delete previously stored models for this speaker\n",
    "        for directory, s, files in os.walk(SETTINGS_DIR+\"/Models/\"):\n",
    "            for f in files:\n",
    "                if speaker_name in f:\n",
    "                    file_path=directory+\"/\"+f\n",
    "                    os.remove(file_path)\n",
    "    else:\n",
    "        json_file_name = dnn_file_name_structure\n",
    "        wights_file_name = dnn_file_name_weights\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(json_file_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(wights_file_name)\n",
    "    \n",
    "def save_training_dynamics(epoch,history,with_header=False):\n",
    "    training_dynamics=pd.DataFrame(\n",
    "        data = [ [epoch, history.history['loss'][0] ,  history.history['accuracy'][0],  \n",
    "                history.history['val_loss'][0],  history.history['val_accuracy'][0] ]],\n",
    "        columns=[\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "    )\n",
    "    if (with_header):\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=True)\n",
    "    else:\n",
    "        with open(training_dynamics_path, 'a') as csv_file:\n",
    "            training_dynamics.to_csv(csv_file, header=False)\n",
    "            \n",
    "def visualize_training():\n",
    "    import matplotlib.pyplot as plt\n",
    "    if (os.path.isfile(training_dynamics_path) == False ):\n",
    "        print (\"Training dynamics file is not found.\")\n",
    "        return\n",
    "    try:\n",
    "        training_dynamics=pd.read_csv(training_dynamics_path)\n",
    "        loss_values = training_dynamics[\"TrainingLoss\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationLoss\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Ploting Accuracy\n",
    "        loss_values = training_dynamics[\"TrainingAccuracy\"]\n",
    "        val_loss_values = training_dynamics[\"ValidationAccuracy\"]\n",
    "        epochs = range(1, len (training_dynamics['Epoch'])+1)\n",
    "        plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "     \n",
    "    except:\n",
    "        df = pd.read_csv(training_dynamics_path, header=None, index_col=None)\n",
    "        df.columns = [\"\",\"Epoch\",\"TrainingLoss\", \"TrainingAccuracy\",\"ValidationLoss\",\"ValidationAccuracy\"]\n",
    "        df.to_csv(training_dynamics_path, index=False)\n",
    "        visualize_training()\n",
    "    \n",
    "def get_train_test_sets():\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "        \n",
    "        # https://fairyonice.github.io/Learn-about-ImageDataGenerator.html\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "            width_shift_range=0.30,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=False)\n",
    "        \n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # If shuffle=False then the validation results will be different from classifier.predict_generator()\n",
    "        print (\"Setting training date...\")\n",
    "        training_set = train_datagen.flow_from_directory(\n",
    "            train_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True)\n",
    "        \n",
    "        print (\"Setting testing date...\")\n",
    "        test_set = test_datagen.flow_from_directory(\n",
    "           test_set_path,\n",
    "            target_size=image_input_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "        return training_set, test_set\n",
    "    \n",
    "def test_generator(test_set_generator):\n",
    "    steps=test_set_generator.samples/batch_size\n",
    "    model = load_model()\n",
    "\n",
    "    y_pred = model.evaluate_generator(test_set_generator, steps = steps, verbose = 1)\n",
    "    y_test = test_set_generator.classes\n",
    "    correct_classifications=0\n",
    "    for pred,label in zip(y_pred, y_test):\n",
    "        if pred.argmax()==label:\n",
    "            correct_classifications+=1\n",
    "    print (\"Loss:\", y_pred[0])\n",
    "    print (\"Acuracy:\", y_pred[1] *100,\"%\")\n",
    "    return \n",
    "\n",
    "def manual_testing():\n",
    "    model = load_model() \n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/F05\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M06\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Dysarthric/Test/M10\"\n",
    "    #test_path = SETTINGS_DIR+\"/images/Control/Test\"\n",
    "    test_path=test_set_path\n",
    "    \n",
    "    correct_classifications=0\n",
    "    i=0\n",
    "    prog = pyprog.ProgressBar(\"Predicting \", \" Done\", utilities.get_no_files_in_path(test_path))\n",
    "    # Show the initial status\n",
    "    prog.update()\n",
    "    no_processed=i\n",
    "    for directory, s, files in os.walk(test_path):\n",
    "            for f in files:\n",
    "                file_path=directory+\"/\"+f\n",
    "                if (\"jpg\" in f):                \n",
    "                    predicted_word, true_word = predict_an_image(file_path,model)\n",
    "                    #print (predicted_word,true_word)\n",
    "                    if (predicted_word==true_word):\n",
    "                        correct_classifications+=1\n",
    "                    i+=1\n",
    "                    prog.set_stat(i)\n",
    "                    prog.update()\n",
    "\n",
    "    prog.end()\n",
    "    print (\"Testing acuracy:\", correct_classifications/i *100,\"%\")\n",
    "    \n",
    "def train(ideal_loss=0.01, is_dnn_structure_changned=False, learning_rate=0.001, max_epoch=50, enabled_trasfer_learning=False):\n",
    "        \n",
    "        # Check if speaker_name is set\n",
    "        if (speaker_name==\"\"):\n",
    "            print (\"Please set speaker_name and try again.\")\n",
    "            return\n",
    "            \n",
    "        is_new_dnn=False\n",
    "        \n",
    "        history = History()\n",
    "        \n",
    "        print(\"=================================================\")\n",
    "        \n",
    "        if (os.path.isfile(dnn_file_name_structure) and\n",
    "                (os.path.isfile(dnn_file_name_weights)) and \n",
    "                (is_dnn_structure_changned == False)):\n",
    "            # load the previosly trained DNN\n",
    "            if (enabled_trasfer_learning):\n",
    "                # Enable Transfer Learning\n",
    "                print (\"Transfer learning is enabled.\")\n",
    "                model = FreezeLayers(load_model(learning_rate=learning_rate),\n",
    "                                     top_unfrozen_layer_name=\"separable_conv2d_3\" ) \n",
    "            else:\n",
    "                print (\"Transer learning is disabled.\")\n",
    "                model = load_model(learning_rate=learning_rate)\n",
    "            print(\"CNN is loaded.\")\n",
    "        else:\n",
    "            # Create a new model\n",
    "            model =  get_model()                    \n",
    "            print(\"CNN is created\")\n",
    "            # Erase the training_dynamic_csv file\n",
    "            if os.path.exists(training_dynamics_path):\n",
    "                os.remove(training_dynamics_path)\n",
    "            is_new_dnn=True\n",
    "            model_compile(model)\n",
    "        \n",
    "        ep= read_epoch()+1\n",
    "        PringFrozenLayers(model)\n",
    "        history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size, epochs=1,                            \n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10, \n",
    "                             max_queue_size=10)\n",
    "        \n",
    "        save_training_dynamics(ep,history,with_header=is_new_dnn)\n",
    "       \n",
    "        max_val = history.history['val_accuracy'][0]\n",
    "        \n",
    "        while (history.history['loss'][0] >= ideal_loss):\n",
    "            print(\"Epoch\", ep)\n",
    "            history=model.fit(\n",
    "            training_set,\n",
    "            steps_per_epoch=training_set.samples/batch_size,epochs=1,\n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=test_set.samples/batch_size,\n",
    "                             workers=10,\n",
    "                             max_queue_size=10)\n",
    "\n",
    "            # Save the max model, if any            \n",
    "            if (history.history['val_accuracy'][0]>max_val):\n",
    "                max_val= history.history['val_accuracy'][0]\n",
    "                save_model(model=model,is_max_val_inclluded=True,max_val=max_val,ep=ep)\n",
    "             \n",
    "            # Save/overwrite the model\n",
    "            save_model(model)\n",
    "               \n",
    "            ep += 1\n",
    "            save_training_dynamics(ep,history,with_header=False)        \n",
    "\n",
    "            # stop the traning if certain accuracy is reached\n",
    "            #if (ep%10==0):\n",
    "                #manual_testing()   \n",
    "            #if   (history.history['val_accuracy'][0]>0.92):\n",
    "              #  break\n",
    "            if (history.history['loss'][0]<ideal_loss):\n",
    "                   break\n",
    "            \n",
    "            if (ep > max_epoch):\n",
    "                break\n",
    "\n",
    "        return history\n",
    "    \n",
    "    # Transfer learning: freeze top layers but unfreeze all layers below the given layer   \n",
    "def FreezeLayers(droprate, model, top_unfrozen_layer_name):\n",
    "    \n",
    "    model.trainable=True\n",
    "    set_trainable = False\n",
    "    for layer in model.layers:\n",
    "        # Increase dropout rate\n",
    "        if \"dropout\" in layer.name:\n",
    "            layer.rate=droprate\n",
    "            print (layer.name,\"dropout rate updated to\",layer.rate)\n",
    "        if (layer.name==top_unfrozen_layer_name):\n",
    "            set_trainable=True\n",
    "\n",
    "        if (set_trainable):\n",
    "            print (layer.name,\" NOT FREEZED\")\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            print (layer.name,\" FREEZED\")\n",
    "            layer.trainable=False\n",
    "        #if (layer.name==\"dense_1\"):\n",
    "            #layer.trainable = False\n",
    "    #model = add_new_dense(model)\n",
    "    model_compile(model)\n",
    "    return model\n",
    "\n",
    "# add a new dense layer\n",
    "def add_new_dense(model):\n",
    "    new_model=Sequential()\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.name=layer.name+\"_old\"\n",
    "        new_model.add(layer)\n",
    "    new_model.add(Dense(units = 1024, activation='relu' ))\n",
    "    new_model.add(Dropout(0.5))\n",
    "    new_model.add(Dense (units=vocab_size, activation='softmax' ))\n",
    "    return new_model\n",
    "\n",
    "def PringFrozenLayers(model):\n",
    "     for layer in model.layers:\n",
    "            print (\"Layer:\",layer.name, \"Frozen:\",not layer.trainable)\n",
    "            \n",
    "def training_restart_initalize():\n",
    "    import shutil\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_control.json\", dnn_file_name_structure)\n",
    "    shutil.copyfile(SETTINGS_DIR+\"/Models/cnn_weight_control.h5\", dnn_file_name_weights)\n",
    "    if (os.path.isfile(training_dynamics_path)):\n",
    "        os.remove(training_dynamics_path)\n",
    "    print (\"Ready for training...\")\n",
    "\n",
    "# Load X and y\n",
    "training_set, test_set =get_train_test_sets()\n",
    "\n",
    "\n",
    "!find '.' -name '*.ipynb_checkpoints' -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training...\n"
     ]
    }
   ],
   "source": [
    "# Enable this if you want to train the model for this speaker from scracth. \n",
    "# Otherwise, the previously trained model is continued training.\n",
    "# This loads the base, control model.\n",
    "training_restart_initalize()\n",
    "set_gpus(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Transfer learning is enabled.\n",
      "0.001\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.55\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.55\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "separable_conv2d_2  FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.55\n",
      "spatial_dropout2d_2  FREEZED\n",
      "batch_normalization_2  FREEZED\n",
      "max_pooling2d_1  FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.55\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.55\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "dropout dropout rate updated to 0.55\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "CNN is loaded.\n",
      "Layer: separable_conv2d Frozen: True\n",
      "Layer: spatial_dropout2d Frozen: True\n",
      "Layer: batch_normalization Frozen: True\n",
      "Layer: max_pooling2d Frozen: True\n",
      "Layer: separable_conv2d_1 Frozen: True\n",
      "Layer: spatial_dropout2d_1 Frozen: True\n",
      "Layer: batch_normalization_1 Frozen: True\n",
      "Layer: separable_conv2d_2 Frozen: True\n",
      "Layer: spatial_dropout2d_2 Frozen: True\n",
      "Layer: batch_normalization_2 Frozen: True\n",
      "Layer: max_pooling2d_1 Frozen: True\n",
      "Layer: separable_conv2d_3 Frozen: False\n",
      "Layer: spatial_dropout2d_3 Frozen: False\n",
      "Layer: batch_normalization_3 Frozen: False\n",
      "Layer: separable_conv2d_4 Frozen: False\n",
      "Layer: spatial_dropout2d_4 Frozen: False\n",
      "Layer: max_pooling2d_2 Frozen: False\n",
      "Layer: dropout Frozen: False\n",
      "Layer: flatten Frozen: False\n",
      "Layer: dense Frozen: False\n",
      "3/3 [==============================] - 6s 1s/step - loss: 6.1298 - accuracy: 0.0588 - val_loss: 1.5203 - val_accuracy: 0.6860\n",
      "Epoch 1\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 5.6606 - accuracy: 0.0462 - val_loss: 1.4316 - val_accuracy: 0.6925\n",
      "Epoch 2\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 5.6080 - accuracy: 0.0419 - val_loss: 1.5047 - val_accuracy: 0.6602\n",
      "Epoch 3\n",
      "3/3 [==============================] - 3s 700ms/step - loss: 5.3844 - accuracy: 0.0441 - val_loss: 1.6844 - val_accuracy: 0.6194\n",
      "Epoch 4\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 5.3647 - accuracy: 0.0473 - val_loss: 1.8944 - val_accuracy: 0.5742\n",
      "Epoch 5\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 5.3503 - accuracy: 0.0473 - val_loss: 2.1008 - val_accuracy: 0.5591\n",
      "Epoch 6\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 5.3002 - accuracy: 0.0366 - val_loss: 2.2700 - val_accuracy: 0.5505\n",
      "Epoch 7\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 5.3294 - accuracy: 0.0323 - val_loss: 2.4045 - val_accuracy: 0.5441\n",
      "Epoch 8\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 5.2013 - accuracy: 0.0505 - val_loss: 2.4940 - val_accuracy: 0.5527\n",
      "Epoch 9\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 5.2120 - accuracy: 0.0495 - val_loss: 2.5412 - val_accuracy: 0.5505\n",
      "Epoch 10\n",
      "3/3 [==============================] - 3s 574ms/step - loss: 5.2291 - accuracy: 0.0548 - val_loss: 2.5766 - val_accuracy: 0.5484\n",
      "Epoch 11\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 5.1493 - accuracy: 0.0548 - val_loss: 2.5996 - val_accuracy: 0.5677\n",
      "Epoch 12\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 5.1642 - accuracy: 0.0720 - val_loss: 2.6018 - val_accuracy: 0.5871\n",
      "Epoch 13\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 5.1773 - accuracy: 0.0796 - val_loss: 2.6051 - val_accuracy: 0.6022\n",
      "Epoch 14\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 5.2017 - accuracy: 0.0892 - val_loss: 2.6131 - val_accuracy: 0.6022\n",
      "Epoch 15\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 5.2923 - accuracy: 0.0763 - val_loss: 2.6421 - val_accuracy: 0.6129\n",
      "Epoch 16\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 5.2897 - accuracy: 0.0667 - val_loss: 2.6846 - val_accuracy: 0.6086\n",
      "Epoch 17\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 5.3459 - accuracy: 0.0871 - val_loss: 2.7412 - val_accuracy: 0.6129\n",
      "Epoch 18\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 5.2475 - accuracy: 0.0957 - val_loss: 2.7842 - val_accuracy: 0.6108\n",
      "Epoch 19\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 5.3134 - accuracy: 0.0957 - val_loss: 2.8341 - val_accuracy: 0.6151\n",
      "Epoch 20\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 5.2827 - accuracy: 0.1011 - val_loss: 2.8753 - val_accuracy: 0.6237\n",
      "Epoch 21\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.4751 - accuracy: 0.0935 - val_loss: 2.9106 - val_accuracy: 0.6301\n",
      "Epoch 22\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 5.3884 - accuracy: 0.0968 - val_loss: 2.9120 - val_accuracy: 0.6344\n",
      "Epoch 23\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 5.4254 - accuracy: 0.1215 - val_loss: 2.9327 - val_accuracy: 0.6473\n",
      "Epoch 24\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 5.5896 - accuracy: 0.1097 - val_loss: 2.9749 - val_accuracy: 0.6538\n",
      "Epoch 25\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 5.5601 - accuracy: 0.1118 - val_loss: 3.0517 - val_accuracy: 0.6516\n",
      "Epoch 26\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 5.6096 - accuracy: 0.1129 - val_loss: 3.1062 - val_accuracy: 0.6559\n",
      "Epoch 27\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 5.5531 - accuracy: 0.1247 - val_loss: 3.1196 - val_accuracy: 0.6602\n",
      "Epoch 28\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 5.6284 - accuracy: 0.1419 - val_loss: 3.1060 - val_accuracy: 0.6667\n",
      "Epoch 29\n",
      "3/3 [==============================] - 3s 649ms/step - loss: 5.5612 - accuracy: 0.1344 - val_loss: 3.0626 - val_accuracy: 0.6946\n",
      "Epoch 30\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 5.6634 - accuracy: 0.1344 - val_loss: 3.0465 - val_accuracy: 0.7054\n",
      "Epoch 31\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 5.6988 - accuracy: 0.1344 - val_loss: 3.0599 - val_accuracy: 0.7161\n",
      "Epoch 32\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 5.8109 - accuracy: 0.1344 - val_loss: 3.1035 - val_accuracy: 0.7161\n",
      "Epoch 33\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 5.7259 - accuracy: 0.1688 - val_loss: 3.1760 - val_accuracy: 0.7054\n",
      "Epoch 34\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 5.7630 - accuracy: 0.1495 - val_loss: 3.2130 - val_accuracy: 0.7161\n",
      "Epoch 35\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 5.6239 - accuracy: 0.1656 - val_loss: 3.2351 - val_accuracy: 0.7204\n",
      "Epoch 36\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 5.7219 - accuracy: 0.1538 - val_loss: 3.2669 - val_accuracy: 0.7333\n",
      "Epoch 37\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 5.6639 - accuracy: 0.1516 - val_loss: 3.2409 - val_accuracy: 0.7505\n",
      "Epoch 38\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 5.6729 - accuracy: 0.1753 - val_loss: 3.1732 - val_accuracy: 0.7591\n",
      "Epoch 39\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 5.7878 - accuracy: 0.1871 - val_loss: 3.1320 - val_accuracy: 0.7527\n",
      "Epoch 40\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 5.7625 - accuracy: 0.1774 - val_loss: 3.1244 - val_accuracy: 0.7548\n",
      "Epoch 41\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 5.6353 - accuracy: 0.1989 - val_loss: 3.1448 - val_accuracy: 0.7591\n",
      "Epoch 42\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 5.7639 - accuracy: 0.1828 - val_loss: 3.1595 - val_accuracy: 0.7548\n",
      "Epoch 43\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 5.6704 - accuracy: 0.1935 - val_loss: 3.1562 - val_accuracy: 0.7613\n",
      "Epoch 44\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 5.5590 - accuracy: 0.2075 - val_loss: 3.1328 - val_accuracy: 0.7613\n",
      "Epoch 45\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 5.8995 - accuracy: 0.1753 - val_loss: 3.1529 - val_accuracy: 0.7548\n",
      "Epoch 46\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 5.6735 - accuracy: 0.2065 - val_loss: 3.1650 - val_accuracy: 0.7505\n",
      "Epoch 47\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 5.6896 - accuracy: 0.2140 - val_loss: 3.1580 - val_accuracy: 0.7548\n",
      "Epoch 48\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 5.6977 - accuracy: 0.2129 - val_loss: 3.1507 - val_accuracy: 0.7699\n",
      "Epoch 49\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.5437 - accuracy: 0.2452 - val_loss: 3.1390 - val_accuracy: 0.7742\n",
      "Epoch 50\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 5.6891 - accuracy: 0.2366 - val_loss: 3.1597 - val_accuracy: 0.7806\n",
      "Epoch 51\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 5.5942 - accuracy: 0.2548 - val_loss: 3.1831 - val_accuracy: 0.7828\n",
      "Epoch 52\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 5.6749 - accuracy: 0.2419 - val_loss: 3.2072 - val_accuracy: 0.7785\n",
      "Epoch 53\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 5.7667 - accuracy: 0.2484 - val_loss: 3.2179 - val_accuracy: 0.7634\n",
      "Epoch 54\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 5.5653 - accuracy: 0.2774 - val_loss: 3.2138 - val_accuracy: 0.7763\n",
      "Epoch 55\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 5.7333 - accuracy: 0.2505 - val_loss: 3.2288 - val_accuracy: 0.7849\n",
      "Epoch 56\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 5.8552 - accuracy: 0.2473 - val_loss: 3.2578 - val_accuracy: 0.7699\n",
      "Epoch 57\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 5.6513 - accuracy: 0.2753 - val_loss: 3.2617 - val_accuracy: 0.7785\n",
      "Epoch 58\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 5.8084 - accuracy: 0.2527 - val_loss: 3.2760 - val_accuracy: 0.7806\n",
      "Epoch 59\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 5.5129 - accuracy: 0.2828 - val_loss: 3.2872 - val_accuracy: 0.7763\n",
      "Epoch 60\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 5.6530 - accuracy: 0.2763 - val_loss: 3.2914 - val_accuracy: 0.7699\n",
      "Epoch 61\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 5.5903 - accuracy: 0.2796 - val_loss: 3.3028 - val_accuracy: 0.7656\n",
      "Epoch 62\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 5.7498 - accuracy: 0.2914 - val_loss: 3.2914 - val_accuracy: 0.7720\n",
      "Epoch 63\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 5.7510 - accuracy: 0.2720 - val_loss: 3.2972 - val_accuracy: 0.7742\n",
      "Epoch 64\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 5.6390 - accuracy: 0.2968 - val_loss: 3.3032 - val_accuracy: 0.7720\n",
      "Epoch 65\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 5.7006 - accuracy: 0.2925 - val_loss: 3.3003 - val_accuracy: 0.7763\n",
      "Epoch 66\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 5.5238 - accuracy: 0.3237 - val_loss: 3.2998 - val_accuracy: 0.7806\n",
      "Epoch 67\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 5.5700 - accuracy: 0.3323 - val_loss: 3.2931 - val_accuracy: 0.7828\n",
      "Epoch 68\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 5.5704 - accuracy: 0.3204 - val_loss: 3.2889 - val_accuracy: 0.7892\n",
      "Epoch 69\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 5.5811 - accuracy: 0.3065 - val_loss: 3.3038 - val_accuracy: 0.7957\n",
      "Epoch 70\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 5.5811 - accuracy: 0.3194 - val_loss: 3.3162 - val_accuracy: 0.7871\n",
      "Epoch 71\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 5.4863 - accuracy: 0.3430 - val_loss: 3.3081 - val_accuracy: 0.7806\n",
      "Epoch 72\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 5.5155 - accuracy: 0.3258 - val_loss: 3.2917 - val_accuracy: 0.7849\n",
      "Epoch 73\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 5.7149 - accuracy: 0.3022 - val_loss: 3.3089 - val_accuracy: 0.7892\n",
      "Epoch 74\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 5.4611 - accuracy: 0.3387 - val_loss: 3.3433 - val_accuracy: 0.7871\n",
      "Epoch 75\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 5.5610 - accuracy: 0.3108 - val_loss: 3.3489 - val_accuracy: 0.7849\n",
      "Epoch 76\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 5.3847 - accuracy: 0.3634 - val_loss: 3.3435 - val_accuracy: 0.7892\n",
      "Epoch 77\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 5.6119 - accuracy: 0.3323 - val_loss: 3.3656 - val_accuracy: 0.7914\n",
      "Epoch 78\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 5.4672 - accuracy: 0.3505 - val_loss: 3.3747 - val_accuracy: 0.7806\n",
      "Epoch 79\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 5.4698 - accuracy: 0.3419 - val_loss: 3.3714 - val_accuracy: 0.7849\n",
      "Epoch 80\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 5.4539 - accuracy: 0.3538 - val_loss: 3.3782 - val_accuracy: 0.7871\n",
      "Epoch 81\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 5.4082 - accuracy: 0.3452 - val_loss: 3.3765 - val_accuracy: 0.7914\n",
      "Epoch 82\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 5.4453 - accuracy: 0.3527 - val_loss: 3.3695 - val_accuracy: 0.7935\n",
      "Epoch 83\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 5.3733 - accuracy: 0.3484 - val_loss: 3.3642 - val_accuracy: 0.8000\n",
      "Epoch 84\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 5.3510 - accuracy: 0.3710 - val_loss: 3.3715 - val_accuracy: 0.7957\n",
      "Epoch 85\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 5.2528 - accuracy: 0.3839 - val_loss: 3.3717 - val_accuracy: 0.7892\n",
      "Epoch 86\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 5.2344 - accuracy: 0.3731 - val_loss: 3.3552 - val_accuracy: 0.7935\n",
      "Epoch 87\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 5.3076 - accuracy: 0.3677 - val_loss: 3.3414 - val_accuracy: 0.7935\n",
      "Epoch 88\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 5.2944 - accuracy: 0.3968 - val_loss: 3.3366 - val_accuracy: 0.7914\n",
      "Epoch 89\n",
      "3/3 [==============================] - 3s 719ms/step - loss: 5.4151 - accuracy: 0.3720 - val_loss: 3.3306 - val_accuracy: 0.7871\n",
      "Epoch 90\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 5.4154 - accuracy: 0.3710 - val_loss: 3.3447 - val_accuracy: 0.7806\n",
      "Epoch 91\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 5.3876 - accuracy: 0.3796 - val_loss: 3.3650 - val_accuracy: 0.7849\n",
      "Epoch 92\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 5.2184 - accuracy: 0.3989 - val_loss: 3.3769 - val_accuracy: 0.7828\n",
      "Epoch 93\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 5.2442 - accuracy: 0.3828 - val_loss: 3.3756 - val_accuracy: 0.7849\n",
      "Epoch 94\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 5.2496 - accuracy: 0.4054 - val_loss: 3.3647 - val_accuracy: 0.7914\n",
      "Epoch 95\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 5.3647 - accuracy: 0.3925 - val_loss: 3.3676 - val_accuracy: 0.8000\n",
      "Epoch 96\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 5.1667 - accuracy: 0.4269 - val_loss: 3.3778 - val_accuracy: 0.8000\n",
      "Epoch 97\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 5.0739 - accuracy: 0.4140 - val_loss: 3.3835 - val_accuracy: 0.7935\n",
      "Epoch 98\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 5.0982 - accuracy: 0.4570 - val_loss: 3.3959 - val_accuracy: 0.7828\n",
      "Epoch 99\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 5.1303 - accuracy: 0.4366 - val_loss: 3.4150 - val_accuracy: 0.7892\n",
      "Epoch 100\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 5.3683 - accuracy: 0.3860 - val_loss: 3.4312 - val_accuracy: 0.7849\n",
      "Epoch 101\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 5.2176 - accuracy: 0.4323 - val_loss: 3.4445 - val_accuracy: 0.7699\n",
      "Epoch 102\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 5.1688 - accuracy: 0.4280 - val_loss: 3.4483 - val_accuracy: 0.7720\n",
      "Epoch 103\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 5.1465 - accuracy: 0.4387 - val_loss: 3.4441 - val_accuracy: 0.7763\n",
      "Epoch 104\n",
      "3/3 [==============================] - 3s 770ms/step - loss: 5.2106 - accuracy: 0.4172 - val_loss: 3.4294 - val_accuracy: 0.7806\n",
      "Epoch 105\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 5.1429 - accuracy: 0.4269 - val_loss: 3.4252 - val_accuracy: 0.7957\n",
      "Epoch 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 800ms/step - loss: 5.0652 - accuracy: 0.4570 - val_loss: 3.4369 - val_accuracy: 0.7957\n",
      "Epoch 107\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 5.0893 - accuracy: 0.4387 - val_loss: 3.4586 - val_accuracy: 0.7957\n",
      "Epoch 108\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 5.1615 - accuracy: 0.4269 - val_loss: 3.4802 - val_accuracy: 0.7871\n",
      "Epoch 109\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 4.9712 - accuracy: 0.4667 - val_loss: 3.4968 - val_accuracy: 0.7871\n",
      "Epoch 110\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 4.9665 - accuracy: 0.4688 - val_loss: 3.4943 - val_accuracy: 0.7914\n",
      "Epoch 111\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 4.9799 - accuracy: 0.4559 - val_loss: 3.4814 - val_accuracy: 0.7914\n",
      "Epoch 112\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 5.0827 - accuracy: 0.4688 - val_loss: 3.4751 - val_accuracy: 0.7785\n",
      "Epoch 113\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 5.0957 - accuracy: 0.4591 - val_loss: 3.4810 - val_accuracy: 0.7806\n",
      "Epoch 114\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 5.0353 - accuracy: 0.4527 - val_loss: 3.4968 - val_accuracy: 0.7677\n",
      "Epoch 115\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 4.9462 - accuracy: 0.4688 - val_loss: 3.5051 - val_accuracy: 0.7677\n",
      "Epoch 116\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 4.8808 - accuracy: 0.4903 - val_loss: 3.5063 - val_accuracy: 0.7720\n",
      "Epoch 117\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 5.0253 - accuracy: 0.4484 - val_loss: 3.5088 - val_accuracy: 0.7634\n",
      "Epoch 118\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 4.9864 - accuracy: 0.4688 - val_loss: 3.5210 - val_accuracy: 0.7634\n",
      "Epoch 119\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 4.8989 - accuracy: 0.4720 - val_loss: 3.5287 - val_accuracy: 0.7613\n",
      "Epoch 120\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 4.9822 - accuracy: 0.4430 - val_loss: 3.5306 - val_accuracy: 0.7570\n",
      "Epoch 121\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 4.8974 - accuracy: 0.4753 - val_loss: 3.5315 - val_accuracy: 0.7484\n",
      "Epoch 122\n",
      "3/3 [==============================] - 3s 766ms/step - loss: 4.8129 - accuracy: 0.4892 - val_loss: 3.5188 - val_accuracy: 0.7505\n",
      "Epoch 123\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 4.8558 - accuracy: 0.4849 - val_loss: 3.5131 - val_accuracy: 0.7613\n",
      "Epoch 124\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 4.9410 - accuracy: 0.4828 - val_loss: 3.5146 - val_accuracy: 0.7699\n",
      "Epoch 125\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 4.9871 - accuracy: 0.4731 - val_loss: 3.5214 - val_accuracy: 0.7591\n",
      "Epoch 126\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 4.8259 - accuracy: 0.4935 - val_loss: 3.5203 - val_accuracy: 0.7591\n",
      "Epoch 127\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 4.8626 - accuracy: 0.4882 - val_loss: 3.5128 - val_accuracy: 0.7570\n",
      "Epoch 128\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.7779 - accuracy: 0.4935 - val_loss: 3.5037 - val_accuracy: 0.7570\n",
      "Epoch 129\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 4.9099 - accuracy: 0.4946 - val_loss: 3.4880 - val_accuracy: 0.7591\n",
      "Epoch 130\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 4.7935 - accuracy: 0.5032 - val_loss: 3.4669 - val_accuracy: 0.7613\n",
      "Epoch 131\n",
      "3/3 [==============================] - 3s 804ms/step - loss: 4.7973 - accuracy: 0.4957 - val_loss: 3.4625 - val_accuracy: 0.7699\n",
      "Epoch 132\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 4.7106 - accuracy: 0.5032 - val_loss: 3.4644 - val_accuracy: 0.7742\n",
      "Epoch 133\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 4.8184 - accuracy: 0.4860 - val_loss: 3.4715 - val_accuracy: 0.7591\n",
      "Epoch 134\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 4.7104 - accuracy: 0.5183 - val_loss: 3.4651 - val_accuracy: 0.7613\n",
      "Epoch 135\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 4.7504 - accuracy: 0.4989 - val_loss: 3.4598 - val_accuracy: 0.7613\n",
      "Epoch 136\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 4.6990 - accuracy: 0.5151 - val_loss: 3.4578 - val_accuracy: 0.7677\n",
      "Epoch 137\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 4.6977 - accuracy: 0.5097 - val_loss: 3.4544 - val_accuracy: 0.7634\n",
      "Epoch 138\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 4.7108 - accuracy: 0.5161 - val_loss: 3.4640 - val_accuracy: 0.7656\n",
      "Epoch 139\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 4.7109 - accuracy: 0.5129 - val_loss: 3.4814 - val_accuracy: 0.7634\n",
      "Epoch 140\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 4.7280 - accuracy: 0.5140 - val_loss: 3.4953 - val_accuracy: 0.7548\n",
      "Epoch 141\n",
      "3/3 [==============================] - 3s 722ms/step - loss: 4.8435 - accuracy: 0.5065 - val_loss: 3.4918 - val_accuracy: 0.7570\n",
      "Epoch 142\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 4.6594 - accuracy: 0.5215 - val_loss: 3.4827 - val_accuracy: 0.7591\n",
      "Epoch 143\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 4.7123 - accuracy: 0.5161 - val_loss: 3.4797 - val_accuracy: 0.7527\n",
      "Epoch 144\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 4.7970 - accuracy: 0.4978 - val_loss: 3.4746 - val_accuracy: 0.7570\n",
      "Epoch 145\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 4.6657 - accuracy: 0.5097 - val_loss: 3.4738 - val_accuracy: 0.7591\n",
      "Epoch 146\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 4.5752 - accuracy: 0.5376 - val_loss: 3.4786 - val_accuracy: 0.7505\n",
      "Epoch 147\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 4.5920 - accuracy: 0.5258 - val_loss: 3.4853 - val_accuracy: 0.7462\n",
      "Epoch 148\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 4.5899 - accuracy: 0.5247 - val_loss: 3.4896 - val_accuracy: 0.7548\n",
      "Epoch 149\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 4.5552 - accuracy: 0.5441 - val_loss: 3.4883 - val_accuracy: 0.7570\n",
      "Epoch 150\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 4.6919 - accuracy: 0.5247 - val_loss: 3.4891 - val_accuracy: 0.7527\n",
      "Epoch 151\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 4.7020 - accuracy: 0.4946 - val_loss: 3.4805 - val_accuracy: 0.7527\n",
      "Epoch 152\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 4.5345 - accuracy: 0.5333 - val_loss: 3.4630 - val_accuracy: 0.7634\n",
      "Epoch 153\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 4.6270 - accuracy: 0.5108 - val_loss: 3.4582 - val_accuracy: 0.7677\n",
      "Epoch 154\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 4.3658 - accuracy: 0.5645 - val_loss: 3.4661 - val_accuracy: 0.7613\n",
      "Epoch 155\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 4.4309 - accuracy: 0.5570 - val_loss: 3.4722 - val_accuracy: 0.7699\n",
      "Epoch 156\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 4.6182 - accuracy: 0.5290 - val_loss: 3.4701 - val_accuracy: 0.7720\n",
      "Epoch 157\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 4.6124 - accuracy: 0.5258 - val_loss: 3.4629 - val_accuracy: 0.7677\n",
      "Epoch 158\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 4.6549 - accuracy: 0.5280 - val_loss: 3.4504 - val_accuracy: 0.7720\n",
      "Epoch 159\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 4.5196 - accuracy: 0.5667 - val_loss: 3.4378 - val_accuracy: 0.7785\n",
      "Epoch 160\n",
      "3/3 [==============================] - 3s 733ms/step - loss: 4.5593 - accuracy: 0.5344 - val_loss: 3.4349 - val_accuracy: 0.7742\n",
      "Epoch 161\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 4.4194 - accuracy: 0.5452 - val_loss: 3.4388 - val_accuracy: 0.7742\n",
      "Epoch 162\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 4.4742 - accuracy: 0.5559 - val_loss: 3.4454 - val_accuracy: 0.7785\n",
      "Epoch 163\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 4.4486 - accuracy: 0.5452 - val_loss: 3.4593 - val_accuracy: 0.7656\n",
      "Epoch 164\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 4.5015 - accuracy: 0.5333 - val_loss: 3.4770 - val_accuracy: 0.7634\n",
      "Epoch 165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 612ms/step - loss: 4.4385 - accuracy: 0.5398 - val_loss: 3.4858 - val_accuracy: 0.7613\n",
      "Epoch 166\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 4.4436 - accuracy: 0.5527 - val_loss: 3.4853 - val_accuracy: 0.7591\n",
      "Epoch 167\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 4.4017 - accuracy: 0.5505 - val_loss: 3.4814 - val_accuracy: 0.7505\n",
      "Epoch 168\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 4.4716 - accuracy: 0.5591 - val_loss: 3.4829 - val_accuracy: 0.7484\n",
      "Epoch 169\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 4.4102 - accuracy: 0.5677 - val_loss: 3.4843 - val_accuracy: 0.7484\n",
      "Epoch 170\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 4.4214 - accuracy: 0.5570 - val_loss: 3.4879 - val_accuracy: 0.7484\n",
      "Epoch 171\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 4.3590 - accuracy: 0.5710 - val_loss: 3.4865 - val_accuracy: 0.7462\n",
      "Epoch 172\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 4.3556 - accuracy: 0.5763 - val_loss: 3.4818 - val_accuracy: 0.7484\n",
      "Epoch 173\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 4.3849 - accuracy: 0.5570 - val_loss: 3.4799 - val_accuracy: 0.7484\n",
      "Epoch 174\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 4.2443 - accuracy: 0.5849 - val_loss: 3.4749 - val_accuracy: 0.7505\n",
      "Epoch 175\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 4.2625 - accuracy: 0.5602 - val_loss: 3.4682 - val_accuracy: 0.7548\n",
      "Epoch 176\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 4.3985 - accuracy: 0.5516 - val_loss: 3.4650 - val_accuracy: 0.7548\n",
      "Epoch 177\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 4.2638 - accuracy: 0.5731 - val_loss: 3.4570 - val_accuracy: 0.7591\n",
      "Epoch 178\n",
      "3/3 [==============================] - 3s 716ms/step - loss: 4.2517 - accuracy: 0.5914 - val_loss: 3.4464 - val_accuracy: 0.7613\n",
      "Epoch 179\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 4.2025 - accuracy: 0.5935 - val_loss: 3.4349 - val_accuracy: 0.7570\n",
      "Epoch 180\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 4.3287 - accuracy: 0.5742 - val_loss: 3.4171 - val_accuracy: 0.7591\n",
      "Epoch 181\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 4.2780 - accuracy: 0.5828 - val_loss: 3.4066 - val_accuracy: 0.7591\n",
      "Epoch 182\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 4.2288 - accuracy: 0.5914 - val_loss: 3.3976 - val_accuracy: 0.7613\n",
      "Epoch 183\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 4.4527 - accuracy: 0.5495 - val_loss: 3.3888 - val_accuracy: 0.7570\n",
      "Epoch 184\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 4.2908 - accuracy: 0.5656 - val_loss: 3.3709 - val_accuracy: 0.7634\n",
      "Epoch 185\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 4.2059 - accuracy: 0.5892 - val_loss: 3.3553 - val_accuracy: 0.7656\n",
      "Epoch 186\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 4.2848 - accuracy: 0.5839 - val_loss: 3.3416 - val_accuracy: 0.7656\n",
      "Epoch 187\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 4.2720 - accuracy: 0.5871 - val_loss: 3.3358 - val_accuracy: 0.7699\n",
      "Epoch 188\n",
      "3/3 [==============================] - 3s 666ms/step - loss: 4.2340 - accuracy: 0.5839 - val_loss: 3.3367 - val_accuracy: 0.7677\n",
      "Epoch 189\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 4.1287 - accuracy: 0.6043 - val_loss: 3.3381 - val_accuracy: 0.7677\n",
      "Epoch 190\n",
      "3/3 [==============================] - 3s 640ms/step - loss: 4.2507 - accuracy: 0.5753 - val_loss: 3.3385 - val_accuracy: 0.7742\n",
      "Epoch 191\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 4.3368 - accuracy: 0.5667 - val_loss: 3.3434 - val_accuracy: 0.7785\n",
      "Epoch 192\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 4.1528 - accuracy: 0.6065 - val_loss: 3.3548 - val_accuracy: 0.7720\n",
      "Epoch 193\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 4.2183 - accuracy: 0.5656 - val_loss: 3.3628 - val_accuracy: 0.7720\n",
      "Epoch 194\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 4.3176 - accuracy: 0.5839 - val_loss: 3.3593 - val_accuracy: 0.7720\n",
      "Epoch 195\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 4.0898 - accuracy: 0.6215 - val_loss: 3.3444 - val_accuracy: 0.7720\n",
      "Epoch 196\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 4.0627 - accuracy: 0.6022 - val_loss: 3.3236 - val_accuracy: 0.7763\n",
      "Epoch 197\n",
      "3/3 [==============================] - 3s 579ms/step - loss: 4.1690 - accuracy: 0.6086 - val_loss: 3.3096 - val_accuracy: 0.7763\n",
      "Epoch 198\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.9680 - accuracy: 0.6505 - val_loss: 3.3003 - val_accuracy: 0.7806\n",
      "Epoch 199\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 4.1185 - accuracy: 0.5978 - val_loss: 3.2931 - val_accuracy: 0.7763\n",
      "Epoch 200\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 4.2270 - accuracy: 0.5828 - val_loss: 3.2839 - val_accuracy: 0.7806\n",
      "Epoch 201\n",
      "3/3 [==============================] - 3s 742ms/step - loss: 4.1499 - accuracy: 0.5957 - val_loss: 3.2728 - val_accuracy: 0.7785\n",
      "Epoch 202\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 3.9660 - accuracy: 0.6140 - val_loss: 3.2722 - val_accuracy: 0.7763\n",
      "Epoch 203\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 4.0347 - accuracy: 0.6151 - val_loss: 3.2681 - val_accuracy: 0.7785\n",
      "Epoch 204\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 4.0237 - accuracy: 0.6075 - val_loss: 3.2673 - val_accuracy: 0.7742\n",
      "Epoch 205\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.9443 - accuracy: 0.6183 - val_loss: 3.2689 - val_accuracy: 0.7763\n",
      "Epoch 206\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 4.1448 - accuracy: 0.6129 - val_loss: 3.2729 - val_accuracy: 0.7806\n",
      "Epoch 207\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 4.0785 - accuracy: 0.5957 - val_loss: 3.2894 - val_accuracy: 0.7849\n",
      "Epoch 208\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.9541 - accuracy: 0.6290 - val_loss: 3.3023 - val_accuracy: 0.7742\n",
      "Epoch 209\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 3.9208 - accuracy: 0.6290 - val_loss: 3.3113 - val_accuracy: 0.7742\n",
      "Epoch 210\n",
      "3/3 [==============================] - 3s 703ms/step - loss: 4.0240 - accuracy: 0.5968 - val_loss: 3.3075 - val_accuracy: 0.7656\n",
      "Epoch 211\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 4.0123 - accuracy: 0.5978 - val_loss: 3.3012 - val_accuracy: 0.7634\n",
      "Epoch 212\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 4.0377 - accuracy: 0.6409 - val_loss: 3.2891 - val_accuracy: 0.7634\n",
      "Epoch 213\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 4.1037 - accuracy: 0.6097 - val_loss: 3.2787 - val_accuracy: 0.7656\n",
      "Epoch 214\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 3.8964 - accuracy: 0.6258 - val_loss: 3.2791 - val_accuracy: 0.7677\n",
      "Epoch 215\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.9660 - accuracy: 0.6054 - val_loss: 3.2782 - val_accuracy: 0.7656\n",
      "Epoch 216\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 3.9578 - accuracy: 0.6258 - val_loss: 3.2767 - val_accuracy: 0.7656\n",
      "Epoch 217\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 3.8676 - accuracy: 0.6419 - val_loss: 3.2697 - val_accuracy: 0.7656\n",
      "Epoch 218\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 3.9735 - accuracy: 0.6011 - val_loss: 3.2588 - val_accuracy: 0.7742\n",
      "Epoch 219\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 3.9327 - accuracy: 0.6172 - val_loss: 3.2474 - val_accuracy: 0.7742\n",
      "Epoch 220\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 3.9551 - accuracy: 0.6194 - val_loss: 3.2407 - val_accuracy: 0.7806\n",
      "Epoch 221\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.8520 - accuracy: 0.6301 - val_loss: 3.2445 - val_accuracy: 0.7806\n",
      "Epoch 222\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.9206 - accuracy: 0.6387 - val_loss: 3.2562 - val_accuracy: 0.7677\n",
      "Epoch 223\n",
      "3/3 [==============================] - 3s 777ms/step - loss: 3.7803 - accuracy: 0.6409 - val_loss: 3.2650 - val_accuracy: 0.7656\n",
      "Epoch 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 616ms/step - loss: 3.9691 - accuracy: 0.6215 - val_loss: 3.2641 - val_accuracy: 0.7699\n",
      "Epoch 225\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 4.0144 - accuracy: 0.6237 - val_loss: 3.2540 - val_accuracy: 0.7656\n",
      "Epoch 226\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.8610 - accuracy: 0.6344 - val_loss: 3.2284 - val_accuracy: 0.7656\n",
      "Epoch 227\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 3.8673 - accuracy: 0.6376 - val_loss: 3.2044 - val_accuracy: 0.7677\n",
      "Epoch 228\n",
      "3/3 [==============================] - 3s 773ms/step - loss: 3.9140 - accuracy: 0.6387 - val_loss: 3.1795 - val_accuracy: 0.7634\n",
      "Epoch 229\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 3.9182 - accuracy: 0.6226 - val_loss: 3.1702 - val_accuracy: 0.7763\n",
      "Epoch 230\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 3.8669 - accuracy: 0.6355 - val_loss: 3.1748 - val_accuracy: 0.7763\n",
      "Epoch 231\n",
      "3/3 [==============================] - 3s 775ms/step - loss: 3.8382 - accuracy: 0.6366 - val_loss: 3.1888 - val_accuracy: 0.7763\n",
      "Epoch 232\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.8348 - accuracy: 0.6559 - val_loss: 3.1971 - val_accuracy: 0.7677\n",
      "Epoch 233\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 3.8600 - accuracy: 0.6452 - val_loss: 3.1959 - val_accuracy: 0.7634\n",
      "Epoch 234\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 3.8148 - accuracy: 0.6290 - val_loss: 3.1952 - val_accuracy: 0.7656\n",
      "Epoch 235\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.7407 - accuracy: 0.6462 - val_loss: 3.1975 - val_accuracy: 0.7656\n",
      "Epoch 236\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.8161 - accuracy: 0.6344 - val_loss: 3.1922 - val_accuracy: 0.7591\n",
      "Epoch 237\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.7972 - accuracy: 0.6237 - val_loss: 3.1869 - val_accuracy: 0.7677\n",
      "Epoch 238\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.7705 - accuracy: 0.6527 - val_loss: 3.1896 - val_accuracy: 0.7677\n",
      "Epoch 239\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 3.8544 - accuracy: 0.6333 - val_loss: 3.1904 - val_accuracy: 0.7634\n",
      "Epoch 240\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.7452 - accuracy: 0.6591 - val_loss: 3.1936 - val_accuracy: 0.7570\n",
      "Epoch 241\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.7498 - accuracy: 0.6462 - val_loss: 3.1958 - val_accuracy: 0.7656\n",
      "Epoch 242\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 3.7728 - accuracy: 0.6462 - val_loss: 3.1953 - val_accuracy: 0.7677\n",
      "Epoch 243\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 3.7644 - accuracy: 0.6441 - val_loss: 3.1899 - val_accuracy: 0.7742\n",
      "Epoch 244\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 3.7016 - accuracy: 0.6656 - val_loss: 3.1828 - val_accuracy: 0.7763\n",
      "Epoch 245\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 3.7098 - accuracy: 0.6355 - val_loss: 3.1807 - val_accuracy: 0.7763\n",
      "Epoch 246\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 3.7289 - accuracy: 0.6699 - val_loss: 3.1857 - val_accuracy: 0.7699\n",
      "Epoch 247\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.6533 - accuracy: 0.6613 - val_loss: 3.1833 - val_accuracy: 0.7677\n",
      "Epoch 248\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 3.7558 - accuracy: 0.6376 - val_loss: 3.1812 - val_accuracy: 0.7613\n",
      "Epoch 249\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 3.8136 - accuracy: 0.6430 - val_loss: 3.1742 - val_accuracy: 0.7677\n",
      "Epoch 250\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.7806 - accuracy: 0.6581 - val_loss: 3.1666 - val_accuracy: 0.7720\n",
      "Epoch 251\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 3.7321 - accuracy: 0.6441 - val_loss: 3.1550 - val_accuracy: 0.7785\n",
      "Epoch 252\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 3.7428 - accuracy: 0.6430 - val_loss: 3.1422 - val_accuracy: 0.7742\n",
      "Epoch 253\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 3.8173 - accuracy: 0.6333 - val_loss: 3.1357 - val_accuracy: 0.7720\n",
      "Epoch 254\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 3.6570 - accuracy: 0.6742 - val_loss: 3.1305 - val_accuracy: 0.7742\n",
      "Epoch 255\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 3.6458 - accuracy: 0.6355 - val_loss: 3.1228 - val_accuracy: 0.7763\n",
      "Epoch 256\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 3.7012 - accuracy: 0.6581 - val_loss: 3.1255 - val_accuracy: 0.7785\n",
      "Epoch 257\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 3.7135 - accuracy: 0.6473 - val_loss: 3.1405 - val_accuracy: 0.7742\n",
      "Epoch 258\n",
      "3/3 [==============================] - 3s 642ms/step - loss: 3.6973 - accuracy: 0.6538 - val_loss: 3.1513 - val_accuracy: 0.7634\n",
      "Epoch 259\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.5282 - accuracy: 0.6806 - val_loss: 3.1586 - val_accuracy: 0.7613\n",
      "Epoch 260\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.6041 - accuracy: 0.6753 - val_loss: 3.1521 - val_accuracy: 0.7613\n",
      "Epoch 261\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.6235 - accuracy: 0.6613 - val_loss: 3.1513 - val_accuracy: 0.7570\n",
      "Epoch 262\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 3.5974 - accuracy: 0.6774 - val_loss: 3.1500 - val_accuracy: 0.7570\n",
      "Epoch 263\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 3.8168 - accuracy: 0.6215 - val_loss: 3.1510 - val_accuracy: 0.7591\n",
      "Epoch 264\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.5522 - accuracy: 0.6688 - val_loss: 3.1494 - val_accuracy: 0.7591\n",
      "Epoch 265\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 3.7019 - accuracy: 0.6473 - val_loss: 3.1433 - val_accuracy: 0.7570\n",
      "Epoch 266\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 3.6712 - accuracy: 0.6452 - val_loss: 3.1380 - val_accuracy: 0.7548\n",
      "Epoch 267\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.6589 - accuracy: 0.6538 - val_loss: 3.1280 - val_accuracy: 0.7634\n",
      "Epoch 268\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.5621 - accuracy: 0.6656 - val_loss: 3.1198 - val_accuracy: 0.7634\n",
      "Epoch 269\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.5999 - accuracy: 0.6817 - val_loss: 3.1218 - val_accuracy: 0.7634\n",
      "Epoch 270\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.6479 - accuracy: 0.6699 - val_loss: 3.1202 - val_accuracy: 0.7699\n",
      "Epoch 271\n",
      "3/3 [==============================] - 3s 784ms/step - loss: 3.5844 - accuracy: 0.6720 - val_loss: 3.1226 - val_accuracy: 0.7742\n",
      "Epoch 272\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.7791 - accuracy: 0.6032 - val_loss: 3.1146 - val_accuracy: 0.7699\n",
      "Epoch 273\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 3.5762 - accuracy: 0.6720 - val_loss: 3.0980 - val_accuracy: 0.7634\n",
      "Epoch 274\n",
      "3/3 [==============================] - 3s 637ms/step - loss: 3.5128 - accuracy: 0.6613 - val_loss: 3.0858 - val_accuracy: 0.7677\n",
      "Epoch 275\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 3.5456 - accuracy: 0.6581 - val_loss: 3.0795 - val_accuracy: 0.7720\n",
      "Epoch 276\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.6825 - accuracy: 0.6677 - val_loss: 3.0713 - val_accuracy: 0.7677\n",
      "Epoch 277\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 3.5099 - accuracy: 0.6925 - val_loss: 3.0710 - val_accuracy: 0.7699\n",
      "Epoch 278\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 3.6415 - accuracy: 0.6645 - val_loss: 3.0647 - val_accuracy: 0.7720\n",
      "Epoch 279\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 3.5521 - accuracy: 0.6688 - val_loss: 3.0508 - val_accuracy: 0.7806\n",
      "Epoch 280\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.3909 - accuracy: 0.7054 - val_loss: 3.0461 - val_accuracy: 0.7871\n",
      "Epoch 281\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.5553 - accuracy: 0.6796 - val_loss: 3.0484 - val_accuracy: 0.7806\n",
      "Epoch 282\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 3.5997 - accuracy: 0.6677 - val_loss: 3.0538 - val_accuracy: 0.7785\n",
      "Epoch 283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 587ms/step - loss: 3.4597 - accuracy: 0.7022 - val_loss: 3.0525 - val_accuracy: 0.7871\n",
      "Epoch 284\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 3.5535 - accuracy: 0.6677 - val_loss: 3.0455 - val_accuracy: 0.7935\n",
      "Epoch 285\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 3.4233 - accuracy: 0.6903 - val_loss: 3.0346 - val_accuracy: 0.7914\n",
      "Epoch 286\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 3.6015 - accuracy: 0.6548 - val_loss: 3.0304 - val_accuracy: 0.7763\n",
      "Epoch 287\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 3.5657 - accuracy: 0.6656 - val_loss: 3.0243 - val_accuracy: 0.7699\n",
      "Epoch 288\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 3.5547 - accuracy: 0.6581 - val_loss: 3.0187 - val_accuracy: 0.7785\n",
      "Epoch 289\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.5609 - accuracy: 0.6527 - val_loss: 3.0212 - val_accuracy: 0.7720\n",
      "Epoch 290\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 3.5630 - accuracy: 0.6710 - val_loss: 3.0292 - val_accuracy: 0.7634\n",
      "Epoch 291\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.5353 - accuracy: 0.6699 - val_loss: 3.0362 - val_accuracy: 0.7656\n",
      "Epoch 292\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 3.5463 - accuracy: 0.6634 - val_loss: 3.0469 - val_accuracy: 0.7699\n",
      "Epoch 293\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 3.4717 - accuracy: 0.6774 - val_loss: 3.0504 - val_accuracy: 0.7634\n",
      "Epoch 294\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.4089 - accuracy: 0.6796 - val_loss: 3.0513 - val_accuracy: 0.7742\n",
      "Epoch 295\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.4380 - accuracy: 0.6957 - val_loss: 3.0462 - val_accuracy: 0.7720\n",
      "Epoch 296\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.3916 - accuracy: 0.6796 - val_loss: 3.0525 - val_accuracy: 0.7763\n",
      "Epoch 297\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 3.5225 - accuracy: 0.6613 - val_loss: 3.0581 - val_accuracy: 0.7742\n",
      "Epoch 298\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 3.3791 - accuracy: 0.6946 - val_loss: 3.0527 - val_accuracy: 0.7828\n",
      "Epoch 299\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 3.4348 - accuracy: 0.6925 - val_loss: 3.0394 - val_accuracy: 0.7828\n",
      "Epoch 300\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 3.4663 - accuracy: 0.6828 - val_loss: 3.0326 - val_accuracy: 0.7871\n",
      "Epoch 301\n",
      "3/3 [==============================] - 3s 657ms/step - loss: 3.2885 - accuracy: 0.6935 - val_loss: 3.0315 - val_accuracy: 0.7871\n",
      "Epoch 302\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 3.5343 - accuracy: 0.6742 - val_loss: 3.0381 - val_accuracy: 0.7742\n",
      "Epoch 303\n",
      "3/3 [==============================] - 3s 761ms/step - loss: 3.4704 - accuracy: 0.6677 - val_loss: 3.0361 - val_accuracy: 0.7742\n",
      "Epoch 304\n",
      "3/3 [==============================] - 3s 759ms/step - loss: 3.4585 - accuracy: 0.6656 - val_loss: 3.0349 - val_accuracy: 0.7828\n",
      "Epoch 305\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.3631 - accuracy: 0.7108 - val_loss: 3.0306 - val_accuracy: 0.7849\n",
      "Epoch 306\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.3880 - accuracy: 0.6957 - val_loss: 3.0248 - val_accuracy: 0.7806\n",
      "Epoch 307\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 3.4746 - accuracy: 0.6699 - val_loss: 3.0242 - val_accuracy: 0.7785\n",
      "Epoch 308\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.4594 - accuracy: 0.6860 - val_loss: 3.0168 - val_accuracy: 0.7742\n",
      "Epoch 309\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 3.3910 - accuracy: 0.6656 - val_loss: 3.0229 - val_accuracy: 0.7763\n",
      "Epoch 310\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.5179 - accuracy: 0.6624 - val_loss: 3.0334 - val_accuracy: 0.7763\n",
      "Epoch 311\n",
      "3/3 [==============================] - 3s 747ms/step - loss: 3.3461 - accuracy: 0.6871 - val_loss: 3.0466 - val_accuracy: 0.7677\n",
      "Epoch 312\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.3829 - accuracy: 0.6914 - val_loss: 3.0479 - val_accuracy: 0.7677\n",
      "Epoch 313\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 3.5376 - accuracy: 0.6484 - val_loss: 3.0418 - val_accuracy: 0.7699\n",
      "Epoch 314\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 3.3810 - accuracy: 0.7000 - val_loss: 3.0319 - val_accuracy: 0.7677\n",
      "Epoch 315\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 3.4686 - accuracy: 0.6828 - val_loss: 3.0143 - val_accuracy: 0.7656\n",
      "Epoch 316\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 3.3265 - accuracy: 0.7054 - val_loss: 3.0050 - val_accuracy: 0.7742\n",
      "Epoch 317\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 3.4229 - accuracy: 0.6720 - val_loss: 3.0075 - val_accuracy: 0.7699\n",
      "Epoch 318\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 3.3725 - accuracy: 0.6957 - val_loss: 2.9968 - val_accuracy: 0.7677\n",
      "Epoch 319\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 3.1723 - accuracy: 0.7333 - val_loss: 2.9780 - val_accuracy: 0.7634\n",
      "Epoch 320\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.1960 - accuracy: 0.7301 - val_loss: 2.9679 - val_accuracy: 0.7742\n",
      "Epoch 321\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 3.3816 - accuracy: 0.6806 - val_loss: 2.9696 - val_accuracy: 0.7763\n",
      "Epoch 322\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 3.3956 - accuracy: 0.6720 - val_loss: 2.9727 - val_accuracy: 0.7785\n",
      "Epoch 323\n",
      "3/3 [==============================] - 3s 726ms/step - loss: 3.2698 - accuracy: 0.7129 - val_loss: 2.9763 - val_accuracy: 0.7785\n",
      "Epoch 324\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.4016 - accuracy: 0.6892 - val_loss: 2.9779 - val_accuracy: 0.7720\n",
      "Epoch 325\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 3.3513 - accuracy: 0.6978 - val_loss: 2.9814 - val_accuracy: 0.7634\n",
      "Epoch 326\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 3.3491 - accuracy: 0.6882 - val_loss: 2.9771 - val_accuracy: 0.7677\n",
      "Epoch 327\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 3.2719 - accuracy: 0.6935 - val_loss: 2.9783 - val_accuracy: 0.7720\n",
      "Epoch 328\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 3.2204 - accuracy: 0.7043 - val_loss: 2.9841 - val_accuracy: 0.7720\n",
      "Epoch 329\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 3.3147 - accuracy: 0.6914 - val_loss: 2.9798 - val_accuracy: 0.7677\n",
      "Epoch 330\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 3.3716 - accuracy: 0.6882 - val_loss: 2.9711 - val_accuracy: 0.7699\n",
      "Epoch 331\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.3843 - accuracy: 0.6817 - val_loss: 2.9644 - val_accuracy: 0.7785\n",
      "Epoch 332\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 3.2790 - accuracy: 0.7032 - val_loss: 2.9589 - val_accuracy: 0.7785\n",
      "Epoch 333\n",
      "3/3 [==============================] - 3s 715ms/step - loss: 3.4237 - accuracy: 0.6731 - val_loss: 2.9521 - val_accuracy: 0.7742\n",
      "Epoch 334\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 3.3353 - accuracy: 0.6978 - val_loss: 2.9590 - val_accuracy: 0.7656\n",
      "Epoch 335\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 3.2427 - accuracy: 0.7054 - val_loss: 2.9625 - val_accuracy: 0.7634\n",
      "Epoch 336\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 3.3464 - accuracy: 0.7032 - val_loss: 2.9610 - val_accuracy: 0.7634\n",
      "Epoch 337\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 3.2498 - accuracy: 0.7269 - val_loss: 2.9531 - val_accuracy: 0.7613\n",
      "Epoch 338\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.2619 - accuracy: 0.7118 - val_loss: 2.9551 - val_accuracy: 0.7699\n",
      "Epoch 339\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 3.3566 - accuracy: 0.6989 - val_loss: 2.9601 - val_accuracy: 0.7720\n",
      "Epoch 340\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 3.2675 - accuracy: 0.6925 - val_loss: 2.9675 - val_accuracy: 0.7742\n",
      "Epoch 341\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 3.2990 - accuracy: 0.7011 - val_loss: 2.9700 - val_accuracy: 0.7548\n",
      "Epoch 342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 618ms/step - loss: 3.3109 - accuracy: 0.6935 - val_loss: 2.9659 - val_accuracy: 0.7591\n",
      "Epoch 343\n",
      "3/3 [==============================] - 3s 715ms/step - loss: 3.2402 - accuracy: 0.7022 - val_loss: 2.9523 - val_accuracy: 0.7570\n",
      "Epoch 344\n",
      "3/3 [==============================] - 3s 795ms/step - loss: 3.2499 - accuracy: 0.7075 - val_loss: 2.9378 - val_accuracy: 0.7613\n",
      "Epoch 345\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.2028 - accuracy: 0.7022 - val_loss: 2.9331 - val_accuracy: 0.7591\n",
      "Epoch 346\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 3.1753 - accuracy: 0.7032 - val_loss: 2.9333 - val_accuracy: 0.7699\n",
      "Epoch 347\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 3.1321 - accuracy: 0.7215 - val_loss: 2.9358 - val_accuracy: 0.7742\n",
      "Epoch 348\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 3.1328 - accuracy: 0.7269 - val_loss: 2.9409 - val_accuracy: 0.7806\n",
      "Epoch 349\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.2090 - accuracy: 0.7172 - val_loss: 2.9374 - val_accuracy: 0.7720\n",
      "Epoch 350\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.1670 - accuracy: 0.7344 - val_loss: 2.9317 - val_accuracy: 0.7763\n",
      "Epoch 351\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 3.1964 - accuracy: 0.7032 - val_loss: 2.9178 - val_accuracy: 0.7763\n",
      "Epoch 352\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 3.1778 - accuracy: 0.7151 - val_loss: 2.9050 - val_accuracy: 0.7785\n",
      "Epoch 353\n",
      "3/3 [==============================] - 3s 723ms/step - loss: 3.2614 - accuracy: 0.7000 - val_loss: 2.8994 - val_accuracy: 0.7806\n",
      "Epoch 354\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 3.1394 - accuracy: 0.7258 - val_loss: 2.8983 - val_accuracy: 0.7699\n",
      "Epoch 355\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 3.1679 - accuracy: 0.7108 - val_loss: 2.9050 - val_accuracy: 0.7634\n",
      "Epoch 356\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 3.1738 - accuracy: 0.7086 - val_loss: 2.9105 - val_accuracy: 0.7591\n",
      "Epoch 357\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.1231 - accuracy: 0.7301 - val_loss: 2.9178 - val_accuracy: 0.7484\n",
      "Epoch 358\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.1461 - accuracy: 0.7323 - val_loss: 2.9185 - val_accuracy: 0.7570\n",
      "Epoch 359\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 3.1712 - accuracy: 0.7258 - val_loss: 2.9198 - val_accuracy: 0.7591\n",
      "Epoch 360\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.0991 - accuracy: 0.7290 - val_loss: 2.9178 - val_accuracy: 0.7742\n",
      "Epoch 361\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 3.0905 - accuracy: 0.7312 - val_loss: 2.9136 - val_accuracy: 0.7763\n",
      "Epoch 362\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 3.1392 - accuracy: 0.7323 - val_loss: 2.9169 - val_accuracy: 0.7763\n",
      "Epoch 363\n",
      "3/3 [==============================] - 3s 790ms/step - loss: 3.1756 - accuracy: 0.7118 - val_loss: 2.9223 - val_accuracy: 0.7742\n",
      "Epoch 364\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 3.0179 - accuracy: 0.7484 - val_loss: 2.9243 - val_accuracy: 0.7742\n",
      "Epoch 365\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 3.0637 - accuracy: 0.7290 - val_loss: 2.9122 - val_accuracy: 0.7720\n",
      "Epoch 366\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.0151 - accuracy: 0.7258 - val_loss: 2.8937 - val_accuracy: 0.7742\n",
      "Epoch 367\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 3.1343 - accuracy: 0.7129 - val_loss: 2.8954 - val_accuracy: 0.7828\n",
      "Epoch 368\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.1923 - accuracy: 0.7065 - val_loss: 2.8931 - val_accuracy: 0.7720\n",
      "Epoch 369\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.1092 - accuracy: 0.7204 - val_loss: 2.8871 - val_accuracy: 0.7699\n",
      "Epoch 370\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 3.1891 - accuracy: 0.6892 - val_loss: 2.8906 - val_accuracy: 0.7785\n",
      "Epoch 371\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 3.1436 - accuracy: 0.7129 - val_loss: 2.8870 - val_accuracy: 0.7806\n",
      "Epoch 372\n",
      "3/3 [==============================] - 3s 781ms/step - loss: 3.1198 - accuracy: 0.7108 - val_loss: 2.8829 - val_accuracy: 0.7785\n",
      "Epoch 373\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 3.1173 - accuracy: 0.7000 - val_loss: 2.8706 - val_accuracy: 0.7763\n",
      "Epoch 374\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 3.1551 - accuracy: 0.7183 - val_loss: 2.8505 - val_accuracy: 0.7806\n",
      "Epoch 375\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 3.1345 - accuracy: 0.7097 - val_loss: 2.8394 - val_accuracy: 0.7849\n",
      "Epoch 376\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.0485 - accuracy: 0.7344 - val_loss: 2.8271 - val_accuracy: 0.7871\n",
      "Epoch 377\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 3.0005 - accuracy: 0.7280 - val_loss: 2.8142 - val_accuracy: 0.7914\n",
      "Epoch 378\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 3.0293 - accuracy: 0.7323 - val_loss: 2.8080 - val_accuracy: 0.8000\n",
      "Epoch 379\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 3.1545 - accuracy: 0.7269 - val_loss: 2.8086 - val_accuracy: 0.7978\n",
      "Epoch 380\n",
      "3/3 [==============================] - 3s 733ms/step - loss: 3.1309 - accuracy: 0.7129 - val_loss: 2.8193 - val_accuracy: 0.8000\n",
      "Epoch 381\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 3.0817 - accuracy: 0.7129 - val_loss: 2.8211 - val_accuracy: 0.7914\n",
      "Epoch 382\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 3.0008 - accuracy: 0.7376 - val_loss: 2.8311 - val_accuracy: 0.7849\n",
      "Epoch 383\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 3.1957 - accuracy: 0.7000 - val_loss: 2.8429 - val_accuracy: 0.7785\n",
      "Epoch 384\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 3.1782 - accuracy: 0.7054 - val_loss: 2.8455 - val_accuracy: 0.7720\n",
      "Epoch 385\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 3.0711 - accuracy: 0.7269 - val_loss: 2.8484 - val_accuracy: 0.7828\n",
      "Epoch 386\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 3.0643 - accuracy: 0.7215 - val_loss: 2.8579 - val_accuracy: 0.7742\n",
      "Epoch 387\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.9731 - accuracy: 0.7720 - val_loss: 2.8634 - val_accuracy: 0.7806\n",
      "Epoch 388\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 3.0669 - accuracy: 0.7355 - val_loss: 2.8576 - val_accuracy: 0.7914\n",
      "Epoch 389\n",
      "3/3 [==============================] - 3s 813ms/step - loss: 3.1062 - accuracy: 0.7054 - val_loss: 2.8542 - val_accuracy: 0.7914\n",
      "Epoch 390\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 3.0382 - accuracy: 0.7290 - val_loss: 2.8481 - val_accuracy: 0.7978\n",
      "Epoch 391\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 3.0360 - accuracy: 0.7108 - val_loss: 2.8465 - val_accuracy: 0.8000\n",
      "Epoch 392\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.9493 - accuracy: 0.7462 - val_loss: 2.8420 - val_accuracy: 0.7978\n",
      "Epoch 393\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.9560 - accuracy: 0.7355 - val_loss: 2.8381 - val_accuracy: 0.7978\n",
      "Epoch 394\n",
      "3/3 [==============================] - 3s 784ms/step - loss: 2.9889 - accuracy: 0.7355 - val_loss: 2.8294 - val_accuracy: 0.7978\n",
      "Epoch 395\n",
      "3/3 [==============================] - 3s 798ms/step - loss: 3.0154 - accuracy: 0.7419 - val_loss: 2.8211 - val_accuracy: 0.7892\n",
      "Epoch 396\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 3.0065 - accuracy: 0.7043 - val_loss: 2.8229 - val_accuracy: 0.7828\n",
      "Epoch 397\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 3.1490 - accuracy: 0.7140 - val_loss: 2.8343 - val_accuracy: 0.7871\n",
      "Epoch 398\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.9871 - accuracy: 0.7355 - val_loss: 2.8392 - val_accuracy: 0.7871\n",
      "Epoch 399\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.9651 - accuracy: 0.7473 - val_loss: 2.8398 - val_accuracy: 0.7871\n",
      "Epoch 400\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 3.0313 - accuracy: 0.7118 - val_loss: 2.8327 - val_accuracy: 0.7828\n",
      "Epoch 401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 606ms/step - loss: 2.9865 - accuracy: 0.7366 - val_loss: 2.8228 - val_accuracy: 0.7828\n",
      "Epoch 402\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.9040 - accuracy: 0.7323 - val_loss: 2.8127 - val_accuracy: 0.7914\n",
      "Epoch 403\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.9731 - accuracy: 0.7290 - val_loss: 2.8034 - val_accuracy: 0.8022\n",
      "Epoch 404\n",
      "3/3 [==============================] - 3s 575ms/step - loss: 2.9833 - accuracy: 0.7344 - val_loss: 2.8058 - val_accuracy: 0.8065\n",
      "Epoch 405\n",
      "3/3 [==============================] - 3s 797ms/step - loss: 2.9443 - accuracy: 0.7269 - val_loss: 2.7998 - val_accuracy: 0.8086\n",
      "Epoch 406\n",
      "3/3 [==============================] - 3s 740ms/step - loss: 2.9610 - accuracy: 0.7559 - val_loss: 2.7976 - val_accuracy: 0.8022\n",
      "Epoch 407\n",
      "3/3 [==============================] - 3s 797ms/step - loss: 3.1566 - accuracy: 0.6946 - val_loss: 2.7985 - val_accuracy: 0.7978\n",
      "Epoch 408\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 2.9657 - accuracy: 0.7462 - val_loss: 2.7942 - val_accuracy: 0.8043\n",
      "Epoch 409\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.8981 - accuracy: 0.7602 - val_loss: 2.7773 - val_accuracy: 0.8065\n",
      "Epoch 410\n",
      "3/3 [==============================] - 3s 594ms/step - loss: 2.9245 - accuracy: 0.7548 - val_loss: 2.7547 - val_accuracy: 0.8022\n",
      "Epoch 411\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 2.9297 - accuracy: 0.7194 - val_loss: 2.7433 - val_accuracy: 0.8022\n",
      "Epoch 412\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 3.0488 - accuracy: 0.7140 - val_loss: 2.7477 - val_accuracy: 0.7957\n",
      "Epoch 413\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.9537 - accuracy: 0.7366 - val_loss: 2.7690 - val_accuracy: 0.7957\n",
      "Epoch 414\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.9720 - accuracy: 0.7301 - val_loss: 2.7849 - val_accuracy: 0.7828\n",
      "Epoch 415\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.9799 - accuracy: 0.7290 - val_loss: 2.7806 - val_accuracy: 0.7742\n",
      "Epoch 416\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.8911 - accuracy: 0.7548 - val_loss: 2.7637 - val_accuracy: 0.7806\n",
      "Epoch 417\n",
      "3/3 [==============================] - 3s 727ms/step - loss: 2.8866 - accuracy: 0.7441 - val_loss: 2.7489 - val_accuracy: 0.7828\n",
      "Epoch 418\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.8828 - accuracy: 0.7634 - val_loss: 2.7386 - val_accuracy: 0.7892\n",
      "Epoch 419\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 2.9277 - accuracy: 0.7204 - val_loss: 2.7328 - val_accuracy: 0.7914\n",
      "Epoch 420\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.9557 - accuracy: 0.7344 - val_loss: 2.7296 - val_accuracy: 0.7914\n",
      "Epoch 421\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.9670 - accuracy: 0.7280 - val_loss: 2.7274 - val_accuracy: 0.7914\n",
      "Epoch 422\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.8924 - accuracy: 0.7441 - val_loss: 2.7249 - val_accuracy: 0.7978\n",
      "Epoch 423\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.9083 - accuracy: 0.7355 - val_loss: 2.7271 - val_accuracy: 0.7935\n",
      "Epoch 424\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.9402 - accuracy: 0.7355 - val_loss: 2.7291 - val_accuracy: 0.7828\n",
      "Epoch 425\n",
      "3/3 [==============================] - 3s 583ms/step - loss: 2.9791 - accuracy: 0.7129 - val_loss: 2.7280 - val_accuracy: 0.7849\n",
      "Epoch 426\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.9035 - accuracy: 0.7237 - val_loss: 2.7265 - val_accuracy: 0.7785\n",
      "Epoch 427\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.9445 - accuracy: 0.7452 - val_loss: 2.7238 - val_accuracy: 0.7849\n",
      "Epoch 428\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.8846 - accuracy: 0.7355 - val_loss: 2.7210 - val_accuracy: 0.7914\n",
      "Epoch 429\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.8878 - accuracy: 0.7473 - val_loss: 2.7207 - val_accuracy: 0.7935\n",
      "Epoch 430\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 3.0019 - accuracy: 0.7194 - val_loss: 2.7295 - val_accuracy: 0.7871\n",
      "Epoch 431\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.9575 - accuracy: 0.7333 - val_loss: 2.7486 - val_accuracy: 0.7828\n",
      "Epoch 432\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.9133 - accuracy: 0.7183 - val_loss: 2.7724 - val_accuracy: 0.7699\n",
      "Epoch 433\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.9297 - accuracy: 0.7280 - val_loss: 2.7906 - val_accuracy: 0.7720\n",
      "Epoch 434\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.8289 - accuracy: 0.7624 - val_loss: 2.7947 - val_accuracy: 0.7742\n",
      "Epoch 435\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.9366 - accuracy: 0.7441 - val_loss: 2.7876 - val_accuracy: 0.7806\n",
      "Epoch 436\n",
      "3/3 [==============================] - 3s 764ms/step - loss: 2.8797 - accuracy: 0.7237 - val_loss: 2.7835 - val_accuracy: 0.7742\n",
      "Epoch 437\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 2.8458 - accuracy: 0.7355 - val_loss: 2.7822 - val_accuracy: 0.7699\n",
      "Epoch 438\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.8459 - accuracy: 0.7613 - val_loss: 2.7809 - val_accuracy: 0.7699\n",
      "Epoch 439\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.8523 - accuracy: 0.7538 - val_loss: 2.7768 - val_accuracy: 0.7720\n",
      "Epoch 440\n",
      "3/3 [==============================] - 3s 628ms/step - loss: 2.9321 - accuracy: 0.7387 - val_loss: 2.7792 - val_accuracy: 0.7742\n",
      "Epoch 441\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.8249 - accuracy: 0.7538 - val_loss: 2.7765 - val_accuracy: 0.7763\n",
      "Epoch 442\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.8840 - accuracy: 0.7247 - val_loss: 2.7797 - val_accuracy: 0.7806\n",
      "Epoch 443\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.9011 - accuracy: 0.7387 - val_loss: 2.7800 - val_accuracy: 0.7806\n",
      "Epoch 444\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.9300 - accuracy: 0.7280 - val_loss: 2.7864 - val_accuracy: 0.7828\n",
      "Epoch 445\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 3.0187 - accuracy: 0.7108 - val_loss: 2.7910 - val_accuracy: 0.7785\n",
      "Epoch 446\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.8467 - accuracy: 0.7387 - val_loss: 2.8110 - val_accuracy: 0.7699\n",
      "Epoch 447\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.9092 - accuracy: 0.7376 - val_loss: 2.8223 - val_accuracy: 0.7634\n",
      "Epoch 448\n",
      "3/3 [==============================] - 3s 782ms/step - loss: 2.8667 - accuracy: 0.7333 - val_loss: 2.8242 - val_accuracy: 0.7634\n",
      "Epoch 449\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.8168 - accuracy: 0.7441 - val_loss: 2.8274 - val_accuracy: 0.7634\n",
      "Epoch 450\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.7996 - accuracy: 0.7527 - val_loss: 2.8248 - val_accuracy: 0.7613\n",
      "Epoch 451\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.8487 - accuracy: 0.7441 - val_loss: 2.8199 - val_accuracy: 0.7570\n",
      "Epoch 452\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.8587 - accuracy: 0.7419 - val_loss: 2.8220 - val_accuracy: 0.7634\n",
      "Epoch 453\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.9252 - accuracy: 0.7172 - val_loss: 2.8238 - val_accuracy: 0.7634\n",
      "Epoch 454\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.8481 - accuracy: 0.7462 - val_loss: 2.8205 - val_accuracy: 0.7656\n",
      "Epoch 455\n",
      "3/3 [==============================] - 3s 797ms/step - loss: 2.7704 - accuracy: 0.7602 - val_loss: 2.8258 - val_accuracy: 0.7656\n",
      "Epoch 456\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.8186 - accuracy: 0.7634 - val_loss: 2.8278 - val_accuracy: 0.7613\n",
      "Epoch 457\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.7717 - accuracy: 0.7624 - val_loss: 2.8331 - val_accuracy: 0.7527\n",
      "Epoch 458\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.8503 - accuracy: 0.7409 - val_loss: 2.8388 - val_accuracy: 0.7613\n",
      "Epoch 459\n",
      "3/3 [==============================] - 3s 720ms/step - loss: 2.8086 - accuracy: 0.7688 - val_loss: 2.8459 - val_accuracy: 0.7634\n",
      "Epoch 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 591ms/step - loss: 2.7449 - accuracy: 0.7441 - val_loss: 2.8416 - val_accuracy: 0.7699\n",
      "Epoch 461\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 2.8599 - accuracy: 0.7366 - val_loss: 2.8255 - val_accuracy: 0.7785\n",
      "Epoch 462\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.8231 - accuracy: 0.7376 - val_loss: 2.8079 - val_accuracy: 0.7742\n",
      "Epoch 463\n",
      "3/3 [==============================] - 3s 749ms/step - loss: 2.8405 - accuracy: 0.7409 - val_loss: 2.7958 - val_accuracy: 0.7656\n",
      "Epoch 464\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.8337 - accuracy: 0.7602 - val_loss: 2.7902 - val_accuracy: 0.7699\n",
      "Epoch 465\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.8061 - accuracy: 0.7441 - val_loss: 2.7864 - val_accuracy: 0.7656\n",
      "Epoch 466\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.8326 - accuracy: 0.7387 - val_loss: 2.7918 - val_accuracy: 0.7570\n",
      "Epoch 467\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.7983 - accuracy: 0.7366 - val_loss: 2.7906 - val_accuracy: 0.7591\n",
      "Epoch 468\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.8170 - accuracy: 0.7430 - val_loss: 2.7829 - val_accuracy: 0.7634\n",
      "Epoch 469\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.8324 - accuracy: 0.7258 - val_loss: 2.7674 - val_accuracy: 0.7699\n",
      "Epoch 470\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.7348 - accuracy: 0.7699 - val_loss: 2.7573 - val_accuracy: 0.7677\n",
      "Epoch 471\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.8457 - accuracy: 0.7312 - val_loss: 2.7488 - val_accuracy: 0.7763\n",
      "Epoch 472\n",
      "3/3 [==============================] - 3s 714ms/step - loss: 2.8131 - accuracy: 0.7505 - val_loss: 2.7456 - val_accuracy: 0.7742\n",
      "Epoch 473\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 2.8659 - accuracy: 0.7280 - val_loss: 2.7357 - val_accuracy: 0.7785\n",
      "Epoch 474\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.8185 - accuracy: 0.7430 - val_loss: 2.7349 - val_accuracy: 0.7806\n",
      "Epoch 475\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 2.7113 - accuracy: 0.7570 - val_loss: 2.7386 - val_accuracy: 0.7763\n",
      "Epoch 476\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.7694 - accuracy: 0.7505 - val_loss: 2.7283 - val_accuracy: 0.7763\n",
      "Epoch 477\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.8844 - accuracy: 0.7290 - val_loss: 2.7193 - val_accuracy: 0.7742\n",
      "Epoch 478\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.8438 - accuracy: 0.7355 - val_loss: 2.7078 - val_accuracy: 0.7742\n",
      "Epoch 479\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.8214 - accuracy: 0.7419 - val_loss: 2.7029 - val_accuracy: 0.7742\n",
      "Epoch 480\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.8393 - accuracy: 0.7312 - val_loss: 2.7050 - val_accuracy: 0.7720\n",
      "Epoch 481\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.8370 - accuracy: 0.7226 - val_loss: 2.6998 - val_accuracy: 0.7677\n",
      "Epoch 482\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.7479 - accuracy: 0.7548 - val_loss: 2.7048 - val_accuracy: 0.7613\n",
      "Epoch 483\n",
      "3/3 [==============================] - 3s 731ms/step - loss: 2.7457 - accuracy: 0.7484 - val_loss: 2.7199 - val_accuracy: 0.7548\n",
      "Epoch 484\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 2.6985 - accuracy: 0.7774 - val_loss: 2.7090 - val_accuracy: 0.7613\n",
      "Epoch 485\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.8659 - accuracy: 0.7280 - val_loss: 2.6891 - val_accuracy: 0.7591\n",
      "Epoch 486\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.7224 - accuracy: 0.7602 - val_loss: 2.6764 - val_accuracy: 0.7548\n",
      "Epoch 487\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.8245 - accuracy: 0.7280 - val_loss: 2.6700 - val_accuracy: 0.7656\n",
      "Epoch 488\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 2.8173 - accuracy: 0.7398 - val_loss: 2.6618 - val_accuracy: 0.7763\n",
      "Epoch 489\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.7702 - accuracy: 0.7667 - val_loss: 2.6640 - val_accuracy: 0.7763\n",
      "Epoch 490\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.7836 - accuracy: 0.7409 - val_loss: 2.6731 - val_accuracy: 0.7742\n",
      "Epoch 491\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.8779 - accuracy: 0.7301 - val_loss: 2.6765 - val_accuracy: 0.7742\n",
      "Epoch 492\n",
      "3/3 [==============================] - 3s 763ms/step - loss: 2.7364 - accuracy: 0.7398 - val_loss: 2.6837 - val_accuracy: 0.7720\n",
      "Epoch 493\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.7938 - accuracy: 0.7376 - val_loss: 2.6892 - val_accuracy: 0.7634\n",
      "Epoch 494\n",
      "3/3 [==============================] - 3s 780ms/step - loss: 2.8292 - accuracy: 0.7376 - val_loss: 2.6850 - val_accuracy: 0.7656\n",
      "Epoch 495\n",
      "3/3 [==============================] - 3s 783ms/step - loss: 2.8056 - accuracy: 0.7591 - val_loss: 2.6888 - val_accuracy: 0.7720\n",
      "Epoch 496\n",
      "3/3 [==============================] - 3s 781ms/step - loss: 2.7847 - accuracy: 0.7505 - val_loss: 2.6832 - val_accuracy: 0.7763\n",
      "Epoch 497\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 2.7248 - accuracy: 0.7559 - val_loss: 2.6869 - val_accuracy: 0.7806\n",
      "Epoch 498\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.7697 - accuracy: 0.7473 - val_loss: 2.6972 - val_accuracy: 0.7720\n",
      "Epoch 499\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.8046 - accuracy: 0.7527 - val_loss: 2.7050 - val_accuracy: 0.7656\n",
      "Epoch 500\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 2.7866 - accuracy: 0.7505 - val_loss: 2.7097 - val_accuracy: 0.7699\n",
      "Epoch 501\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.7866 - accuracy: 0.7462 - val_loss: 2.6998 - val_accuracy: 0.7613\n",
      "Epoch 502\n",
      "3/3 [==============================] - 3s 746ms/step - loss: 2.6691 - accuracy: 0.7559 - val_loss: 2.6875 - val_accuracy: 0.7720\n",
      "Epoch 503\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.8486 - accuracy: 0.7323 - val_loss: 2.6795 - val_accuracy: 0.7785\n",
      "Epoch 504\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.7038 - accuracy: 0.7581 - val_loss: 2.6735 - val_accuracy: 0.7763\n",
      "Epoch 505\n",
      "3/3 [==============================] - 3s 736ms/step - loss: 2.7571 - accuracy: 0.7430 - val_loss: 2.6709 - val_accuracy: 0.7677\n",
      "Epoch 506\n",
      "3/3 [==============================] - 3s 809ms/step - loss: 2.7307 - accuracy: 0.7570 - val_loss: 2.6802 - val_accuracy: 0.7656\n",
      "Epoch 507\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.6638 - accuracy: 0.7624 - val_loss: 2.6935 - val_accuracy: 0.7570\n",
      "Epoch 508\n",
      "3/3 [==============================] - 3s 752ms/step - loss: 2.7366 - accuracy: 0.7634 - val_loss: 2.6959 - val_accuracy: 0.7613\n",
      "Epoch 509\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.6843 - accuracy: 0.7645 - val_loss: 2.7008 - val_accuracy: 0.7656\n",
      "Epoch 510\n",
      "3/3 [==============================] - 3s 593ms/step - loss: 2.6795 - accuracy: 0.7581 - val_loss: 2.6942 - val_accuracy: 0.7720\n",
      "Epoch 511\n",
      "3/3 [==============================] - 3s 578ms/step - loss: 2.7061 - accuracy: 0.7548 - val_loss: 2.6916 - val_accuracy: 0.7806\n",
      "Epoch 512\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.6767 - accuracy: 0.7720 - val_loss: 2.6965 - val_accuracy: 0.7806\n",
      "Epoch 513\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.7810 - accuracy: 0.7419 - val_loss: 2.6907 - val_accuracy: 0.7742\n",
      "Epoch 514\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.6755 - accuracy: 0.7645 - val_loss: 2.6827 - val_accuracy: 0.7634\n",
      "Epoch 515\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.6298 - accuracy: 0.7699 - val_loss: 2.6912 - val_accuracy: 0.7634\n",
      "Epoch 516\n",
      "3/3 [==============================] - 3s 709ms/step - loss: 2.6731 - accuracy: 0.7581 - val_loss: 2.7092 - val_accuracy: 0.7677\n",
      "Epoch 517\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.7195 - accuracy: 0.7591 - val_loss: 2.7205 - val_accuracy: 0.7613\n",
      "Epoch 518\n",
      "3/3 [==============================] - 3s 734ms/step - loss: 2.7120 - accuracy: 0.7559 - val_loss: 2.7115 - val_accuracy: 0.7634\n",
      "Epoch 519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 641ms/step - loss: 2.7220 - accuracy: 0.7570 - val_loss: 2.6864 - val_accuracy: 0.7656\n",
      "Epoch 520\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.6447 - accuracy: 0.7763 - val_loss: 2.6639 - val_accuracy: 0.7720\n",
      "Epoch 521\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.6102 - accuracy: 0.7882 - val_loss: 2.6478 - val_accuracy: 0.7677\n",
      "Epoch 522\n",
      "3/3 [==============================] - 3s 617ms/step - loss: 2.5968 - accuracy: 0.7806 - val_loss: 2.6461 - val_accuracy: 0.7720\n",
      "Epoch 523\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.6949 - accuracy: 0.7720 - val_loss: 2.6487 - val_accuracy: 0.7720\n",
      "Epoch 524\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.6812 - accuracy: 0.7570 - val_loss: 2.6510 - val_accuracy: 0.7656\n",
      "Epoch 525\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.6507 - accuracy: 0.7656 - val_loss: 2.6595 - val_accuracy: 0.7656\n",
      "Epoch 526\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.7681 - accuracy: 0.7591 - val_loss: 2.6595 - val_accuracy: 0.7656\n",
      "Epoch 527\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 2.7480 - accuracy: 0.7419 - val_loss: 2.6636 - val_accuracy: 0.7591\n",
      "Epoch 528\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.6915 - accuracy: 0.7527 - val_loss: 2.6751 - val_accuracy: 0.7591\n",
      "Epoch 529\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.7250 - accuracy: 0.7312 - val_loss: 2.6930 - val_accuracy: 0.7548\n",
      "Epoch 530\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.7252 - accuracy: 0.7538 - val_loss: 2.7000 - val_accuracy: 0.7613\n",
      "Epoch 531\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 2.6561 - accuracy: 0.7656 - val_loss: 2.7072 - val_accuracy: 0.7591\n",
      "Epoch 532\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 2.6621 - accuracy: 0.7763 - val_loss: 2.7148 - val_accuracy: 0.7505\n",
      "Epoch 533\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.7510 - accuracy: 0.7441 - val_loss: 2.7055 - val_accuracy: 0.7527\n",
      "Epoch 534\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.6700 - accuracy: 0.7591 - val_loss: 2.6953 - val_accuracy: 0.7398\n",
      "Epoch 535\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.6238 - accuracy: 0.7796 - val_loss: 2.6885 - val_accuracy: 0.7484\n",
      "Epoch 536\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.6158 - accuracy: 0.7806 - val_loss: 2.6782 - val_accuracy: 0.7505\n",
      "Epoch 537\n",
      "3/3 [==============================] - 3s 737ms/step - loss: 2.7676 - accuracy: 0.7376 - val_loss: 2.6587 - val_accuracy: 0.7570\n",
      "Epoch 538\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5572 - accuracy: 0.7935 - val_loss: 2.6450 - val_accuracy: 0.7677\n",
      "Epoch 539\n",
      "3/3 [==============================] - 3s 757ms/step - loss: 2.6031 - accuracy: 0.7656 - val_loss: 2.6387 - val_accuracy: 0.7634\n",
      "Epoch 540\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 2.6204 - accuracy: 0.7656 - val_loss: 2.6245 - val_accuracy: 0.7634\n",
      "Epoch 541\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.6045 - accuracy: 0.7688 - val_loss: 2.6157 - val_accuracy: 0.7720\n",
      "Epoch 542\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.6844 - accuracy: 0.7419 - val_loss: 2.6082 - val_accuracy: 0.7677\n",
      "Epoch 543\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.6218 - accuracy: 0.7624 - val_loss: 2.6078 - val_accuracy: 0.7677\n",
      "Epoch 544\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.6437 - accuracy: 0.7710 - val_loss: 2.6074 - val_accuracy: 0.7763\n",
      "Epoch 545\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.6256 - accuracy: 0.7624 - val_loss: 2.6210 - val_accuracy: 0.7720\n",
      "Epoch 546\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.6325 - accuracy: 0.7602 - val_loss: 2.6368 - val_accuracy: 0.7763\n",
      "Epoch 547\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.7019 - accuracy: 0.7441 - val_loss: 2.6545 - val_accuracy: 0.7720\n",
      "Epoch 548\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6003 - accuracy: 0.7591 - val_loss: 2.6763 - val_accuracy: 0.7634\n",
      "Epoch 549\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.5697 - accuracy: 0.7624 - val_loss: 2.6897 - val_accuracy: 0.7613\n",
      "Epoch 550\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.5253 - accuracy: 0.7914 - val_loss: 2.6871 - val_accuracy: 0.7419\n",
      "Epoch 551\n",
      "3/3 [==============================] - 3s 642ms/step - loss: 2.5661 - accuracy: 0.7667 - val_loss: 2.6757 - val_accuracy: 0.7484\n",
      "Epoch 552\n",
      "3/3 [==============================] - 3s 638ms/step - loss: 2.7024 - accuracy: 0.7344 - val_loss: 2.6648 - val_accuracy: 0.7548\n",
      "Epoch 553\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6622 - accuracy: 0.7376 - val_loss: 2.6543 - val_accuracy: 0.7591\n",
      "Epoch 554\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.5486 - accuracy: 0.7839 - val_loss: 2.6482 - val_accuracy: 0.7613\n",
      "Epoch 555\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6766 - accuracy: 0.7731 - val_loss: 2.6481 - val_accuracy: 0.7570\n",
      "Epoch 556\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.5915 - accuracy: 0.7527 - val_loss: 2.6493 - val_accuracy: 0.7613\n",
      "Epoch 557\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.5510 - accuracy: 0.7989 - val_loss: 2.6404 - val_accuracy: 0.7677\n",
      "Epoch 558\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.6980 - accuracy: 0.7527 - val_loss: 2.6480 - val_accuracy: 0.7699\n",
      "Epoch 559\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.5839 - accuracy: 0.7645 - val_loss: 2.6566 - val_accuracy: 0.7699\n",
      "Epoch 560\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 2.6438 - accuracy: 0.7656 - val_loss: 2.6705 - val_accuracy: 0.7871\n",
      "Epoch 561\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5997 - accuracy: 0.7688 - val_loss: 2.6748 - val_accuracy: 0.7871\n",
      "Epoch 562\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5993 - accuracy: 0.7645 - val_loss: 2.6811 - val_accuracy: 0.7806\n",
      "Epoch 563\n",
      "3/3 [==============================] - 3s 748ms/step - loss: 2.5773 - accuracy: 0.7667 - val_loss: 2.6563 - val_accuracy: 0.7742\n",
      "Epoch 564\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.5893 - accuracy: 0.7667 - val_loss: 2.6402 - val_accuracy: 0.7742\n",
      "Epoch 565\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.6631 - accuracy: 0.7484 - val_loss: 2.6382 - val_accuracy: 0.7806\n",
      "Epoch 566\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.5515 - accuracy: 0.7839 - val_loss: 2.6309 - val_accuracy: 0.7785\n",
      "Epoch 567\n",
      "3/3 [==============================] - 3s 779ms/step - loss: 2.5279 - accuracy: 0.7860 - val_loss: 2.6323 - val_accuracy: 0.7763\n",
      "Epoch 568\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.6670 - accuracy: 0.7462 - val_loss: 2.6171 - val_accuracy: 0.7742\n",
      "Epoch 569\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.6089 - accuracy: 0.7774 - val_loss: 2.5898 - val_accuracy: 0.7892\n",
      "Epoch 570\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 2.5603 - accuracy: 0.7688 - val_loss: 2.5728 - val_accuracy: 0.7849\n",
      "Epoch 571\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.5216 - accuracy: 0.7763 - val_loss: 2.5782 - val_accuracy: 0.7763\n",
      "Epoch 572\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.5290 - accuracy: 0.7839 - val_loss: 2.6012 - val_accuracy: 0.7699\n",
      "Epoch 573\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6778 - accuracy: 0.7301 - val_loss: 2.6248 - val_accuracy: 0.7720\n",
      "Epoch 574\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.6448 - accuracy: 0.7505 - val_loss: 2.6369 - val_accuracy: 0.7699\n",
      "Epoch 575\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.5380 - accuracy: 0.7817 - val_loss: 2.6501 - val_accuracy: 0.7570\n",
      "Epoch 576\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.6605 - accuracy: 0.7462 - val_loss: 2.6752 - val_accuracy: 0.7376\n",
      "Epoch 577\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.5790 - accuracy: 0.7742 - val_loss: 2.6923 - val_accuracy: 0.7419\n",
      "Epoch 578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 767ms/step - loss: 2.6138 - accuracy: 0.7516 - val_loss: 2.7074 - val_accuracy: 0.7398\n",
      "Epoch 579\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.6298 - accuracy: 0.7645 - val_loss: 2.7146 - val_accuracy: 0.7419\n",
      "Epoch 580\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.5762 - accuracy: 0.7667 - val_loss: 2.7053 - val_accuracy: 0.7462\n",
      "Epoch 581\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6198 - accuracy: 0.7473 - val_loss: 2.6961 - val_accuracy: 0.7505\n",
      "Epoch 582\n",
      "3/3 [==============================] - 3s 656ms/step - loss: 2.5713 - accuracy: 0.7742 - val_loss: 2.6936 - val_accuracy: 0.7505\n",
      "Epoch 583\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.5496 - accuracy: 0.7860 - val_loss: 2.6901 - val_accuracy: 0.7591\n",
      "Epoch 584\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.5168 - accuracy: 0.7710 - val_loss: 2.6929 - val_accuracy: 0.7570\n",
      "Epoch 585\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.5086 - accuracy: 0.7860 - val_loss: 2.6974 - val_accuracy: 0.7570\n",
      "Epoch 586\n",
      "3/3 [==============================] - 3s 597ms/step - loss: 2.5593 - accuracy: 0.7839 - val_loss: 2.6882 - val_accuracy: 0.7656\n",
      "Epoch 587\n",
      "3/3 [==============================] - 3s 586ms/step - loss: 2.5414 - accuracy: 0.7634 - val_loss: 2.6824 - val_accuracy: 0.7742\n",
      "Epoch 588\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.5493 - accuracy: 0.7699 - val_loss: 2.6769 - val_accuracy: 0.7656\n",
      "Epoch 589\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.6151 - accuracy: 0.7699 - val_loss: 2.6668 - val_accuracy: 0.7570\n",
      "Epoch 590\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.5889 - accuracy: 0.7613 - val_loss: 2.6496 - val_accuracy: 0.7613\n",
      "Epoch 591\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 2.5525 - accuracy: 0.7742 - val_loss: 2.6435 - val_accuracy: 0.7613\n",
      "Epoch 592\n",
      "3/3 [==============================] - 3s 750ms/step - loss: 2.4996 - accuracy: 0.7763 - val_loss: 2.6417 - val_accuracy: 0.7634\n",
      "Epoch 593\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.6058 - accuracy: 0.7656 - val_loss: 2.6370 - val_accuracy: 0.7634\n",
      "Epoch 594\n",
      "3/3 [==============================] - 3s 745ms/step - loss: 2.6144 - accuracy: 0.7634 - val_loss: 2.6242 - val_accuracy: 0.7613\n",
      "Epoch 595\n",
      "3/3 [==============================] - 3s 602ms/step - loss: 2.6200 - accuracy: 0.7570 - val_loss: 2.6155 - val_accuracy: 0.7656\n",
      "Epoch 596\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.6201 - accuracy: 0.7602 - val_loss: 2.6147 - val_accuracy: 0.7699\n",
      "Epoch 597\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.6533 - accuracy: 0.7505 - val_loss: 2.6207 - val_accuracy: 0.7677\n",
      "Epoch 598\n",
      "3/3 [==============================] - 3s 732ms/step - loss: 2.5627 - accuracy: 0.7667 - val_loss: 2.6324 - val_accuracy: 0.7613\n",
      "Epoch 599\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.5795 - accuracy: 0.7742 - val_loss: 2.6466 - val_accuracy: 0.7613\n",
      "Epoch 600\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.5612 - accuracy: 0.7688 - val_loss: 2.6601 - val_accuracy: 0.7591\n",
      "Epoch 601\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.5999 - accuracy: 0.7548 - val_loss: 2.6604 - val_accuracy: 0.7591\n",
      "Epoch 602\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.5546 - accuracy: 0.7656 - val_loss: 2.6430 - val_accuracy: 0.7484\n",
      "Epoch 603\n",
      "3/3 [==============================] - 3s 603ms/step - loss: 2.6130 - accuracy: 0.7613 - val_loss: 2.6250 - val_accuracy: 0.7656\n",
      "Epoch 604\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 2.5523 - accuracy: 0.7613 - val_loss: 2.6244 - val_accuracy: 0.7634\n",
      "Epoch 605\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.5516 - accuracy: 0.7667 - val_loss: 2.6220 - val_accuracy: 0.7548\n",
      "Epoch 606\n",
      "3/3 [==============================] - 3s 760ms/step - loss: 2.5624 - accuracy: 0.7720 - val_loss: 2.6310 - val_accuracy: 0.7613\n",
      "Epoch 607\n",
      "3/3 [==============================] - 3s 616ms/step - loss: 2.5567 - accuracy: 0.7613 - val_loss: 2.6407 - val_accuracy: 0.7505\n",
      "Epoch 608\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 2.5244 - accuracy: 0.7849 - val_loss: 2.6463 - val_accuracy: 0.7441\n",
      "Epoch 609\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.4808 - accuracy: 0.7817 - val_loss: 2.6447 - val_accuracy: 0.7376\n",
      "Epoch 610\n",
      "3/3 [==============================] - 3s 581ms/step - loss: 2.6590 - accuracy: 0.7516 - val_loss: 2.6317 - val_accuracy: 0.7462\n",
      "Epoch 611\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.5567 - accuracy: 0.7688 - val_loss: 2.6074 - val_accuracy: 0.7548\n",
      "Epoch 612\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 2.5513 - accuracy: 0.7667 - val_loss: 2.6054 - val_accuracy: 0.7591\n",
      "Epoch 613\n",
      "3/3 [==============================] - 3s 738ms/step - loss: 2.4906 - accuracy: 0.7817 - val_loss: 2.6137 - val_accuracy: 0.7634\n",
      "Epoch 614\n",
      "3/3 [==============================] - 3s 735ms/step - loss: 2.5093 - accuracy: 0.7871 - val_loss: 2.6443 - val_accuracy: 0.7613\n",
      "Epoch 615\n",
      "3/3 [==============================] - 3s 641ms/step - loss: 2.6405 - accuracy: 0.7538 - val_loss: 2.6630 - val_accuracy: 0.7613\n",
      "Epoch 616\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.5171 - accuracy: 0.7699 - val_loss: 2.6753 - val_accuracy: 0.7591\n",
      "Epoch 617\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.5281 - accuracy: 0.7774 - val_loss: 2.6813 - val_accuracy: 0.7548\n",
      "Epoch 618\n",
      "3/3 [==============================] - 3s 647ms/step - loss: 2.4366 - accuracy: 0.8011 - val_loss: 2.6837 - val_accuracy: 0.7634\n",
      "Epoch 619\n",
      "3/3 [==============================] - 3s 632ms/step - loss: 2.5117 - accuracy: 0.7774 - val_loss: 2.6653 - val_accuracy: 0.7613\n",
      "Epoch 620\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.4868 - accuracy: 0.7871 - val_loss: 2.6540 - val_accuracy: 0.7634\n",
      "Epoch 621\n",
      "3/3 [==============================] - 3s 724ms/step - loss: 2.5055 - accuracy: 0.7720 - val_loss: 2.6518 - val_accuracy: 0.7570\n",
      "Epoch 622\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.5235 - accuracy: 0.7796 - val_loss: 2.6516 - val_accuracy: 0.7591\n",
      "Epoch 623\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.5597 - accuracy: 0.7720 - val_loss: 2.6469 - val_accuracy: 0.7591\n",
      "Epoch 624\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.5492 - accuracy: 0.7667 - val_loss: 2.6624 - val_accuracy: 0.7333\n",
      "Epoch 625\n",
      "3/3 [==============================] - 3s 633ms/step - loss: 2.4638 - accuracy: 0.7968 - val_loss: 2.6826 - val_accuracy: 0.7269\n",
      "Epoch 626\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.5319 - accuracy: 0.7677 - val_loss: 2.6849 - val_accuracy: 0.7290\n",
      "Epoch 627\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.5240 - accuracy: 0.7602 - val_loss: 2.6734 - val_accuracy: 0.7462\n",
      "Epoch 628\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.5203 - accuracy: 0.7828 - val_loss: 2.6537 - val_accuracy: 0.7548\n",
      "Epoch 629\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.4315 - accuracy: 0.7806 - val_loss: 2.6458 - val_accuracy: 0.7742\n",
      "Epoch 630\n",
      "3/3 [==============================] - 3s 725ms/step - loss: 2.5053 - accuracy: 0.7839 - val_loss: 2.6383 - val_accuracy: 0.7763\n",
      "Epoch 631\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.6156 - accuracy: 0.7699 - val_loss: 2.6319 - val_accuracy: 0.7656\n",
      "Epoch 632\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4433 - accuracy: 0.7892 - val_loss: 2.6208 - val_accuracy: 0.7613\n",
      "Epoch 633\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.5283 - accuracy: 0.7806 - val_loss: 2.6142 - val_accuracy: 0.7613\n",
      "Epoch 634\n",
      "3/3 [==============================] - 3s 649ms/step - loss: 2.5836 - accuracy: 0.7634 - val_loss: 2.6091 - val_accuracy: 0.7634\n",
      "Epoch 635\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.4660 - accuracy: 0.7925 - val_loss: 2.6048 - val_accuracy: 0.7699\n",
      "Epoch 636\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 2.6110 - accuracy: 0.7473 - val_loss: 2.5955 - val_accuracy: 0.7742\n",
      "Epoch 637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 587ms/step - loss: 2.4675 - accuracy: 0.7828 - val_loss: 2.5847 - val_accuracy: 0.7763\n",
      "Epoch 638\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.5315 - accuracy: 0.7731 - val_loss: 2.5740 - val_accuracy: 0.7699\n",
      "Epoch 639\n",
      "3/3 [==============================] - 3s 751ms/step - loss: 2.4731 - accuracy: 0.7882 - val_loss: 2.5626 - val_accuracy: 0.7763\n",
      "Epoch 640\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.4932 - accuracy: 0.7925 - val_loss: 2.5623 - val_accuracy: 0.7677\n",
      "Epoch 641\n",
      "3/3 [==============================] - 3s 619ms/step - loss: 2.5217 - accuracy: 0.7774 - val_loss: 2.5574 - val_accuracy: 0.7634\n",
      "Epoch 642\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.5231 - accuracy: 0.7753 - val_loss: 2.5377 - val_accuracy: 0.7656\n",
      "Epoch 643\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.4021 - accuracy: 0.7978 - val_loss: 2.5395 - val_accuracy: 0.7699\n",
      "Epoch 644\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.5443 - accuracy: 0.7581 - val_loss: 2.5458 - val_accuracy: 0.7720\n",
      "Epoch 645\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.5055 - accuracy: 0.7860 - val_loss: 2.5490 - val_accuracy: 0.7699\n",
      "Epoch 646\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.4987 - accuracy: 0.7645 - val_loss: 2.5588 - val_accuracy: 0.7699\n",
      "Epoch 647\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3765 - accuracy: 0.8011 - val_loss: 2.5655 - val_accuracy: 0.7699\n",
      "Epoch 648\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4866 - accuracy: 0.7882 - val_loss: 2.5709 - val_accuracy: 0.7634\n",
      "Epoch 649\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.4130 - accuracy: 0.7785 - val_loss: 2.5674 - val_accuracy: 0.7484\n",
      "Epoch 650\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.4774 - accuracy: 0.7710 - val_loss: 2.5549 - val_accuracy: 0.7484\n",
      "Epoch 651\n",
      "3/3 [==============================] - 3s 645ms/step - loss: 2.4189 - accuracy: 0.8075 - val_loss: 2.5498 - val_accuracy: 0.7527\n",
      "Epoch 652\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 2.4299 - accuracy: 0.8011 - val_loss: 2.5509 - val_accuracy: 0.7570\n",
      "Epoch 653\n",
      "3/3 [==============================] - 3s 713ms/step - loss: 2.5438 - accuracy: 0.7613 - val_loss: 2.5365 - val_accuracy: 0.7462\n",
      "Epoch 654\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.5200 - accuracy: 0.7925 - val_loss: 2.5135 - val_accuracy: 0.7484\n",
      "Epoch 655\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.5889 - accuracy: 0.7409 - val_loss: 2.5044 - val_accuracy: 0.7527\n",
      "Epoch 656\n",
      "3/3 [==============================] - 3s 659ms/step - loss: 2.5056 - accuracy: 0.7785 - val_loss: 2.4973 - val_accuracy: 0.7591\n",
      "Epoch 657\n",
      "3/3 [==============================] - 3s 754ms/step - loss: 2.4847 - accuracy: 0.8000 - val_loss: 2.5016 - val_accuracy: 0.7613\n",
      "Epoch 658\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.4320 - accuracy: 0.7892 - val_loss: 2.5077 - val_accuracy: 0.7634\n",
      "Epoch 659\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.5338 - accuracy: 0.7677 - val_loss: 2.5178 - val_accuracy: 0.7505\n",
      "Epoch 660\n",
      "3/3 [==============================] - 3s 765ms/step - loss: 2.4832 - accuracy: 0.7882 - val_loss: 2.5320 - val_accuracy: 0.7505\n",
      "Epoch 661\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.4323 - accuracy: 0.7785 - val_loss: 2.5542 - val_accuracy: 0.7419\n",
      "Epoch 662\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.5228 - accuracy: 0.7710 - val_loss: 2.5609 - val_accuracy: 0.7505\n",
      "Epoch 663\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.5426 - accuracy: 0.7656 - val_loss: 2.5735 - val_accuracy: 0.7419\n",
      "Epoch 664\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.3883 - accuracy: 0.8097 - val_loss: 2.5844 - val_accuracy: 0.7462\n",
      "Epoch 665\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.4975 - accuracy: 0.7667 - val_loss: 2.5713 - val_accuracy: 0.7441\n",
      "Epoch 666\n",
      "3/3 [==============================] - 3s 610ms/step - loss: 2.4301 - accuracy: 0.7957 - val_loss: 2.5526 - val_accuracy: 0.7441\n",
      "Epoch 667\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.4551 - accuracy: 0.7935 - val_loss: 2.5230 - val_accuracy: 0.7484\n",
      "Epoch 668\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.4310 - accuracy: 0.7892 - val_loss: 2.5043 - val_accuracy: 0.7591\n",
      "Epoch 669\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.4523 - accuracy: 0.7796 - val_loss: 2.4910 - val_accuracy: 0.7677\n",
      "Epoch 670\n",
      "3/3 [==============================] - 3s 730ms/step - loss: 2.3824 - accuracy: 0.7978 - val_loss: 2.4964 - val_accuracy: 0.7613\n",
      "Epoch 671\n",
      "3/3 [==============================] - 3s 644ms/step - loss: 2.4616 - accuracy: 0.7914 - val_loss: 2.4961 - val_accuracy: 0.7656\n",
      "Epoch 672\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.4794 - accuracy: 0.7785 - val_loss: 2.5003 - val_accuracy: 0.7591\n",
      "Epoch 673\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.4661 - accuracy: 0.7925 - val_loss: 2.5108 - val_accuracy: 0.7548\n",
      "Epoch 674\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.3946 - accuracy: 0.7785 - val_loss: 2.5273 - val_accuracy: 0.7441\n",
      "Epoch 675\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.5059 - accuracy: 0.7720 - val_loss: 2.5493 - val_accuracy: 0.7505\n",
      "Epoch 676\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4179 - accuracy: 0.7892 - val_loss: 2.5785 - val_accuracy: 0.7484\n",
      "Epoch 677\n",
      "3/3 [==============================] - 3s 605ms/step - loss: 2.4224 - accuracy: 0.7731 - val_loss: 2.5922 - val_accuracy: 0.7527\n",
      "Epoch 678\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.4106 - accuracy: 0.8065 - val_loss: 2.5928 - val_accuracy: 0.7570\n",
      "Epoch 679\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.5239 - accuracy: 0.7667 - val_loss: 2.5891 - val_accuracy: 0.7527\n",
      "Epoch 680\n",
      "3/3 [==============================] - 3s 576ms/step - loss: 2.5320 - accuracy: 0.7656 - val_loss: 2.5870 - val_accuracy: 0.7462\n",
      "Epoch 681\n",
      "3/3 [==============================] - 3s 582ms/step - loss: 2.4101 - accuracy: 0.7925 - val_loss: 2.5706 - val_accuracy: 0.7527\n",
      "Epoch 682\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.3971 - accuracy: 0.8140 - val_loss: 2.5639 - val_accuracy: 0.7527\n",
      "Epoch 683\n",
      "3/3 [==============================] - 3s 622ms/step - loss: 2.5161 - accuracy: 0.7742 - val_loss: 2.5612 - val_accuracy: 0.7484\n",
      "Epoch 684\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.3961 - accuracy: 0.8086 - val_loss: 2.5546 - val_accuracy: 0.7484\n",
      "Epoch 685\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.4490 - accuracy: 0.7624 - val_loss: 2.5561 - val_accuracy: 0.7527\n",
      "Epoch 686\n",
      "3/3 [==============================] - 3s 600ms/step - loss: 2.4427 - accuracy: 0.7882 - val_loss: 2.5605 - val_accuracy: 0.7570\n",
      "Epoch 687\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.3941 - accuracy: 0.8086 - val_loss: 2.5522 - val_accuracy: 0.7591\n",
      "Epoch 688\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4307 - accuracy: 0.7903 - val_loss: 2.5391 - val_accuracy: 0.7591\n",
      "Epoch 689\n",
      "3/3 [==============================] - 3s 587ms/step - loss: 2.3361 - accuracy: 0.8065 - val_loss: 2.5193 - val_accuracy: 0.7634\n",
      "Epoch 690\n",
      "3/3 [==============================] - 3s 778ms/step - loss: 2.3668 - accuracy: 0.8032 - val_loss: 2.5015 - val_accuracy: 0.7699\n",
      "Epoch 691\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.5523 - accuracy: 0.7591 - val_loss: 2.5107 - val_accuracy: 0.7699\n",
      "Epoch 692\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.4271 - accuracy: 0.8032 - val_loss: 2.5341 - val_accuracy: 0.7656\n",
      "Epoch 693\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.5252 - accuracy: 0.7753 - val_loss: 2.5611 - val_accuracy: 0.7656\n",
      "Epoch 694\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.4876 - accuracy: 0.7774 - val_loss: 2.5790 - val_accuracy: 0.7656\n",
      "Epoch 695\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.4856 - accuracy: 0.7935 - val_loss: 2.5948 - val_accuracy: 0.7591\n",
      "Epoch 696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 584ms/step - loss: 2.5353 - accuracy: 0.7581 - val_loss: 2.6090 - val_accuracy: 0.7527\n",
      "Epoch 697\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.4222 - accuracy: 0.7763 - val_loss: 2.6065 - val_accuracy: 0.7548\n",
      "Epoch 698\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.4086 - accuracy: 0.8011 - val_loss: 2.6058 - val_accuracy: 0.7548\n",
      "Epoch 699\n",
      "3/3 [==============================] - 3s 634ms/step - loss: 2.3344 - accuracy: 0.8269 - val_loss: 2.5918 - val_accuracy: 0.7591\n",
      "Epoch 700\n",
      "3/3 [==============================] - 3s 721ms/step - loss: 2.4617 - accuracy: 0.7763 - val_loss: 2.5720 - val_accuracy: 0.7613\n",
      "Epoch 701\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4441 - accuracy: 0.7699 - val_loss: 2.5538 - val_accuracy: 0.7656\n",
      "Epoch 702\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.5315 - accuracy: 0.7581 - val_loss: 2.5386 - val_accuracy: 0.7677\n",
      "Epoch 703\n",
      "3/3 [==============================] - 3s 648ms/step - loss: 2.3820 - accuracy: 0.8054 - val_loss: 2.5326 - val_accuracy: 0.7699\n",
      "Epoch 704\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.5045 - accuracy: 0.7763 - val_loss: 2.5370 - val_accuracy: 0.7742\n",
      "Epoch 705\n",
      "3/3 [==============================] - 3s 611ms/step - loss: 2.4441 - accuracy: 0.7989 - val_loss: 2.5407 - val_accuracy: 0.7763\n",
      "Epoch 706\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.4052 - accuracy: 0.7882 - val_loss: 2.5342 - val_accuracy: 0.7742\n",
      "Epoch 707\n",
      "3/3 [==============================] - 3s 601ms/step - loss: 2.4261 - accuracy: 0.7720 - val_loss: 2.5051 - val_accuracy: 0.7720\n",
      "Epoch 708\n",
      "3/3 [==============================] - 3s 604ms/step - loss: 2.3697 - accuracy: 0.7946 - val_loss: 2.4600 - val_accuracy: 0.7785\n",
      "Epoch 709\n",
      "3/3 [==============================] - 3s 599ms/step - loss: 2.3738 - accuracy: 0.8108 - val_loss: 2.4374 - val_accuracy: 0.7849\n",
      "Epoch 710\n",
      "3/3 [==============================] - 3s 707ms/step - loss: 2.3106 - accuracy: 0.8118 - val_loss: 2.4303 - val_accuracy: 0.7871\n",
      "Epoch 711\n",
      "3/3 [==============================] - 3s 744ms/step - loss: 2.3180 - accuracy: 0.8215 - val_loss: 2.4234 - val_accuracy: 0.7892\n",
      "Epoch 712\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.3877 - accuracy: 0.7957 - val_loss: 2.4236 - val_accuracy: 0.7914\n",
      "Epoch 713\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3656 - accuracy: 0.8086 - val_loss: 2.4220 - val_accuracy: 0.7935\n",
      "Epoch 714\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.4950 - accuracy: 0.7763 - val_loss: 2.4292 - val_accuracy: 0.7914\n",
      "Epoch 715\n",
      "3/3 [==============================] - 3s 595ms/step - loss: 2.3585 - accuracy: 0.7914 - val_loss: 2.4333 - val_accuracy: 0.7871\n",
      "Epoch 716\n",
      "3/3 [==============================] - 3s 715ms/step - loss: 2.3583 - accuracy: 0.8043 - val_loss: 2.4331 - val_accuracy: 0.7828\n",
      "Epoch 717\n",
      "3/3 [==============================] - 3s 606ms/step - loss: 2.4750 - accuracy: 0.7796 - val_loss: 2.4259 - val_accuracy: 0.7742\n",
      "Epoch 718\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.3843 - accuracy: 0.7860 - val_loss: 2.4232 - val_accuracy: 0.7763\n",
      "Epoch 719\n",
      "3/3 [==============================] - 3s 625ms/step - loss: 2.4078 - accuracy: 0.7839 - val_loss: 2.4097 - val_accuracy: 0.7871\n",
      "Epoch 720\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.3701 - accuracy: 0.7892 - val_loss: 2.4002 - val_accuracy: 0.7935\n",
      "Epoch 721\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.3647 - accuracy: 0.8011 - val_loss: 2.3978 - val_accuracy: 0.7957\n",
      "Epoch 722\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.4048 - accuracy: 0.8022 - val_loss: 2.3955 - val_accuracy: 0.7871\n",
      "Epoch 723\n",
      "3/3 [==============================] - 3s 615ms/step - loss: 2.2952 - accuracy: 0.8108 - val_loss: 2.4116 - val_accuracy: 0.7828\n",
      "Epoch 724\n",
      "3/3 [==============================] - 3s 629ms/step - loss: 2.3949 - accuracy: 0.7978 - val_loss: 2.4316 - val_accuracy: 0.7849\n",
      "Epoch 725\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3773 - accuracy: 0.7903 - val_loss: 2.4436 - val_accuracy: 0.7699\n",
      "Epoch 726\n",
      "3/3 [==============================] - 3s 580ms/step - loss: 2.4586 - accuracy: 0.7591 - val_loss: 2.4514 - val_accuracy: 0.7613\n",
      "Epoch 727\n",
      "3/3 [==============================] - 3s 621ms/step - loss: 2.4768 - accuracy: 0.7753 - val_loss: 2.4517 - val_accuracy: 0.7677\n",
      "Epoch 728\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4406 - accuracy: 0.7763 - val_loss: 2.4567 - val_accuracy: 0.7634\n",
      "Epoch 729\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4365 - accuracy: 0.7914 - val_loss: 2.4675 - val_accuracy: 0.7699\n",
      "Epoch 730\n",
      "3/3 [==============================] - 3s 643ms/step - loss: 2.4248 - accuracy: 0.7925 - val_loss: 2.4752 - val_accuracy: 0.7699\n",
      "Epoch 731\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.4579 - accuracy: 0.7688 - val_loss: 2.4928 - val_accuracy: 0.7785\n",
      "Epoch 732\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4634 - accuracy: 0.7731 - val_loss: 2.5041 - val_accuracy: 0.7656\n",
      "Epoch 733\n",
      "3/3 [==============================] - 3s 624ms/step - loss: 2.4139 - accuracy: 0.7774 - val_loss: 2.5001 - val_accuracy: 0.7591\n",
      "Epoch 734\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.3687 - accuracy: 0.8043 - val_loss: 2.4904 - val_accuracy: 0.7656\n",
      "Epoch 735\n",
      "3/3 [==============================] - 3s 627ms/step - loss: 2.4369 - accuracy: 0.7871 - val_loss: 2.4717 - val_accuracy: 0.7742\n",
      "Epoch 736\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.3792 - accuracy: 0.7892 - val_loss: 2.4451 - val_accuracy: 0.7763\n",
      "Epoch 737\n",
      "3/3 [==============================] - 3s 626ms/step - loss: 2.4313 - accuracy: 0.7828 - val_loss: 2.4285 - val_accuracy: 0.7742\n",
      "Epoch 738\n",
      "3/3 [==============================] - 3s 768ms/step - loss: 2.4440 - accuracy: 0.7882 - val_loss: 2.4175 - val_accuracy: 0.7914\n",
      "Epoch 739\n",
      "3/3 [==============================] - 3s 741ms/step - loss: 2.3536 - accuracy: 0.7935 - val_loss: 2.4081 - val_accuracy: 0.7892\n",
      "Epoch 740\n",
      "3/3 [==============================] - 3s 729ms/step - loss: 2.3590 - accuracy: 0.8118 - val_loss: 2.4119 - val_accuracy: 0.7957\n",
      "Epoch 741\n",
      "3/3 [==============================] - 3s 758ms/step - loss: 2.4435 - accuracy: 0.7688 - val_loss: 2.4169 - val_accuracy: 0.7849\n",
      "Epoch 742\n",
      "3/3 [==============================] - 3s 762ms/step - loss: 2.3705 - accuracy: 0.7849 - val_loss: 2.4220 - val_accuracy: 0.7871\n",
      "Epoch 743\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.4458 - accuracy: 0.7935 - val_loss: 2.4346 - val_accuracy: 0.7806\n",
      "Epoch 744\n",
      "3/3 [==============================] - 3s 649ms/step - loss: 2.4040 - accuracy: 0.7860 - val_loss: 2.4622 - val_accuracy: 0.7806\n",
      "Epoch 745\n",
      "3/3 [==============================] - 3s 651ms/step - loss: 2.4128 - accuracy: 0.7839 - val_loss: 2.4871 - val_accuracy: 0.7806\n",
      "Epoch 746\n",
      "3/3 [==============================] - 3s 728ms/step - loss: 2.4056 - accuracy: 0.7946 - val_loss: 2.5074 - val_accuracy: 0.7656\n",
      "Epoch 747\n",
      "3/3 [==============================] - 3s 631ms/step - loss: 2.3490 - accuracy: 0.7978 - val_loss: 2.5147 - val_accuracy: 0.7699\n",
      "Epoch 748\n",
      "3/3 [==============================] - 3s 620ms/step - loss: 2.3791 - accuracy: 0.8140 - val_loss: 2.5219 - val_accuracy: 0.7677\n",
      "Epoch 749\n",
      "3/3 [==============================] - 3s 739ms/step - loss: 2.4552 - accuracy: 0.7849 - val_loss: 2.5246 - val_accuracy: 0.7591\n",
      "Epoch 750\n",
      "3/3 [==============================] - 3s 609ms/step - loss: 2.4067 - accuracy: 0.7688 - val_loss: 2.5211 - val_accuracy: 0.7634\n",
      "Epoch 751\n",
      "3/3 [==============================] - 3s 588ms/step - loss: 2.4071 - accuracy: 0.7860 - val_loss: 2.5111 - val_accuracy: 0.7591\n",
      "Epoch 752\n",
      "3/3 [==============================] - 3s 592ms/step - loss: 2.3448 - accuracy: 0.8032 - val_loss: 2.4939 - val_accuracy: 0.7591\n",
      "Epoch 753\n",
      "3/3 [==============================] - 3s 646ms/step - loss: 2.3796 - accuracy: 0.8118 - val_loss: 2.4844 - val_accuracy: 0.7634\n",
      "Epoch 754\n",
      "3/3 [==============================] - 3s 743ms/step - loss: 2.3149 - accuracy: 0.8054 - val_loss: 2.4765 - val_accuracy: 0.7570\n",
      "Epoch 755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 579ms/step - loss: 2.3949 - accuracy: 0.7839 - val_loss: 2.4858 - val_accuracy: 0.7505\n",
      "Epoch 756\n",
      "3/3 [==============================] - 3s 612ms/step - loss: 2.3674 - accuracy: 0.7968 - val_loss: 2.5048 - val_accuracy: 0.7505\n",
      "Epoch 757\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.4338 - accuracy: 0.7763 - val_loss: 2.5273 - val_accuracy: 0.7613\n",
      "Epoch 758\n",
      "3/3 [==============================] - 3s 771ms/step - loss: 2.4654 - accuracy: 0.7731 - val_loss: 2.5368 - val_accuracy: 0.7570\n",
      "Epoch 759\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.4335 - accuracy: 0.7882 - val_loss: 2.5495 - val_accuracy: 0.7591\n",
      "Epoch 760\n",
      "3/3 [==============================] - 3s 585ms/step - loss: 2.3731 - accuracy: 0.7989 - val_loss: 2.5553 - val_accuracy: 0.7570\n",
      "Epoch 761\n",
      "3/3 [==============================] - 3s 614ms/step - loss: 2.4388 - accuracy: 0.7806 - val_loss: 2.5552 - val_accuracy: 0.7570\n",
      "Epoch 762\n",
      "3/3 [==============================] - 3s 591ms/step - loss: 2.3931 - accuracy: 0.7946 - val_loss: 2.5600 - val_accuracy: 0.7548\n",
      "Epoch 763\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.3415 - accuracy: 0.8022 - val_loss: 2.5525 - val_accuracy: 0.7505\n",
      "Epoch 764\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.3619 - accuracy: 0.8075 - val_loss: 2.5451 - val_accuracy: 0.7484\n",
      "Epoch 765\n",
      "3/3 [==============================] - 3s 613ms/step - loss: 2.3875 - accuracy: 0.7871 - val_loss: 2.5558 - val_accuracy: 0.7484\n",
      "Epoch 766\n",
      "3/3 [==============================] - 3s 589ms/step - loss: 2.4988 - accuracy: 0.7731 - val_loss: 2.5686 - val_accuracy: 0.7462\n",
      "Epoch 767\n",
      "3/3 [==============================] - 3s 654ms/step - loss: 2.4169 - accuracy: 0.7731 - val_loss: 2.5695 - val_accuracy: 0.7419\n",
      "Epoch 768\n",
      "3/3 [==============================] - 3s 590ms/step - loss: 2.3647 - accuracy: 0.7957 - val_loss: 2.5712 - val_accuracy: 0.7462\n",
      "Epoch 769\n",
      "3/3 [==============================] - 3s 584ms/step - loss: 2.2707 - accuracy: 0.8258 - val_loss: 2.5794 - val_accuracy: 0.7376\n",
      "Epoch 770\n",
      "3/3 [==============================] - 3s 618ms/step - loss: 2.3181 - accuracy: 0.8118 - val_loss: 2.5732 - val_accuracy: 0.7419\n",
      "Epoch 771\n",
      "3/3 [==============================] - 3s 623ms/step - loss: 2.3686 - accuracy: 0.7978 - val_loss: 2.5668 - val_accuracy: 0.7441\n",
      "Epoch 772\n",
      "3/3 [==============================] - 3s 608ms/step - loss: 2.3914 - accuracy: 0.8032 - val_loss: 2.5624 - val_accuracy: 0.7441\n",
      "Epoch 773\n",
      "3/3 [==============================] - 3s 812ms/step - loss: 2.3443 - accuracy: 0.8011 - val_loss: 2.5389 - val_accuracy: 0.7484\n",
      "Epoch 774\n",
      "3/3 [==============================] - 3s 598ms/step - loss: 2.4799 - accuracy: 0.7903 - val_loss: 2.5290 - val_accuracy: 0.7548\n",
      "Epoch 775\n",
      "3/3 [==============================] - 3s 607ms/step - loss: 2.3126 - accuracy: 0.7957 - val_loss: 2.5366 - val_accuracy: 0.7505\n",
      "Epoch 776\n",
      "4/3 [=================================] - ETA: 0s - loss: 2.2964 - accuracy: 0.8086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a0d69f308d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dnn_structure_changned\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled_trasfer_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SpeechVision/DysarthricCNNRezaTransferLearningSD/DysarthricSpeechVision.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ideal_loss, is_dnn_structure_changned, learning_rate, max_epoch, enabled_trasfer_learning)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mideal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             history=model.fit(\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "train(is_dnn_structure_changned= False, enabled_trasfer_learning=True, max_epoch=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner_model_M08/dyser_M08_Resnet/oracle.json\n",
      "0.0001\n",
      "input_1  FREEZED\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.2\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "activation  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.2\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "activation_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.2\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "conv2d  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "add  NOT FREEZED\n",
      "activation_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.2\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_4  NOT FREEZED\n",
      "activation_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.2\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "conv2d_1  NOT FREEZED\n",
      "batch_normalization_5  NOT FREEZED\n",
      "batch_normalization_6  NOT FREEZED\n",
      "add_1  NOT FREEZED\n",
      "activation_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "separable_conv2d_5  NOT FREEZED\n",
      "spatial_dropout2d_5 dropout rate updated to 0.2\n",
      "spatial_dropout2d_5  NOT FREEZED\n",
      "batch_normalization_7  NOT FREEZED\n",
      "activation_5  NOT FREEZED\n",
      "separable_conv2d_6  NOT FREEZED\n",
      "spatial_dropout2d_6 dropout rate updated to 0.2\n",
      "spatial_dropout2d_6  NOT FREEZED\n",
      "conv2d_2  NOT FREEZED\n",
      "batch_normalization_8  NOT FREEZED\n",
      "batch_normalization_9  NOT FREEZED\n",
      "add_2  NOT FREEZED\n",
      "activation_6  NOT FREEZED\n",
      "max_pooling2d_3  NOT FREEZED\n",
      "dropout dropout rate updated to 0.2\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "INFO:tensorflow:Reloading Tuner from tuner_model_M08/dyser_M08_Resnet/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search=RandomSearch(get_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=55,directory='tuner_model_M08',\n",
    "                          project_name=\"dyser_M08_Resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033826843258466803\n",
      "input_1  FREEZED\n",
      "separable_conv2d  FREEZED\n",
      "spatial_dropout2d dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d  FREEZED\n",
      "batch_normalization  FREEZED\n",
      "activation  FREEZED\n",
      "max_pooling2d  FREEZED\n",
      "separable_conv2d_1  FREEZED\n",
      "spatial_dropout2d_1 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_1  FREEZED\n",
      "batch_normalization_1  FREEZED\n",
      "activation_1  FREEZED\n",
      "separable_conv2d_2  NOT FREEZED\n",
      "spatial_dropout2d_2 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_2  NOT FREEZED\n",
      "conv2d  NOT FREEZED\n",
      "batch_normalization_2  NOT FREEZED\n",
      "batch_normalization_3  NOT FREEZED\n",
      "add  NOT FREEZED\n",
      "activation_2  NOT FREEZED\n",
      "max_pooling2d_1  NOT FREEZED\n",
      "separable_conv2d_3  NOT FREEZED\n",
      "spatial_dropout2d_3 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_3  NOT FREEZED\n",
      "batch_normalization_4  NOT FREEZED\n",
      "activation_3  NOT FREEZED\n",
      "separable_conv2d_4  NOT FREEZED\n",
      "spatial_dropout2d_4 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_4  NOT FREEZED\n",
      "conv2d_1  NOT FREEZED\n",
      "batch_normalization_5  NOT FREEZED\n",
      "batch_normalization_6  NOT FREEZED\n",
      "add_1  NOT FREEZED\n",
      "activation_4  NOT FREEZED\n",
      "max_pooling2d_2  NOT FREEZED\n",
      "separable_conv2d_5  NOT FREEZED\n",
      "spatial_dropout2d_5 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_5  NOT FREEZED\n",
      "batch_normalization_7  NOT FREEZED\n",
      "activation_5  NOT FREEZED\n",
      "separable_conv2d_6  NOT FREEZED\n",
      "spatial_dropout2d_6 dropout rate updated to 0.22343453317323078\n",
      "spatial_dropout2d_6  NOT FREEZED\n",
      "conv2d_2  NOT FREEZED\n",
      "batch_normalization_8  NOT FREEZED\n",
      "batch_normalization_9  NOT FREEZED\n",
      "add_2  NOT FREEZED\n",
      "activation_6  NOT FREEZED\n",
      "max_pooling2d_3  NOT FREEZED\n",
      "dropout dropout rate updated to 0.22343453317323078\n",
      "dropout  NOT FREEZED\n",
      "flatten  NOT FREEZED\n",
      "dense  NOT FREEZED\n",
      "best hyper parameters are:\n",
      "droprate 0.22343453317323078\n",
      "first_train 2\n",
      "lr 0.0033826843258466803\n"
     ]
    }
   ],
   "source": [
    "tuner_search.reload()\n",
    "model=tuner_search.get_best_models(num_models=1)[0]\n",
    "best_hps=tuner_search.get_best_hyperparameters(num_trials=1)[0]\n",
    "print('best hyper parameters are:')\n",
    "print('droprate',best_hps.get('droprate'))\n",
    "print('first_train',best_hps.get('first_train'))\n",
    "print('lr',best_hps.get('lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "droprate (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.75, 'step': None, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "first_train (Choice)\n",
      "{'default': '2', 'conditions': [], 'values': ['2', '3', '4', '5', '6'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 Complete [00h 03m 57s]\n",
      "val_accuracy: 0.025806451216340065\n",
      "\n",
      "Best val_accuracy So Far: 0.9139785170555115\n",
      "Total elapsed time: 02h 14m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(training_set,epochs=95,\n",
    "                    steps_per_epoch=training_set.samples/batch_size,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=test_set.samples/batch_size,\n",
    "                    workers=10,\n",
    "                    max_queue_size=10\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.visualize_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "sv.set_gpus(\"1\")\n",
    "sv.test_generator(sv.test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
